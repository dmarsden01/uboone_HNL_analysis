{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ab81f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "import os,sys,string, time\n",
    "from array import array\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import uproot\n",
    "import pandas as pd\n",
    "from platform import python_version\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import uproot3\n",
    "import math\n",
    "from matplotlib.patches import Rectangle\n",
    "import pickle\n",
    "import functools\n",
    "from importlib import reload\n",
    "\n",
    "import Utilities.Plotter as PT\n",
    "import Utilities.Constants as Constants\n",
    "import Utilities.Variables_list as Variables\n",
    "import Utilities.Functions as Functions\n",
    "from Utilities.ipython_exit import exit\n",
    "\n",
    "print ('Success')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec8c084-e0ee-4f9a-9a99-c25ee62304d9",
   "metadata": {},
   "source": [
    "# Setting which samples to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3bfdae0-160d-4f43-bc28-aa18b62013f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading these run2a samples: \n",
      "['overlay', 'dirtoverlay', 'beamoff', 'beamgood']\n",
      "Saving these variables: \n",
      "['run', 'sub', 'evt', 'nslice', 'n_pfps', 'n_tracks', 'n_showers', 'swtrig_pre', 'swtrig_post', 'trk_sce_start_x_v', 'trk_sce_start_y_v', 'trk_sce_start_z_v', 'trk_sce_end_x_v', 'trk_sce_end_y_v', 'trk_sce_end_z_v', 'shr_theta_v', 'shr_phi_v', 'shr_px_v', 'shr_py_v', 'shr_pz_v', 'shrclusdir0', 'shrclusdir1', 'shrclusdir2', 'shr_energy_tot', 'trk_theta_v', 'trk_phi_v', 'trk_dir_x_v', 'trk_dir_y_v', 'trk_dir_z_v', 'trk_energy', 'trk_energy_hits_tot', 'trk_energy_tot', 'trk_score_v', 'trk_calo_energy_u_v', 'trk_end_x_v', 'trk_chipr_best', 'pfnplanehits_U', 'pfnplanehits_V', 'pfnplanehits_Y', 'NeutrinoEnergy2', 'SliceCaloEnergy2', 'nu_flashmatch_score', 'contained_sps_ratio', 'flash_time', 'contained_fraction', 'trk_score', 'crtveto', 'shr_tkfit_dedx_U', 'shr_tkfit_dedx_V', 'shr_tkfit_dedx_Y', 'shr_tkfit_dedx_max', 'shr_tkfit_2cm_dedx_Y', 'shr_chipr', 'trk_bragg_p', 'trk_bragg_p_v', 'trk_chipr', 'subcluster', 'shr_moliere_avg_v', 'shrmoliereavg', 'topological_score', 'weightSplineTimesTune', 'ppfx_cv', 'npi0']\n"
     ]
    }
   ],
   "source": [
    "Params = {\"Run\":\"run2a\", #The run number, so far either \"run1\" or \"run3\"\n",
    "          \"Load_lepton_signal\":False, #Just e+e- samples, Majorana\n",
    "          \"Load_pi0_signal\":False, #Just pi0 samples, Majorana\n",
    "          \"Load_lepton_dirac\":False, #Just e+e-, Dirac\n",
    "          \"Load_pi0_dirac\":False, #Just pi0, Dirac\n",
    "          \"Load_standard_bkgs\":True, #Backgrounds, 'overlay', 'dirtoverlay' and 'beamoff'\n",
    "          \"Load_data\":True, #'beamgood' sample\n",
    "          \"Load_DetVars\":False, #overlay Detector variations\n",
    "          \"Load_Signal_DetVars\":False, #e+e- Detector variation samples\n",
    "          \"Load_pi0_signal_DetVars\":False, #pi0 Detector variation samples\n",
    "          \"Only_keep_common_DetVar_evs\":True, #For DetVar samples, only keep events common between samples\n",
    "          \"FLATTEN\":True, #Have one row per reconstructed object in the dataframe\n",
    "          \"only_presel\":False, #Create small files containing only variables necessary for pre-selection, for making pre-selection plots\n",
    "          \"Load_truth_vars\":False, #Load the \"mc_\" type variables for signal\n",
    "          \"Load_single_file\":False, #This will override everything else, put the desired file in the \"single_file\" line\n",
    "          \"single_file\":'beamgood'} \n",
    "\n",
    "Params, samples = Functions.new_create_sample_list(Params)\n",
    "sample_locs_new = Functions.Get_all_sample_locs(Params)\n",
    "\n",
    "print(\"Saving these variables: \\n\" + str(Params[\"variables_MC\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5103bfa1-5b16-484c-bfc0-fda62c2b7524",
   "metadata": {},
   "source": [
    "## Loading and pickling files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fb0d30-19a9-4a11-b11e-21bfb393be26",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_evs = Functions.Make_common_evs(samples, sample_locs_new, Params)\n",
    "loc_pkls = \"pkl_files/\"+Params[\"Run\"]+\"/current_files/\"+Params[\"variables_string\"]+\"/\"\n",
    "\n",
    "Functions.New_load_and_pkl(samples, sample_locs_new, loc_pkls, common_evs, Params, save_str=\"_full_Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f4c729-3cd1-4a22-b794-8af44dfddf07",
   "metadata": {},
   "source": [
    "## Getting runs in goodrun list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12015772-053a-4cff-8932-fa51222ea13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_runs_in_goodruns(root_file_path, goodruns_list):\n",
    "    \"\"\"\n",
    "    Input .root file and \\\"goodrun\\\" list.\n",
    "    Return lists of runs in list and runs not in list.\n",
    "    \"\"\"\n",
    "    root_file = uproot3.open(root_file_path)['nuselection/NeutrinoSelectionFilter']\n",
    "    df_file = root_file.pandas.df(['run'], flatten=False)\n",
    "    \n",
    "    with open(goodruns_list, \"r\") as file:\n",
    "        goodruns = [int(line.strip()) for line in file]\n",
    "        \n",
    "    unique_values = list(set(goodruns))\n",
    "    unique_file_subruns = list(set(np.array(df_file['run'])))\n",
    "    \n",
    "    runs_in_goodruns, runs_not_in_goodruns = [], []\n",
    "    \n",
    "    for run in unique_file_subruns:\n",
    "        if run in unique_values: runs_in_goodruns.append(run)\n",
    "        if run not in unique_values: runs_not_in_goodruns.append(run)\n",
    "        \n",
    "    return runs_in_goodruns, runs_not_in_goodruns\n",
    "\n",
    "def Filter_df_runs(df, goodruns_list):\n",
    "    \"\"\"\n",
    "    Input dataframe and goodruns list.\n",
    "    Return the filtered dataframe, with only the goodruns included.\n",
    "    \"\"\"\n",
    "    filtered = df.loc[(df['run'].isin(goodruns_list))]\n",
    "    \n",
    "    return filtered\n",
    "    \n",
    "def Return_runs_subruns(df):\n",
    "    \"\"\"\n",
    "    Input filtered df.\n",
    "    Return lists of runs and subruns.\n",
    "    \"\"\"\n",
    "    # if pd.Series(['run', 'sub']).isin(df.columns).all():\n",
    "    #     run_sub_list = []\n",
    "    #     for entry in df.index: #Looping over all events in the dataframe\n",
    "    #         run_sub = str(df['run'][entry]) + \"_\" + str(df['sub'][entry])\n",
    "    #         run_sub_list.append(run_sub)\n",
    "    #     unique_run_subrun = list(set(run_sub_list))\n",
    "    #     return df.copy()\n",
    "    # else:\n",
    "    #     print(\"Dataframe needs \\\"run\\\", \\\"sub\\\" columns.\")\n",
    "    #     return 0\n",
    "    placeholder=df.drop_duplicates(subset=[\"run\",\"sub\"]).copy()\n",
    "    runs_list = placeholder[\"run\"]\n",
    "    subruns_list = placeholder[\"sub\"]\n",
    "    \n",
    "    return runs_list, subruns_list\n",
    "\n",
    "def Save_runs_subruns_as_txt(runs_list, subruns_list, savename):\n",
    "    \"\"\"\n",
    "    Input list of runs and subruns.\n",
    "    Saves runs subruns file as savename.\n",
    "    \"\"\"\n",
    "    with open(savename, \"w\") as file:\n",
    "        for val1, val2 in zip(runs_list, subruns_list):\n",
    "            file.write(str(val1) + \" \" + str(val2) + \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b364af8-1957-4f3d-b78c-5550111032ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1277 454\n",
      "899 122\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "runs_in_goodruns_2a, not_in_goodruns_2a = Get_runs_in_goodruns(\"../NuMI_data/neutrinoselection_filt_run2a_beamoff.root\", \"../NuMI_data/run2_goodruns.txt\")\n",
    "runs_in_goodruns_2b, not_in_goodruns_2b = Get_runs_in_goodruns(\"../NuMI_data/neutrinoselection_filt_run2b_beamoff.root\", \"../NuMI_data/run2_goodruns.txt\")\n",
    "\n",
    "print(len(runs_in_goodruns_2a), len(not_in_goodruns_2a))\n",
    "print(len(runs_in_goodruns_2b), len(not_in_goodruns_2b))\n",
    "\n",
    "print(type(runs_in_goodruns_2a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05e97b55-ddff-4412-ad11-44dd5aff4220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run2a beamon length: 762814\n",
      "run2b beamon length: 283307\n",
      "run2a beamon all runs: 1186\n",
      "run2b beamon all runs: 479\n",
      "run2a beamon length: 762814\n",
      "run2b beamon length: 283307\n",
      "run2a\n",
      "152856 152856\n",
      "run2b\n",
      "54228 54228\n"
     ]
    }
   ],
   "source": [
    "r2a_file = uproot3.open(\"../NuMI_data/neutrinoselection_filt_run2a_beamon.root\")['nuselection/NeutrinoSelectionFilter']\n",
    "full_run2a_df = r2a_file.pandas.df(['run', 'sub'], flatten=False)\n",
    "r2b_file = uproot3.open(\"../NuMI_data/neutrinoselection_filt_run2b_beamon.root\")['nuselection/NeutrinoSelectionFilter']\n",
    "full_run2b_df = r2b_file.pandas.df(['run', 'sub'], flatten=False)\n",
    "\n",
    "print(\"run2a beamon length: \" + str(len(full_run2a_df)))\n",
    "print(\"run2b beamon length: \" + str(len(full_run2b_df)))\n",
    "\n",
    "all_run2a_runs = list(set(np.array(full_run2a_df['run'])))\n",
    "all_run2b_runs = list(set(np.array(full_run2b_df['run'])))\n",
    "\n",
    "print(\"run2a beamon all runs: \" + str(len(all_run2a_runs)))\n",
    "print(\"run2b beamon all runs: \" + str(len(all_run2b_runs)))\n",
    "\n",
    "run2a_filtered = Filter_df_runs(full_run2a_df, all_run2a_runs)\n",
    "run2b_filtered = Filter_df_runs(full_run2b_df, all_run2b_runs)\n",
    "\n",
    "print(\"run2a beamon length: \" + str(len(run2a_filtered)))\n",
    "print(\"run2b beamon length: \" + str(len(run2b_filtered)))\n",
    "\n",
    "run2a_runs, run2a_subruns = Return_runs_subruns(run2a_filtered)\n",
    "run2b_runs, run2b_subruns = Return_runs_subruns(run2b_filtered)\n",
    "\n",
    "print(\"run2a\")\n",
    "print(len(run2a_runs), len(run2a_subruns))\n",
    "print(\"run2b\")\n",
    "print(len(run2b_runs), len(run2b_subruns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2160d39-4bfd-4ddf-a714-c16c1332a93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Save_runs_subruns_as_txt(run2a_runs, run2a_subruns, \"../NuMI_data/FULL_beamon_run2a_run_sub.txt\")\n",
    "Save_runs_subruns_as_txt(run2b_runs, run2b_subruns, \"../NuMI_data/FULL_beamon_run2b_run_sub.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e44ca590-33b4-4471-a558-dce0dead3450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run2a beamon length: 1641015\n",
      "run2b beamon length: 1044584\n",
      "run2a beamoff all runs: 1731\n",
      "run2b beamoff all runs: 1021\n",
      "run2a beamon length: 1641015\n",
      "run2b beamon length: 1044584\n",
      "run2a\n",
      "215845 215845\n",
      "run2b\n",
      "109500 109500\n"
     ]
    }
   ],
   "source": [
    "r2a_file = uproot3.open(\"../NuMI_data/neutrinoselection_filt_run2a_beamoff.root\")['nuselection/NeutrinoSelectionFilter']\n",
    "full_run2a_df = r2a_file.pandas.df(['run', 'sub'], flatten=False)\n",
    "r2b_file = uproot3.open(\"../NuMI_data/neutrinoselection_filt_run2b_beamoff.root\")['nuselection/NeutrinoSelectionFilter']\n",
    "full_run2b_df = r2b_file.pandas.df(['run', 'sub'], flatten=False)\n",
    "\n",
    "print(\"run2a beamon length: \" + str(len(full_run2a_df)))\n",
    "print(\"run2b beamon length: \" + str(len(full_run2b_df)))\n",
    "\n",
    "all_run2a_runs = list(set(np.array(full_run2a_df['run'])))\n",
    "all_run2b_runs = list(set(np.array(full_run2b_df['run'])))\n",
    "\n",
    "print(\"run2a beamoff all runs: \" + str(len(all_run2a_runs)))\n",
    "print(\"run2b beamoff all runs: \" + str(len(all_run2b_runs)))\n",
    "\n",
    "run2a_filtered = Filter_df_runs(full_run2a_df, all_run2a_runs)\n",
    "run2b_filtered = Filter_df_runs(full_run2b_df, all_run2b_runs)\n",
    "\n",
    "print(\"run2a beamon length: \" + str(len(run2a_filtered)))\n",
    "print(\"run2b beamon length: \" + str(len(run2b_filtered)))\n",
    "\n",
    "run2a_runs, run2a_subruns = Return_runs_subruns(run2a_filtered)\n",
    "run2b_runs, run2b_subruns = Return_runs_subruns(run2b_filtered)\n",
    "\n",
    "print(\"run2a\")\n",
    "print(len(run2a_runs), len(run2a_subruns))\n",
    "print(\"run2b\")\n",
    "print(len(run2b_runs), len(run2b_subruns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41cf53ff-e064-464e-a1eb-1aee11ab12b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Save_runs_subruns_as_txt(run2a_runs, run2a_subruns, \"../NuMI_data/FULL_beamoff_run2a_run_sub.txt\")\n",
    "Save_runs_subruns_as_txt(run2b_runs, run2b_subruns, \"../NuMI_data/FULL_beamoff_run2b_run_sub.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7dacddf-685c-4f36-9541-c0448247aea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185419 185419\n",
      "104922 104922\n"
     ]
    }
   ],
   "source": [
    "run2a_file = uproot3.open(\"../NuMI_data/neutrinoselection_filt_run2a_beamoff.root\")['nuselection/NeutrinoSelectionFilter']\n",
    "run2b_file = uproot3.open(\"../NuMI_data/neutrinoselection_filt_run2b_beamoff.root\")['nuselection/NeutrinoSelectionFilter']\n",
    "\n",
    "run2a_df = run2a_file.pandas.df(['run', 'sub', 'evt'], flatten=False)\n",
    "run2b_df = run2b_file.pandas.df(['run', 'sub', 'evt'], flatten=False)\n",
    "\n",
    "run2a_filtered = Filter_df_runs(run2a_df, runs_in_goodruns_2a)\n",
    "run2b_filtered = Filter_df_runs(run2b_df, runs_in_goodruns_2b)\n",
    "\n",
    "run2a_runs, run2a_subruns = Return_runs_subruns(run2a_filtered)\n",
    "run2b_runs, run2b_subruns = Return_runs_subruns(run2b_filtered)\n",
    "\n",
    "print(len(run2a_runs), len(run2a_subruns))\n",
    "print(len(run2b_runs), len(run2b_subruns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b7153a8f-0379-4d9b-9cb0-1b1f4ef6a109",
   "metadata": {},
   "outputs": [],
   "source": [
    "Save_runs_subruns_as_txt(run2a_runs, run2a_subruns, \"../NuMI_data/beamoff_run2a_run_sub.txt\")\n",
    "Save_runs_subruns_as_txt(run2b_runs, run2b_subruns, \"../NuMI_data/beamoff_run2b_run_sub.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c151459b-d31e-4d70-b4c8-560cefec8b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_locs = Functions.Get_all_sample_locs(Params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "837dac2d-21d4-46de-8fb1-32e8323c5ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../NuMI_data/neutrinoselection_filt_run2a_beamon.root\n"
     ]
    }
   ],
   "source": [
    "root_file_loc = file_locs[\"beamgood\"]\n",
    "print(root_file_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "282157e7-5a72-4328-85c4-5e200630f7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../NuMI_data/run2_goodruns.txt\"  \n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    values = [int(line.strip()) for line in file]\n",
    "    \n",
    "root_file = uproot3.open(root_file_loc)['nuselection/NeutrinoSelectionFilter']\n",
    "\n",
    "df_file = root_file.pandas.df(['run', 'sub', 'evt'], flatten=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "895e5d2c-4574-4e2d-8d21-e38964472190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runs in run2a file is 479\n",
      "runs in goodrun list: 453\n",
      "runs NOT in goodrun list: 26\n"
     ]
    }
   ],
   "source": [
    "unique_values = list(set(values))\n",
    "unique_file_subruns = list(set(np.array(df_file['run'])))\n",
    "\n",
    "runs_in_goodruns = []\n",
    "runs_not_in_goodruns = []\n",
    "\n",
    "for run in unique_file_subruns:\n",
    "    if run in unique_values: runs_in_goodruns.append(run)\n",
    "    if run not in unique_values: runs_not_in_goodruns.append(run)\n",
    "    \n",
    "print(\"Total runs in run2a file is \" + str(len(unique_file_subruns)))\n",
    "print(\"runs in goodrun list: \" + str(len(runs_in_goodruns)))\n",
    "print(\"runs NOT in goodrun list: \" + str(len(runs_not_in_goodruns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88ee3660-2fce-4cc4-a99a-873fcefe2f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../NuMI_data/run2_goodruns.txt\"  \n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    values = [int(line.strip()) for line in file]\n",
    "    \n",
    "root_file = uproot3.open(\"../NuMI_data/neutrinoselection_filt_run2b_beamon.root\")['nuselection/NeutrinoSelectionFilter']\n",
    "\n",
    "df_file = root_file.pandas.df(['run', 'sub', 'evt'], flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a7c285f-ed77-426d-ba9f-68155896d678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runs in file is \n",
      "runs in goodrun list: 453\n",
      "runs NOT in goodrun list: 26\n"
     ]
    }
   ],
   "source": [
    "unique_values = list(set(values))\n",
    "unique_file_subruns = list(set(np.array(df_file['run'])))\n",
    "\n",
    "runs_in_goodruns = []\n",
    "runs_not_in_goodruns = []\n",
    "\n",
    "for run in unique_file_subruns:\n",
    "    if run in unique_values: runs_in_goodruns.append(run)\n",
    "    if run not in unique_values: runs_not_in_goodruns.append(run)\n",
    "    \n",
    "print(\"Total runs in run2b file is \")\n",
    "print(\"runs in goodrun list: \" + str(len(runs_in_goodruns)))\n",
    "print(\"runs NOT in goodrun list: \" + str(len(runs_not_in_goodruns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ac905b-8750-4d3c-8e18-58877a2bc887",
   "metadata": {},
   "source": [
    "## End of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360cb25b-5dec-4cd3-b733-bf28d6f4bb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Params[\"variables_MC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e6110f-cd17-47da-9da9-87599220c582",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'nuselection'\n",
    "main_tree = 'NeutrinoSelectionFilter'\n",
    "loc_pkls = \"pkl_files/\"+Params[\"Run\"]+\"/current_files/\"+Params[\"variables_string\"]+\"/\"\n",
    "\n",
    "if (Params[\"Load_DetVars\"] == True) and (Params[\"Only_keep_common_DetVar_evs\"] == True):\n",
    "    df_rse_list = []\n",
    "    print(\"Loading only run, subrun, event numbers\" + \"\\n\")\n",
    "    for sample in samples: #Looping over all samples, should make a function for this.\n",
    "        if sample in Constants.Detector_variations: #Checks if it is an overlay Detector Variation sample\n",
    "            print(f\"Loading overlay {sample} \"+Params[\"Run\"]+\" with uproot\")\n",
    "            NuMI_MC_overlay = uproot3.open(\"../NuMI_MC/DetVars/neutrinoselection_filt_\"+Params[\"Run\"]+f\"_overlay_{sample}.root\")[root_dir+\"/\"+main_tree]\n",
    "            df_overlay = NuMI_MC_overlay.pandas.df(['run','sub','evt'], flatten=Params[\"FLATTEN\"])\n",
    "            file = df_overlay\n",
    "            Functions.make_unique_ev_id(file) #This creates \"rse_id\" branch\n",
    "            new_overlay = file.copy()\n",
    "            df_rse_list.append(new_overlay)\n",
    "\n",
    "    common_evs = Functions.make_common_evs_df(df_rse_list)\n",
    "    \n",
    "elif (Params[\"Load_Signal_DetVars\"] == True) and (Params[\"Only_keep_common_DetVar_evs\"] == True): #WRONG\n",
    "    common_evs_dict = {}\n",
    "    print(\"Loading only run, subrun, event numbers\" + \"\\n\")\n",
    "    if Params[\"Run\"] == \"run1\": HNL_samples = [150]\n",
    "    if Params[\"Run\"] == \"run3\": HNL_samples = [2, 10, 20, 50, 100]\n",
    "    for HNL_mass in HNL_samples: #Currently don't have 150MeV detvar samples for run3\n",
    "        df_rse_list = []\n",
    "        for DetVar in Constants.Detector_variations: #Looping over all samples, should make a function for this.\n",
    "            #print(f\"Loading overlay {sample} \"+Params[\"Run\"]+\" with uproot\")\n",
    "            NuMI_MC_signal = uproot3.open(\"../NuMI_signal/KDAR_dump/sfnues/DetVars/\"+f\"{HNL_mass}_{DetVar}_\"+Params[\"Run\"]+\".root\")[root_dir+\"/\"+main_tree]\n",
    "            df_signal = NuMI_MC_signal.pandas.df(['run','sub','evt'], flatten=Params[\"FLATTEN\"])\n",
    "            file = df_signal\n",
    "            Functions.make_unique_ev_id(file) #This creates \"rse_id\" branch\n",
    "            new_signal = file.copy()\n",
    "            df_rse_list.append(new_signal)\n",
    "\n",
    "        common_evs = Functions.make_common_evs_df(df_rse_list)\n",
    "        common_evs_dict[HNL_mass] = common_evs\n",
    "        \n",
    "elif (Params[\"Load_pi0_signal_DetVars\"] == True) and (Params[\"Only_keep_common_DetVar_evs\"] == True): #WRONG\n",
    "    common_evs_dict = {}\n",
    "    print(\"Loading only run, subrun, event numbers\" + \"\\n\")\n",
    "    if Params[\"Run\"] == \"run1\": HNL_samples = []\n",
    "    if Params[\"Run\"] == \"run3\": HNL_samples = [150,180,200,220,240,245]\n",
    "    for HNL_mass in HNL_samples: #Currently don't have 150MeV detvar samples for run3\n",
    "        print(HNL_mass)\n",
    "        df_rse_list = []\n",
    "        for DetVar in Constants.Detector_variations: #Looping over all samples, should make a function for this.\n",
    "            #print(f\"Loading overlay {sample} \"+Params[\"Run\"]+\" with uproot\")\n",
    "            NuMI_MC_signal = uproot3.open(\"../NuMI_signal/KDAR_dump/sfnues/pi0/DetVars/\"+f\"{HNL_mass}_{DetVar}_\"+Params[\"Run\"]+\".root\")[root_dir+\"/\"+main_tree]\n",
    "            df_signal = NuMI_MC_signal.pandas.df(['run','sub','evt'], flatten=Params[\"FLATTEN\"])\n",
    "            file = df_signal\n",
    "            Functions.make_unique_ev_id(file) #This creates \"rse_id\" branch\n",
    "            new_signal = file.copy()\n",
    "            df_rse_list.append(new_signal)\n",
    "\n",
    "        common_evs = Functions.make_common_evs_df(df_rse_list)\n",
    "        common_evs_dict[HNL_mass] = common_evs\n",
    "else: common_evs = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57978fb1-26d1-4303-b051-eb7fe4921765",
   "metadata": {},
   "source": [
    "## Making new variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8204d9ac-fca4-4fe5-bda9-14e4d2dbaea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_first_new_variables(df): #Only for variables which can be directly made from the ntuple variables with no manipulation/selection\n",
    "    df['subcluster'] = df['shrsubclusters0'] + df['shrsubclusters1'] + df['shrsubclusters2']\n",
    "    df['trkfit'] = df['shr_tkfit_npointsvalid'] / df['shr_tkfit_npoints']\n",
    "    #Something like shr_tkfit_distance\n",
    "    return df.copy\n",
    "\n",
    "#Works, but takes a while, ignored objects with huge negative numbers for the positions.\n",
    "def Make_fiducial_vars(df):\n",
    "    print(len(df))\n",
    "    n_pfps = df[\"n_pfps\"].groupby(level=\"entry\").apply(max)\n",
    "    df_placeholder = df.query(\"trk_sce_start_x_v>-1e4\").copy()\n",
    "    print(len(df_placeholder))\n",
    "    min_x=df_placeholder[[\"trk_sce_start_x_v\",\"trk_sce_end_x_v\"]].min(axis=1).groupby(level=\"entry\").apply(min)\n",
    "    max_x=df_placeholder[[\"trk_sce_start_x_v\",\"trk_sce_end_x_v\"]].max(axis=1).groupby(level=\"entry\").apply(max)\n",
    "    \n",
    "    min_y=df_placeholder[[\"trk_sce_start_y_v\",\"trk_sce_end_y_v\"]].min(axis=1).groupby(level=\"entry\").apply(min)\n",
    "    max_y=df_placeholder[[\"trk_sce_start_y_v\",\"trk_sce_end_y_v\"]].max(axis=1).groupby(level=\"entry\").apply(max)\n",
    "    \n",
    "    min_z=df_placeholder[[\"trk_sce_start_z_v\",\"trk_sce_end_z_v\"]].min(axis=1).groupby(level=\"entry\").apply(min)\n",
    "    max_z=df_placeholder[[\"trk_sce_start_z_v\",\"trk_sce_end_z_v\"]].max(axis=1).groupby(level=\"entry\").apply(max)\n",
    "    \n",
    "    del df_placeholder\n",
    "    \n",
    "    df2 = df.copy()\n",
    "    \n",
    "    df2[\"min_x\"]=np.array(np.repeat(min_x, np.array(n_pfps)))\n",
    "    df2[\"max_x\"]=np.array(np.repeat(max_x, np.array(n_pfps)))\n",
    "    df2[\"min_y\"]=np.array(np.repeat(min_y, np.array(n_pfps)))\n",
    "    df2[\"max_y\"]=np.array(np.repeat(max_y, np.array(n_pfps)))\n",
    "    df2[\"min_z\"]=np.array(np.repeat(min_z, np.array(n_pfps)))\n",
    "    df2[\"max_z\"]=np.array(np.repeat(max_z, np.array(n_pfps)))\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd79c64d-6189-4a86-b3d3-285da3f0e560",
   "metadata": {},
   "source": [
    "# Reading in and pickling files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636f0e78-fe3f-4708-87e5-fb65afe11b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ((Params[\"Load_Signal_DetVars\"] == True)or(Params[\"Load_pi0_signal_DetVars\"] == True)) and (Params[\"Only_keep_common_DetVar_evs\"] == True):\n",
    "    Functions.Load_and_pkl_samples(samples, sample_loc, loc_pkls, common_evs_dict, Params, save_str=\"_FINAL\")\n",
    "else:\n",
    "    Functions.Load_and_pkl_samples(samples, sample_loc, loc_pkls, common_evs, Params, save_str=\"_FINAL\") #Remove \"_New_gen\" str for data\n",
    "print(\"Done!\")\n",
    "\n",
    "# New_load_and_pkl(samples, sample_loc, loc_pkls, common_evs, Params, save_str=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70777aa6-7404-444c-a57f-c269c6f87dac",
   "metadata": {},
   "source": [
    "# Finished code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bd9a0a-a821-46a6-944f-2450e56a9520",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
