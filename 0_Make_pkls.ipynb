{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ab81f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "import os,sys,string, time\n",
    "from array import array\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import uproot\n",
    "import pandas as pd\n",
    "from platform import python_version\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import uproot3\n",
    "import math\n",
    "from matplotlib.patches import Rectangle\n",
    "import pickle\n",
    "import functools\n",
    "from importlib import reload\n",
    "\n",
    "import Utilities.Plotter as PT\n",
    "import Utilities.Constants as Constants\n",
    "import Utilities.Variables_list as Variables\n",
    "import Utilities.Functions as Functions\n",
    "from Utilities.ipython_exit import exit\n",
    "\n",
    "print ('Success')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796f7c44",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "This notebook takes the input .root file ntuples and creates .pkl files that are used for the rest of the analysis chain.<br> \n",
    "These .pkl files are much smaller and easier to deal with in python.<br> \n",
    "Which samples will be made into .pkls are defined by the Params dictionary.<br>\n",
    "This notebook will need to be run at least twice to create all necessary files for the analysis chain; once for \"run1\" and once for \"run3\". Always check the names of the samples that are printed and ensure they are what you want to save."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec8c084-e0ee-4f9a-9a99-c25ee62304d9",
   "metadata": {},
   "source": [
    "# Setting which samples to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3bfdae0-160d-4f43-bc28-aa18b62013f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading these run1 samples: \n",
      "['overlay', 'dirtoverlay', 'beamoff', 'beamgood', '2_ee', '10_ee', '20_ee', '50_ee', '100_ee', '150_ee']\n",
      "Saving these variables: \n",
      "['run', 'sub', 'evt', 'nslice', 'n_pfps', 'n_tracks', 'n_showers', 'swtrig_pre', 'swtrig_post', 'trk_sce_start_x_v', 'trk_sce_start_y_v', 'trk_sce_start_z_v', 'trk_sce_end_x_v', 'trk_sce_end_y_v', 'trk_sce_end_z_v', 'shr_theta_v', 'shr_phi_v', 'shr_px_v', 'shr_py_v', 'shr_pz_v', 'shrclusdir0', 'shrclusdir1', 'shrclusdir2', 'shr_energy_tot', 'trk_theta_v', 'trk_phi_v', 'trk_dir_x_v', 'trk_dir_y_v', 'trk_dir_z_v', 'trk_energy', 'trk_energy_hits_tot', 'trk_energy_tot', 'trk_score_v', 'trk_calo_energy_u_v', 'trk_end_x_v', 'trk_chipr_best', 'pfnplanehits_U', 'pfnplanehits_V', 'pfnplanehits_Y', 'NeutrinoEnergy2', 'SliceCaloEnergy2', 'nu_flashmatch_score', 'contained_sps_ratio', 'flash_time', 'contained_fraction', 'trk_score', 'crtveto', 'shr_tkfit_dedx_U', 'shr_tkfit_dedx_V', 'shr_tkfit_dedx_Y', 'shr_tkfit_dedx_max', 'shr_tkfit_2cm_dedx_Y', 'shr_chipr', 'trk_bragg_p', 'trk_bragg_p_v', 'trk_chipr', 'subcluster', 'shr_moliere_avg_v', 'shrmoliereavg', 'topological_score', 'weightSplineTimesTune', 'ppfx_cv', 'npi0']\n"
     ]
    }
   ],
   "source": [
    "Params = {\"Run\":\"run1\", #The run number, so far either \"run1\" or \"run3\"\n",
    "          \"Load_lepton_signal\":True, #Just e+e- samples, Majorana\n",
    "          \"Load_pi0_signal\":False, #Just pi0 samples, Majorana\n",
    "          \"Load_lepton_dirac\":False, #Just e+e-, Dirac\n",
    "          \"Load_pi0_dirac\":False, #Just pi0, Dirac\n",
    "          \"Load_standard_bkgs\":True, #Backgrounds, 'overlay', 'dirtoverlay' and 'beamoff'\n",
    "          \"Load_data\":True, #'beamgood' sample\n",
    "          \"Load_DetVars\":False, #overlay Detector variations\n",
    "          \"Load_Signal_DetVars\":False, #e+e- Detector variation samples\n",
    "          \"Load_pi0_signal_DetVars\":False, #pi0 Detector variation samples\n",
    "          \"Only_keep_common_DetVar_evs\":True, #For DetVar samples, only keep events common between samples\n",
    "          \"FLATTEN\":True, #Have one row per reconstructed object in the dataframe, if True this will effectively make the nslice cut.\n",
    "          \"only_presel\":False, #Create small files containing only variables necessary for pre-selection, for making pre-selection plots\n",
    "          \"Load_truth_vars\":False, #Load the \"mc_\" type variables for signal\n",
    "          \"Load_single_file\":False, #This will override everything else, put the desired file in the \"single_file\" line\n",
    "          \"single_file\":'beamgood'} \n",
    "\n",
    "Params, samples = Functions.new_create_sample_list(Params)\n",
    "sample_locs_new = Functions.Get_all_sample_locs(Params)\n",
    "\n",
    "print(\"Saving these variables: \\n\" + str(Params[\"variables_MC\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5103bfa1-5b16-484c-bfc0-fda62c2b7524",
   "metadata": {},
   "source": [
    "## Loading and pickling files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68fb0d30-19a9-4a11-b11e-21bfb393be26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling run1 overlay file\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m common_evs \u001b[38;5;241m=\u001b[39m Functions\u001b[38;5;241m.\u001b[39mMake_common_evs(samples, sample_locs_new, Params)\n\u001b[1;32m      2\u001b[0m loc_pkls \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpkl_files/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mParams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/current_files/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mParams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariables_string\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mFunctions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNew_load_and_pkl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_locs_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc_pkls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommon_evs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mParams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_full_Finished\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HNL/ee_decays/Utilities/Functions.py:414\u001b[0m, in \u001b[0;36mNew_load_and_pkl\u001b[0;34m(samples, sample_loc, loc_pkls, common_evs, Params, save_str)\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPickling \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mParams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    413\u001b[0m     filename \u001b[38;5;241m=\u001b[39m get_pkl_savename(sample, loc_pkls, Params)\n\u001b[0;32m--> 414\u001b[0m     \u001b[43mfinal_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43msave_str\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m(final_file)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished all!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Virtual_envs/HNL_ana/lib/python3.11/site-packages/pandas/core/generic.py:2955\u001b[0m, in \u001b[0;36mNDFrame.to_pickle\u001b[0;34m(self, path, compression, protocol, storage_options)\u001b[0m\n\u001b[1;32m   2903\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2904\u001b[0m \u001b[38;5;124;03mPickle (serialize) object to file.\u001b[39;00m\n\u001b[1;32m   2905\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2951\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[1;32m   2952\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpickle\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_pickle\n\u001b[0;32m-> 2955\u001b[0m \u001b[43mto_pickle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2956\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2961\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Virtual_envs/HNL_ana/lib/python3.11/site-packages/pandas/io/pickle.py:103\u001b[0m, in \u001b[0;36mto_pickle\u001b[0;34m(obj, filepath_or_buffer, compression, protocol, storage_options)\u001b[0m\n\u001b[1;32m     93\u001b[0m     protocol \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mHIGHEST_PROTOCOL\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m     96\u001b[0m     filepath_or_buffer,\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;66;03m# letting pickle write directly to the buffer is more memory-efficient\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "common_evs = Functions.Make_common_evs(samples, sample_locs_new, Params)\n",
    "loc_pkls = \"pkl_files/\"+Params[\"Run\"]+\"/current_files/\"+Params[\"variables_string\"]+\"/\"\n",
    "\n",
    "Functions.New_load_and_pkl(samples, sample_locs_new, loc_pkls, common_evs, Params, save_str=\"_full_Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ac905b-8750-4d3c-8e18-58877a2bc887",
   "metadata": {},
   "source": [
    "## End of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360cb25b-5dec-4cd3-b733-bf28d6f4bb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Params[\"variables_MC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e6110f-cd17-47da-9da9-87599220c582",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'nuselection'\n",
    "main_tree = 'NeutrinoSelectionFilter'\n",
    "loc_pkls = \"pkl_files/\"+Params[\"Run\"]+\"/current_files/\"+Params[\"variables_string\"]+\"/\"\n",
    "\n",
    "if (Params[\"Load_DetVars\"] == True) and (Params[\"Only_keep_common_DetVar_evs\"] == True):\n",
    "    df_rse_list = []\n",
    "    print(\"Loading only run, subrun, event numbers\" + \"\\n\")\n",
    "    for sample in samples: #Looping over all samples, should make a function for this.\n",
    "        if sample in Constants.Detector_variations: #Checks if it is an overlay Detector Variation sample\n",
    "            print(f\"Loading overlay {sample} \"+Params[\"Run\"]+\" with uproot\")\n",
    "            NuMI_MC_overlay = uproot3.open(\"../NuMI_MC/DetVars/neutrinoselection_filt_\"+Params[\"Run\"]+f\"_overlay_{sample}.root\")[root_dir+\"/\"+main_tree]\n",
    "            df_overlay = NuMI_MC_overlay.pandas.df(['run','sub','evt'], flatten=Params[\"FLATTEN\"])\n",
    "            file = df_overlay\n",
    "            Functions.make_unique_ev_id(file) #This creates \"rse_id\" branch\n",
    "            new_overlay = file.copy()\n",
    "            df_rse_list.append(new_overlay)\n",
    "\n",
    "    common_evs = Functions.make_common_evs_df(df_rse_list)\n",
    "    \n",
    "elif (Params[\"Load_Signal_DetVars\"] == True) and (Params[\"Only_keep_common_DetVar_evs\"] == True): #WRONG\n",
    "    common_evs_dict = {}\n",
    "    print(\"Loading only run, subrun, event numbers\" + \"\\n\")\n",
    "    if Params[\"Run\"] == \"run1\": HNL_samples = [150]\n",
    "    if Params[\"Run\"] == \"run3\": HNL_samples = [2, 10, 20, 50, 100]\n",
    "    for HNL_mass in HNL_samples: #Currently don't have 150MeV detvar samples for run3\n",
    "        df_rse_list = []\n",
    "        for DetVar in Constants.Detector_variations: #Looping over all samples, should make a function for this.\n",
    "            #print(f\"Loading overlay {sample} \"+Params[\"Run\"]+\" with uproot\")\n",
    "            NuMI_MC_signal = uproot3.open(\"../NuMI_signal/KDAR_dump/sfnues/DetVars/\"+f\"{HNL_mass}_{DetVar}_\"+Params[\"Run\"]+\".root\")[root_dir+\"/\"+main_tree]\n",
    "            df_signal = NuMI_MC_signal.pandas.df(['run','sub','evt'], flatten=Params[\"FLATTEN\"])\n",
    "            file = df_signal\n",
    "            Functions.make_unique_ev_id(file) #This creates \"rse_id\" branch\n",
    "            new_signal = file.copy()\n",
    "            df_rse_list.append(new_signal)\n",
    "\n",
    "        common_evs = Functions.make_common_evs_df(df_rse_list)\n",
    "        common_evs_dict[HNL_mass] = common_evs\n",
    "        \n",
    "elif (Params[\"Load_pi0_signal_DetVars\"] == True) and (Params[\"Only_keep_common_DetVar_evs\"] == True): #WRONG\n",
    "    common_evs_dict = {}\n",
    "    print(\"Loading only run, subrun, event numbers\" + \"\\n\")\n",
    "    if Params[\"Run\"] == \"run1\": HNL_samples = []\n",
    "    if Params[\"Run\"] == \"run3\": HNL_samples = [150,180,200,220,240,245]\n",
    "    for HNL_mass in HNL_samples: #Currently don't have 150MeV detvar samples for run3\n",
    "        print(HNL_mass)\n",
    "        df_rse_list = []\n",
    "        for DetVar in Constants.Detector_variations: #Looping over all samples, should make a function for this.\n",
    "            #print(f\"Loading overlay {sample} \"+Params[\"Run\"]+\" with uproot\")\n",
    "            NuMI_MC_signal = uproot3.open(\"../NuMI_signal/KDAR_dump/sfnues/pi0/DetVars/\"+f\"{HNL_mass}_{DetVar}_\"+Params[\"Run\"]+\".root\")[root_dir+\"/\"+main_tree]\n",
    "            df_signal = NuMI_MC_signal.pandas.df(['run','sub','evt'], flatten=Params[\"FLATTEN\"])\n",
    "            file = df_signal\n",
    "            Functions.make_unique_ev_id(file) #This creates \"rse_id\" branch\n",
    "            new_signal = file.copy()\n",
    "            df_rse_list.append(new_signal)\n",
    "\n",
    "        common_evs = Functions.make_common_evs_df(df_rse_list)\n",
    "        common_evs_dict[HNL_mass] = common_evs\n",
    "else: common_evs = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57978fb1-26d1-4303-b051-eb7fe4921765",
   "metadata": {},
   "source": [
    "## Making new variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8204d9ac-fca4-4fe5-bda9-14e4d2dbaea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_first_new_variables(df): #Only for variables which can be directly made from the ntuple variables with no manipulation/selection\n",
    "    df['subcluster'] = df['shrsubclusters0'] + df['shrsubclusters1'] + df['shrsubclusters2']\n",
    "    df['trkfit'] = df['shr_tkfit_npointsvalid'] / df['shr_tkfit_npoints']\n",
    "    #Something like shr_tkfit_distance\n",
    "    return df.copy\n",
    "\n",
    "#Works, but takes a while, ignored objects with huge negative numbers for the positions.\n",
    "def Make_fiducial_vars(df):\n",
    "    print(len(df))\n",
    "    n_pfps = df[\"n_pfps\"].groupby(level=\"entry\").apply(max)\n",
    "    df_placeholder = df.query(\"trk_sce_start_x_v>-1e4\").copy()\n",
    "    print(len(df_placeholder))\n",
    "    min_x=df_placeholder[[\"trk_sce_start_x_v\",\"trk_sce_end_x_v\"]].min(axis=1).groupby(level=\"entry\").apply(min)\n",
    "    max_x=df_placeholder[[\"trk_sce_start_x_v\",\"trk_sce_end_x_v\"]].max(axis=1).groupby(level=\"entry\").apply(max)\n",
    "    \n",
    "    min_y=df_placeholder[[\"trk_sce_start_y_v\",\"trk_sce_end_y_v\"]].min(axis=1).groupby(level=\"entry\").apply(min)\n",
    "    max_y=df_placeholder[[\"trk_sce_start_y_v\",\"trk_sce_end_y_v\"]].max(axis=1).groupby(level=\"entry\").apply(max)\n",
    "    \n",
    "    min_z=df_placeholder[[\"trk_sce_start_z_v\",\"trk_sce_end_z_v\"]].min(axis=1).groupby(level=\"entry\").apply(min)\n",
    "    max_z=df_placeholder[[\"trk_sce_start_z_v\",\"trk_sce_end_z_v\"]].max(axis=1).groupby(level=\"entry\").apply(max)\n",
    "    \n",
    "    del df_placeholder\n",
    "    \n",
    "    df2 = df.copy()\n",
    "    \n",
    "    df2[\"min_x\"]=np.array(np.repeat(min_x, np.array(n_pfps)))\n",
    "    df2[\"max_x\"]=np.array(np.repeat(max_x, np.array(n_pfps)))\n",
    "    df2[\"min_y\"]=np.array(np.repeat(min_y, np.array(n_pfps)))\n",
    "    df2[\"max_y\"]=np.array(np.repeat(max_y, np.array(n_pfps)))\n",
    "    df2[\"min_z\"]=np.array(np.repeat(min_z, np.array(n_pfps)))\n",
    "    df2[\"max_z\"]=np.array(np.repeat(max_z, np.array(n_pfps)))\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd79c64d-6189-4a86-b3d3-285da3f0e560",
   "metadata": {},
   "source": [
    "# Reading in and pickling files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636f0e78-fe3f-4708-87e5-fb65afe11b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ((Params[\"Load_Signal_DetVars\"] == True)or(Params[\"Load_pi0_signal_DetVars\"] == True)) and (Params[\"Only_keep_common_DetVar_evs\"] == True):\n",
    "    Functions.Load_and_pkl_samples(samples, sample_loc, loc_pkls, common_evs_dict, Params, save_str=\"_FINAL\")\n",
    "else:\n",
    "    Functions.Load_and_pkl_samples(samples, sample_loc, loc_pkls, common_evs, Params, save_str=\"_FINAL\") #Remove \"_New_gen\" str for data\n",
    "print(\"Done!\")\n",
    "\n",
    "# New_load_and_pkl(samples, sample_loc, loc_pkls, common_evs, Params, save_str=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70777aa6-7404-444c-a57f-c269c6f87dac",
   "metadata": {},
   "source": [
    "# Finished code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bd9a0a-a821-46a6-944f-2450e56a9520",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
