{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab81f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,string, time\n",
    "from array import array\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import uproot\n",
    "import pandas as pd\n",
    "from platform import python_version\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import uproot3\n",
    "import math\n",
    "from matplotlib.patches import Rectangle\n",
    "import pickle\n",
    "import functools\n",
    "from importlib import reload\n",
    "\n",
    "import Utilities.Plotter as PT\n",
    "import Utilities.Constants as Constants\n",
    "import Utilities.Variables_list as Variables\n",
    "import Utilities.Functions as Functions\n",
    "from Utilities.ipython_exit import exit\n",
    "\n",
    "print ('Success')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec8c084-e0ee-4f9a-9a99-c25ee62304d9",
   "metadata": {},
   "source": [
    "# Setting which samples to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bfdae0-160d-4f43-bc28-aa18b62013f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Params = {\"Run\":\"run2b\", #The run number, so far either \"run1\" or \"run3\"\n",
    "          \"Load_lepton_signal\":False, #Just e+e- samples, Majorana\n",
    "          \"Load_pi0_signal\":False, #Just pi0 samples, Majorana\n",
    "          \"Load_lepton_dirac\":False, #Just e+e-, Dirac\n",
    "          \"Load_pi0_dirac\":False, #Just pi0, Dirac\n",
    "          \"Load_standard_bkgs\":True, #Backgrounds, 'overlay', 'dirtoverlay' and 'beamoff'\n",
    "          \"Load_data\":True, #'beamgood' sample\n",
    "          \"Load_DetVars\":False, #overlay Detector variations\n",
    "          \"Load_Signal_DetVars\":False, #e+e- Detector variation samples\n",
    "          \"Load_pi0_signal_DetVars\":False, #pi0 Detector variation samples\n",
    "          \"Only_keep_common_DetVar_evs\":True, #For DetVar samples, only keep events common between samples\n",
    "          \"FLATTEN\":True, #Have one row per reconstructed object in the dataframe\n",
    "          \"only_presel\":False, #Create small files containing only variables necessary for pre-selection, for making pre-selection plots\n",
    "          \"Load_truth_vars\":False, #Load the \"mc_\" type variables for signal\n",
    "          \"Load_single_file\":False, #This will override everything else, put the desired file in the \"single_file\" line\n",
    "          \"single_file\":'beamgood'} \n",
    "\n",
    "Params, samples = Functions.new_create_sample_list(Params)\n",
    "sample_locs_new = Functions.Get_all_sample_locs(Params)\n",
    "\n",
    "print(\"Saving these variables: \\n\" + str(Params[\"variables_MC\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5103bfa1-5b16-484c-bfc0-fda62c2b7524",
   "metadata": {},
   "source": [
    "## Loading and pickling files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fb0d30-19a9-4a11-b11e-21bfb393be26",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_evs = Functions.Make_common_evs(samples, sample_locs_new, Params)\n",
    "loc_pkls = \"pkl_files/\"+Params[\"Run\"]+\"/current_files/\"+Params[\"variables_string\"]+\"/\"\n",
    "\n",
    "Functions.New_load_and_pkl(samples, sample_locs_new, loc_pkls, common_evs, Params, save_str=\"_full_Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0818c17-cb48-4246-9dbf-aac4ab8c2188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions.New_load_and_pkl([\"beamoff\",\"beamgood\"], sample_locs_new, loc_pkls, common_evs, Params, save_str=\"_full_Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f4c729-3cd1-4a22-b794-8af44dfddf07",
   "metadata": {},
   "source": [
    "## Looking for run2a beamoff issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d546ff5c-3a6f-4298-99b1-2b983a2c7317",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_dict = Functions.Get_all_sample_locs(Params)\n",
    "\n",
    "run2a_beamoff = uproot3.open(loc_dict[\"beamoff\"])['nuselection/NeutrinoSelectionFilter']\n",
    "\n",
    "df_file = run2a_beamoff.pandas.df([\"n_pfps\"]+ Variables.Fiducial_variables + Variables.event_vars, flatten=Params[\"FLATTEN\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601c9e66-6c39-4283-8f07-cc2b9e577ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Remove_fiducial_problem_row(df):\n",
    "    \"\"\"\n",
    "    Pass dataframe with n_pfps and \\\"trk_sce_start_x_v\\\",\\\"trk_sce_end_x_v\\\".\n",
    "    Returns a dataframe with rows removed which cause issues with fiducial var creation.\n",
    "    \"\"\"\n",
    "    n_pfps = df[\"n_pfps\"].groupby(level=\"entry\").apply(max)\n",
    "    df_placeholder = df.query(\"trk_sce_start_x_v>-1e4\").copy()\n",
    "    \n",
    "    min_x=df_placeholder[[\"trk_sce_start_x_v\",\"trk_sce_end_x_v\"]].min(axis=1).groupby(level=\"entry\").apply(min)\n",
    "    \n",
    "    n_pfps_entries = n_pfps.index\n",
    "    min_x_entries = min_x.index\n",
    "    \n",
    "    problem_indices = []\n",
    "    for index in n_pfps_entries:\n",
    "        if index not in min_x_entries: problem_indices.append(index)\n",
    "        \n",
    "    if len(problem_indices) < 1:\n",
    "        print(\"No problem rows\")\n",
    "        return df\n",
    "    \n",
    "    for index in problem_indices:\n",
    "        cleaned = df.drop(labels=374939, axis=0)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fcd5de-07e7-4424-aadf-2b9bf889b780",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df2 = Remove_fiducial_problem_row(df_file)\n",
    "\n",
    "fid_df2= Functions.Make_fiducial_vars(cleaned_df2)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4444e0c-ebfb-402e-8682-c8a37d2eb3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file = run2a_beamoff.pandas.df([\"n_pfps\"]+ Variables.Fiducial_variables + Variables.event_vars, flatten=Params[\"FLATTEN\"])\n",
    "\n",
    "df_file=Functions.make_unique_ev_id(df_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cad274b-16e2-4dd6-b9d9-bb45330204dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd01f8f2-fb0f-4c3d-a2e9-12da67123718",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pfps = df_file[\"n_pfps\"].groupby(level=\"entry\").apply(max) #OLD way, gave an error with one sample\n",
    "df_placeholder = df_file.query(\"trk_sce_start_x_v>-1e4\").copy()\n",
    "\n",
    "min_x=df_placeholder[[\"trk_sce_start_x_v\",\"trk_sce_end_x_v\"]].min(axis=1).groupby(level=\"entry\").apply(min)\n",
    "max_x=df_placeholder[[\"trk_sce_start_x_v\",\"trk_sce_end_x_v\"]].max(axis=1).groupby(level=\"entry\").apply(max)\n",
    "min_y=df_placeholder[[\"trk_sce_start_y_v\",\"trk_sce_end_y_v\"]].min(axis=1).groupby(level=\"entry\").apply(min)\n",
    "max_y=df_placeholder[[\"trk_sce_start_y_v\",\"trk_sce_end_y_v\"]].max(axis=1).groupby(level=\"entry\").apply(max)\n",
    "min_z=df_placeholder[[\"trk_sce_start_z_v\",\"trk_sce_end_z_v\"]].min(axis=1).groupby(level=\"entry\").apply(min)\n",
    "max_z=df_placeholder[[\"trk_sce_start_z_v\",\"trk_sce_end_z_v\"]].max(axis=1).groupby(level=\"entry\").apply(max)\n",
    "\n",
    "del df_placeholder\n",
    "df2 = df_file.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b5c800-e0da-48dd-b6bd-eea0e92511bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ba3c27-224b-40a4-bf23-60aff122e794",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(min_x), len(max_x), len(min_y), len(max_y), len(min_z), len(max_z))\n",
    "print(len(n_pfps))\n",
    "print(len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59c1536-7078-45da-af00-a75cafff3538",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pfps_entries = n_pfps.index\n",
    "\n",
    "min_x_entries = min_x.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028b4284-ec51-43dc-b19f-328e4e214f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in n_pfps_entries:\n",
    "    if index not in min_x_entries: print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2faa69-892e-4cde-a08a-89a3a0cef384",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_pfps[374939])\n",
    "\n",
    "full_df_entries = df2.index\n",
    "\n",
    "print(full_df_entries.get_level_values(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a36212-0c84-4317-b621-89da5135f2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[[374939]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ed1520-7b93-4f6d-8af2-1648ad01481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = df2.drop(labels=374939, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a290ae-6016-4fd8-beea-390bc0b6e88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282157e7-5a72-4328-85c4-5e200630f7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"min_x\"]=np.array(np.repeat(min_x, np.array(n_pfps)))\n",
    "df2[\"max_x\"]=np.array(np.repeat(max_x, np.array(n_pfps)))\n",
    "df2[\"min_y\"]=np.array(np.repeat(min_y, np.array(n_pfps)))\n",
    "df2[\"max_y\"]=np.array(np.repeat(max_y, np.array(n_pfps)))\n",
    "df2[\"min_z\"]=np.array(np.repeat(min_z, np.array(n_pfps)))\n",
    "df2[\"max_z\"]=np.array(np.repeat(max_z, np.array(n_pfps)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ac905b-8750-4d3c-8e18-58877a2bc887",
   "metadata": {},
   "source": [
    "## End of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360cb25b-5dec-4cd3-b733-bf28d6f4bb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Params[\"variables_MC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e6110f-cd17-47da-9da9-87599220c582",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'nuselection'\n",
    "main_tree = 'NeutrinoSelectionFilter'\n",
    "loc_pkls = \"pkl_files/\"+Params[\"Run\"]+\"/current_files/\"+Params[\"variables_string\"]+\"/\"\n",
    "\n",
    "if (Params[\"Load_DetVars\"] == True) and (Params[\"Only_keep_common_DetVar_evs\"] == True):\n",
    "    df_rse_list = []\n",
    "    print(\"Loading only run, subrun, event numbers\" + \"\\n\")\n",
    "    for sample in samples: #Looping over all samples, should make a function for this.\n",
    "        if sample in Constants.Detector_variations: #Checks if it is an overlay Detector Variation sample\n",
    "            print(f\"Loading overlay {sample} \"+Params[\"Run\"]+\" with uproot\")\n",
    "            NuMI_MC_overlay = uproot3.open(\"../NuMI_MC/DetVars/neutrinoselection_filt_\"+Params[\"Run\"]+f\"_overlay_{sample}.root\")[root_dir+\"/\"+main_tree]\n",
    "            df_overlay = NuMI_MC_overlay.pandas.df(['run','sub','evt'], flatten=Params[\"FLATTEN\"])\n",
    "            file = df_overlay\n",
    "            Functions.make_unique_ev_id(file) #This creates \"rse_id\" branch\n",
    "            new_overlay = file.copy()\n",
    "            df_rse_list.append(new_overlay)\n",
    "\n",
    "    common_evs = Functions.make_common_evs_df(df_rse_list)\n",
    "    \n",
    "elif (Params[\"Load_Signal_DetVars\"] == True) and (Params[\"Only_keep_common_DetVar_evs\"] == True): #WRONG\n",
    "    common_evs_dict = {}\n",
    "    print(\"Loading only run, subrun, event numbers\" + \"\\n\")\n",
    "    if Params[\"Run\"] == \"run1\": HNL_samples = [150]\n",
    "    if Params[\"Run\"] == \"run3\": HNL_samples = [2, 10, 20, 50, 100]\n",
    "    for HNL_mass in HNL_samples: #Currently don't have 150MeV detvar samples for run3\n",
    "        df_rse_list = []\n",
    "        for DetVar in Constants.Detector_variations: #Looping over all samples, should make a function for this.\n",
    "            #print(f\"Loading overlay {sample} \"+Params[\"Run\"]+\" with uproot\")\n",
    "            NuMI_MC_signal = uproot3.open(\"../NuMI_signal/KDAR_dump/sfnues/DetVars/\"+f\"{HNL_mass}_{DetVar}_\"+Params[\"Run\"]+\".root\")[root_dir+\"/\"+main_tree]\n",
    "            df_signal = NuMI_MC_signal.pandas.df(['run','sub','evt'], flatten=Params[\"FLATTEN\"])\n",
    "            file = df_signal\n",
    "            Functions.make_unique_ev_id(file) #This creates \"rse_id\" branch\n",
    "            new_signal = file.copy()\n",
    "            df_rse_list.append(new_signal)\n",
    "\n",
    "        common_evs = Functions.make_common_evs_df(df_rse_list)\n",
    "        common_evs_dict[HNL_mass] = common_evs\n",
    "        \n",
    "elif (Params[\"Load_pi0_signal_DetVars\"] == True) and (Params[\"Only_keep_common_DetVar_evs\"] == True): #WRONG\n",
    "    common_evs_dict = {}\n",
    "    print(\"Loading only run, subrun, event numbers\" + \"\\n\")\n",
    "    if Params[\"Run\"] == \"run1\": HNL_samples = []\n",
    "    if Params[\"Run\"] == \"run3\": HNL_samples = [150,180,200,220,240,245]\n",
    "    for HNL_mass in HNL_samples: #Currently don't have 150MeV detvar samples for run3\n",
    "        print(HNL_mass)\n",
    "        df_rse_list = []\n",
    "        for DetVar in Constants.Detector_variations: #Looping over all samples, should make a function for this.\n",
    "            #print(f\"Loading overlay {sample} \"+Params[\"Run\"]+\" with uproot\")\n",
    "            NuMI_MC_signal = uproot3.open(\"../NuMI_signal/KDAR_dump/sfnues/pi0/DetVars/\"+f\"{HNL_mass}_{DetVar}_\"+Params[\"Run\"]+\".root\")[root_dir+\"/\"+main_tree]\n",
    "            df_signal = NuMI_MC_signal.pandas.df(['run','sub','evt'], flatten=Params[\"FLATTEN\"])\n",
    "            file = df_signal\n",
    "            Functions.make_unique_ev_id(file) #This creates \"rse_id\" branch\n",
    "            new_signal = file.copy()\n",
    "            df_rse_list.append(new_signal)\n",
    "\n",
    "        common_evs = Functions.make_common_evs_df(df_rse_list)\n",
    "        common_evs_dict[HNL_mass] = common_evs\n",
    "else: common_evs = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57978fb1-26d1-4303-b051-eb7fe4921765",
   "metadata": {},
   "source": [
    "## Making new variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8204d9ac-fca4-4fe5-bda9-14e4d2dbaea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_first_new_variables(df): #Only for variables which can be directly made from the ntuple variables with no manipulation/selection\n",
    "    df['subcluster'] = df['shrsubclusters0'] + df['shrsubclusters1'] + df['shrsubclusters2']\n",
    "    df['trkfit'] = df['shr_tkfit_npointsvalid'] / df['shr_tkfit_npoints']\n",
    "    #Something like shr_tkfit_distance\n",
    "    return df.copy\n",
    "\n",
    "#Works, but takes a while, ignored objects with huge negative numbers for the positions.\n",
    "def Make_fiducial_vars(df):\n",
    "    print(len(df))\n",
    "    n_pfps = df[\"n_pfps\"].groupby(level=\"entry\").apply(max)\n",
    "    df_placeholder = df.query(\"trk_sce_start_x_v>-1e4\").copy()\n",
    "    print(len(df_placeholder))\n",
    "    min_x=df_placeholder[[\"trk_sce_start_x_v\",\"trk_sce_end_x_v\"]].min(axis=1).groupby(level=\"entry\").apply(min)\n",
    "    max_x=df_placeholder[[\"trk_sce_start_x_v\",\"trk_sce_end_x_v\"]].max(axis=1).groupby(level=\"entry\").apply(max)\n",
    "    \n",
    "    min_y=df_placeholder[[\"trk_sce_start_y_v\",\"trk_sce_end_y_v\"]].min(axis=1).groupby(level=\"entry\").apply(min)\n",
    "    max_y=df_placeholder[[\"trk_sce_start_y_v\",\"trk_sce_end_y_v\"]].max(axis=1).groupby(level=\"entry\").apply(max)\n",
    "    \n",
    "    min_z=df_placeholder[[\"trk_sce_start_z_v\",\"trk_sce_end_z_v\"]].min(axis=1).groupby(level=\"entry\").apply(min)\n",
    "    max_z=df_placeholder[[\"trk_sce_start_z_v\",\"trk_sce_end_z_v\"]].max(axis=1).groupby(level=\"entry\").apply(max)\n",
    "    \n",
    "    del df_placeholder\n",
    "    \n",
    "    df2 = df.copy()\n",
    "    \n",
    "    df2[\"min_x\"]=np.array(np.repeat(min_x, np.array(n_pfps)))\n",
    "    df2[\"max_x\"]=np.array(np.repeat(max_x, np.array(n_pfps)))\n",
    "    df2[\"min_y\"]=np.array(np.repeat(min_y, np.array(n_pfps)))\n",
    "    df2[\"max_y\"]=np.array(np.repeat(max_y, np.array(n_pfps)))\n",
    "    df2[\"min_z\"]=np.array(np.repeat(min_z, np.array(n_pfps)))\n",
    "    df2[\"max_z\"]=np.array(np.repeat(max_z, np.array(n_pfps)))\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd79c64d-6189-4a86-b3d3-285da3f0e560",
   "metadata": {},
   "source": [
    "# Reading in and pickling files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636f0e78-fe3f-4708-87e5-fb65afe11b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ((Params[\"Load_Signal_DetVars\"] == True)or(Params[\"Load_pi0_signal_DetVars\"] == True)) and (Params[\"Only_keep_common_DetVar_evs\"] == True):\n",
    "    Functions.Load_and_pkl_samples(samples, sample_loc, loc_pkls, common_evs_dict, Params, save_str=\"_FINAL\")\n",
    "else:\n",
    "    Functions.Load_and_pkl_samples(samples, sample_loc, loc_pkls, common_evs, Params, save_str=\"_FINAL\") #Remove \"_New_gen\" str for data\n",
    "print(\"Done!\")\n",
    "\n",
    "# New_load_and_pkl(samples, sample_loc, loc_pkls, common_evs, Params, save_str=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70777aa6-7404-444c-a57f-c269c6f87dac",
   "metadata": {},
   "source": [
    "# Finished code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bd9a0a-a821-46a6-944f-2450e56a9520",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
