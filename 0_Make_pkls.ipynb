{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ab81f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.24/06\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "import os,sys,string, time\n",
    "import ROOT\n",
    "from math import *\n",
    "from ROOT import gPad, TTree, TObject, TFile, gDirectory, TH1D, TH2D, TH3D, TCanvas, gROOT, TGaxis, gStyle, TColor, TLegend, THStack, TChain, TLatex, TText, TCollection, kRed, kBlue\n",
    "from array import array\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import uproot\n",
    "import pandas as pd\n",
    "from root_pandas import read_root\n",
    "from platform import python_version\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import uproot3\n",
    "import math\n",
    "from matplotlib.patches import Rectangle\n",
    "import pickle\n",
    "import functools\n",
    "from importlib import reload\n",
    "\n",
    "import Utilities.Plotter as PT\n",
    "import Utilities.Constants as Constants\n",
    "import Utilities.Variables_list as Variables\n",
    "import Utilities.Functions as Functions\n",
    "from Utilities.ipython_exit import exit\n",
    "\n",
    "print ('Success')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec8c084-e0ee-4f9a-9a99-c25ee62304d9",
   "metadata": {},
   "source": [
    "# Setting which samples to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3bfdae0-160d-4f43-bc28-aa18b62013f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Params = {\"Run\":\"run3\", #The run number, so far either \"run1\" or \"run3\"\n",
    "          \"Load_single_file\":False, #This will override everything else, put the desired file in the \"single_file\" line\n",
    "          \"single_file\":'beamgood',\n",
    "          \"Load_lepton_signal\":False, #Just e+e- samples\n",
    "          \"Load_standard_bkgs\":False, #Backgrounds\n",
    "          \"Load_DetVars\":False,\n",
    "          \"Only_keep_common_DetVar_evs\":True, #For overlay only atm\n",
    "          \"Load_Signal_DetVars\":False,\n",
    "          \"Load_data\":False,\n",
    "          \"FLATTEN\":True, #Have one row per reconstructed object in the analysis dataframe\n",
    "          \"only_presel\":False,#Create small files containing only variables necessary for pre-selection, for making pre-selection plots\n",
    "          \"Load_truth_vars\":False, #Load the \"mc_\" type variables for signal\n",
    "          \"Load_pi0_signal\":False,\n",
    "          \"Load_pi0_signal_DetVars\":True,\n",
    "          \"Load_sys_vars\":False} #Load in the signal samples where the HNL decays to pi0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aa22359-c175-46a1-ace4-a3820bcbe7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading these run3 samples: \n",
      "['150_WireModX', '150_WireModYZ', '150_WireModThetaXZ', '150_WireModThetaYZ', '150_WireModdEdX', '150_LYDown', '150_LYRayleigh', '150_LYAttenuation', '150_SCE', '150_Recomb2', '150_CV', '180_WireModX', '180_WireModYZ', '180_WireModThetaXZ', '180_WireModThetaYZ', '180_WireModdEdX', '180_LYDown', '180_LYRayleigh', '180_LYAttenuation', '180_SCE', '180_Recomb2', '180_CV', '200_WireModX', '200_WireModYZ', '200_WireModThetaXZ', '200_WireModThetaYZ', '200_WireModdEdX', '200_LYDown', '200_LYRayleigh', '200_LYAttenuation', '200_SCE', '200_Recomb2', '200_CV', '220_WireModX', '220_WireModYZ', '220_WireModThetaXZ', '220_WireModThetaYZ', '220_WireModdEdX', '220_LYDown', '220_LYRayleigh', '220_LYAttenuation', '220_SCE', '220_Recomb2', '220_CV', '240_WireModX', '240_WireModYZ', '240_WireModThetaXZ', '240_WireModThetaYZ', '240_WireModdEdX', '240_LYDown', '240_LYRayleigh', '240_LYAttenuation', '240_SCE', '240_Recomb2', '240_CV', '245_WireModX', '245_WireModYZ', '245_WireModThetaXZ', '245_WireModThetaYZ', '245_WireModdEdX', '245_LYDown', '245_LYRayleigh', '245_LYAttenuation', '245_SCE', '245_Recomb2', '245_CV']\n"
     ]
    }
   ],
   "source": [
    "Params, samples = Functions.create_sample_list(Params)\n",
    "\n",
    "sample_loc = {\"overlay\":f'../NuMI_MC/SLIMMED_neutrinoselection_filt_'+Params[\"Run\"]+'_overlay.root',\n",
    "              \"dirtoverlay\":f'../NuMI_MC/neutrinoselection_filt_'+Params[\"Run\"]+'_dirt_overlay.root',\n",
    "              \"beamoff\":f'../NuMI_data/neutrinoselection_filt_'+Params[\"Run\"]+'_beamoff.root',\n",
    "              \"signal\":f'../NuMI_signal/KDAR_dump/sfnues/sfnues_KDAR_dump_',\n",
    "              \"pi0_signal\":f'../NuMI_signal/KDAR_dump/sfnues/pi0/sfnues_KDAR_dump_',\n",
    "              \"beamgood\":f'../NuMI_data/neutrinoselection_filt_'+Params[\"Run\"]+'_beamon_beamgood.root'}\n",
    "\n",
    "root_dir = 'nuselection'\n",
    "main_tree = 'NeutrinoSelectionFilter'\n",
    "loc_pkls = \"pkl_files/\"+Params[\"Run\"]+\"/current_files/\"+Params[\"variables_string\"]+\"/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "360cb25b-5dec-4cd3-b733-bf28d6f4bb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'sub', 'evt', 'nslice', 'n_pfps', 'n_tracks', 'n_showers', 'swtrig_pre', 'swtrig_post', 'trk_sce_start_x_v', 'trk_sce_start_y_v', 'trk_sce_start_z_v', 'trk_sce_end_x_v', 'trk_sce_end_y_v', 'trk_sce_end_z_v', 'shr_theta_v', 'shr_phi_v', 'shr_px_v', 'shr_py_v', 'shr_pz_v', 'shrclusdir0', 'shrclusdir1', 'shrclusdir2', 'shr_energy_tot', 'trk_theta_v', 'trk_phi_v', 'trk_dir_x_v', 'trk_dir_y_v', 'trk_dir_z_v', 'trk_energy', 'trk_energy_hits_tot', 'trk_energy_tot', 'trk_score_v', 'trk_calo_energy_u_v', 'trk_end_x_v', 'trk_chipr_best', 'pfnplanehits_U', 'pfnplanehits_V', 'pfnplanehits_Y', 'NeutrinoEnergy2', 'SliceCaloEnergy2', 'nu_flashmatch_score', 'contained_sps_ratio', 'flash_time', 'contained_fraction', 'trk_score', 'crtveto', 'weightSplineTimesTune', 'ppfx_cv', 'npi0']\n"
     ]
    }
   ],
   "source": [
    "print(Params[\"variables_MC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e55f9bc8-e9b6-416b-be2b-7a65655a5cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'sub', 'evt', 'nslice', 'n_pfps', 'n_tracks', 'n_showers', 'swtrig_pre', 'swtrig_post', 'trk_sce_start_x_v', 'trk_sce_start_y_v', 'trk_sce_start_z_v', 'trk_sce_end_x_v', 'trk_sce_end_y_v', 'trk_sce_end_z_v', 'shr_theta_v', 'shr_phi_v', 'shr_px_v', 'shr_py_v', 'shr_pz_v', 'shrclusdir0', 'shrclusdir1', 'shrclusdir2', 'shr_energy_tot', 'trk_theta_v', 'trk_phi_v', 'trk_dir_x_v', 'trk_dir_y_v', 'trk_dir_z_v', 'trk_energy', 'trk_energy_hits_tot', 'trk_energy_tot', 'trk_score_v', 'trk_calo_energy_u_v', 'trk_end_x_v', 'trk_chipr_best', 'pfnplanehits_U', 'pfnplanehits_V', 'pfnplanehits_Y', 'NeutrinoEnergy2', 'SliceCaloEnergy2', 'nu_flashmatch_score', 'contained_sps_ratio', 'flash_time', 'contained_fraction', 'trk_score', 'crtveto', 'weightSplineTimesTune', 'ppfx_cv', 'npi0']\n"
     ]
    }
   ],
   "source": [
    "if Params[\"Load_sys_vars\"] == True:\n",
    "    Params[\"variables_MC\"] += Variables.sys_vars\n",
    "    \n",
    "print(Params[\"variables_MC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3e6110f-cd17-47da-9da9-87599220c582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading only run, subrun, event numbers\n",
      "\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/HNL/ee_decays/Utilities/Functions.py:180: FutureWarning: Passing 'suffixes' which cause duplicate columns {'run_x', 'evt_x', 'sub_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  overlapping_df = functools.reduce(lambda left,right: pd.merge(left, right, on=['rse_id'], how='inner'), df_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length is of common events list is 9159\n",
      "180\n",
      "Length is of common events list is 8672\n",
      "200\n",
      "Length is of common events list is 0\n",
      "220\n",
      "Length is of common events list is 8732\n",
      "240\n",
      "Length is of common events list is 9323\n",
      "245\n",
      "Length is of common events list is 9010\n"
     ]
    }
   ],
   "source": [
    "if (Params[\"Load_DetVars\"] == True) and (Params[\"Only_keep_common_DetVar_evs\"] == True):\n",
    "    df_rse_list = []\n",
    "    print(\"Loading only run, subrun, event numbers\" + \"\\n\")\n",
    "    for sample in samples: #Looping over all samples, should make a function for this.\n",
    "        if sample in Constants.Detector_variations: #Checks if it is an overlay Detector Variation sample\n",
    "            print(f\"Loading overlay {sample} \"+Params[\"Run\"]+\" with uproot\")\n",
    "            NuMI_MC_overlay = uproot3.open(\"../NuMI_MC/DetVars/neutrinoselection_filt_\"+Params[\"Run\"]+f\"_overlay_{sample}.root\")[root_dir+\"/\"+main_tree]\n",
    "            df_overlay = NuMI_MC_overlay.pandas.df(['run','sub','evt'], flatten=Params[\"FLATTEN\"])\n",
    "            file = df_overlay\n",
    "            Functions.make_unique_ev_id(file) #This creates \"rse_id\" branch\n",
    "            new_overlay = file.copy()\n",
    "            df_rse_list.append(new_overlay)\n",
    "\n",
    "    common_evs = Functions.make_common_evs_df(df_rse_list)\n",
    "    \n",
    "elif (Params[\"Load_Signal_DetVars\"] == True) and (Params[\"Only_keep_common_DetVar_evs\"] == True): #WRONG\n",
    "    common_evs_dict = {}\n",
    "    print(\"Loading only run, subrun, event numbers\" + \"\\n\")\n",
    "    if Params[\"Run\"] == \"run1\": HNL_samples = [150]\n",
    "    if Params[\"Run\"] == \"run3\": HNL_samples = [2, 10, 20, 50, 100]\n",
    "    for HNL_mass in HNL_samples: #Currently don't have 150MeV detvar samples for run3\n",
    "        df_rse_list = []\n",
    "        for DetVar in Constants.Detector_variations: #Looping over all samples, should make a function for this.\n",
    "            #print(f\"Loading overlay {sample} \"+Params[\"Run\"]+\" with uproot\")\n",
    "            NuMI_MC_signal = uproot3.open(\"../NuMI_signal/KDAR_dump/sfnues/DetVars/\"+f\"{HNL_mass}_{DetVar}_\"+Params[\"Run\"]+\".root\")[root_dir+\"/\"+main_tree]\n",
    "            df_signal = NuMI_MC_signal.pandas.df(['run','sub','evt'], flatten=Params[\"FLATTEN\"])\n",
    "            file = df_signal\n",
    "            Functions.make_unique_ev_id(file) #This creates \"rse_id\" branch\n",
    "            new_signal = file.copy()\n",
    "            df_rse_list.append(new_signal)\n",
    "\n",
    "        common_evs = Functions.make_common_evs_df(df_rse_list)\n",
    "        common_evs_dict[HNL_mass] = common_evs\n",
    "        \n",
    "elif (Params[\"Load_pi0_signal_DetVars\"] == True) and (Params[\"Only_keep_common_DetVar_evs\"] == True): #WRONG\n",
    "    common_evs_dict = {}\n",
    "    print(\"Loading only run, subrun, event numbers\" + \"\\n\")\n",
    "    if Params[\"Run\"] == \"run1\": HNL_samples = []\n",
    "    if Params[\"Run\"] == \"run3\": HNL_samples = [150,180,200,220,240,245]\n",
    "    for HNL_mass in HNL_samples: #Currently don't have 150MeV detvar samples for run3\n",
    "        print(HNL_mass)\n",
    "        df_rse_list = []\n",
    "        for DetVar in Constants.Detector_variations: #Looping over all samples, should make a function for this.\n",
    "            #print(f\"Loading overlay {sample} \"+Params[\"Run\"]+\" with uproot\")\n",
    "            NuMI_MC_signal = uproot3.open(\"../NuMI_signal/KDAR_dump/sfnues/pi0/DetVars/\"+f\"{HNL_mass}_{DetVar}_\"+Params[\"Run\"]+\".root\")[root_dir+\"/\"+main_tree]\n",
    "            df_signal = NuMI_MC_signal.pandas.df(['run','sub','evt'], flatten=Params[\"FLATTEN\"])\n",
    "            file = df_signal\n",
    "            Functions.make_unique_ev_id(file) #This creates \"rse_id\" branch\n",
    "            new_signal = file.copy()\n",
    "            df_rse_list.append(new_signal)\n",
    "\n",
    "        common_evs = Functions.make_common_evs_df(df_rse_list)\n",
    "        common_evs_dict[HNL_mass] = common_evs\n",
    "else: common_evs = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57978fb1-26d1-4303-b051-eb7fe4921765",
   "metadata": {},
   "source": [
    "## Making new variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8204d9ac-fca4-4fe5-bda9-14e4d2dbaea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_first_new_variables(df): #Only for variables which can be directly made from the ntuple variables with no manipulation/selection\n",
    "    df['subcluster'] = df['shrsubclusters0'] + df['shrsubclusters1'] + df['shrsubclusters2']\n",
    "    df['trkfit'] = df['shr_tkfit_npointsvalid'] / df['shr_tkfit_npoints']\n",
    "    #Something like shr_tkfit_distance\n",
    "    return df.copy\n",
    "\n",
    "#Works, but takes a while, ignored objects with huge negative numbers for the positions.\n",
    "def Make_fiducial_vars(df):\n",
    "    print(len(df))\n",
    "    n_pfps = df[\"n_pfps\"].groupby(level=\"entry\").apply(max)\n",
    "    df_placeholder = df.query(\"trk_sce_start_x_v>-1e4\").copy()\n",
    "    print(len(df_placeholder))\n",
    "    min_x=df_placeholder[[\"trk_sce_start_x_v\",\"trk_sce_end_x_v\"]].min(axis=1).groupby(level=\"entry\").apply(min)\n",
    "    max_x=df_placeholder[[\"trk_sce_start_x_v\",\"trk_sce_end_x_v\"]].max(axis=1).groupby(level=\"entry\").apply(max)\n",
    "    \n",
    "    min_y=df_placeholder[[\"trk_sce_start_y_v\",\"trk_sce_end_y_v\"]].min(axis=1).groupby(level=\"entry\").apply(min)\n",
    "    max_y=df_placeholder[[\"trk_sce_start_y_v\",\"trk_sce_end_y_v\"]].max(axis=1).groupby(level=\"entry\").apply(max)\n",
    "    \n",
    "    min_z=df_placeholder[[\"trk_sce_start_z_v\",\"trk_sce_end_z_v\"]].min(axis=1).groupby(level=\"entry\").apply(min)\n",
    "    max_z=df_placeholder[[\"trk_sce_start_z_v\",\"trk_sce_end_z_v\"]].max(axis=1).groupby(level=\"entry\").apply(max)\n",
    "    \n",
    "    del df_placeholder\n",
    "    \n",
    "    df2 = df.copy()\n",
    "    \n",
    "    df2[\"min_x\"]=np.array(np.repeat(min_x, np.array(n_pfps)))\n",
    "    df2[\"max_x\"]=np.array(np.repeat(max_x, np.array(n_pfps)))\n",
    "    df2[\"min_y\"]=np.array(np.repeat(min_y, np.array(n_pfps)))\n",
    "    df2[\"max_y\"]=np.array(np.repeat(max_y, np.array(n_pfps)))\n",
    "    df2[\"min_z\"]=np.array(np.repeat(min_z, np.array(n_pfps)))\n",
    "    df2[\"max_z\"]=np.array(np.repeat(max_z, np.array(n_pfps)))\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd79c64d-6189-4a86-b3d3-285da3f0e560",
   "metadata": {},
   "source": [
    "# Reading in and pickling files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "636f0e78-fe3f-4708-87e5-fb65afe11b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "if ((Params[\"Load_Signal_DetVars\"] == True)or(Params[\"Load_pi0_signal_DetVars\"] == True)) and (Params[\"Only_keep_common_DetVar_evs\"] == True):\n",
    "    Functions.Load_and_pkl_samples(samples, sample_loc, loc_pkls, common_evs_dict, Params, save_str=\"_FINAL\")\n",
    "else:\n",
    "    Functions.Load_and_pkl_samples(samples, sample_loc, loc_pkls, common_evs, Params, save_str=\"_FINAL\") #Remove \"_New_gen\" str for data\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a93b77-2cf0-4c0b-ad59-03154f9e6777",
   "metadata": {},
   "source": [
    "## Testing Make_fiducial_vars error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93ece46-a651-42a2-80ec-c3dfa655bfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NuMI_MC_overlay=uproot3.open(f\"../NuMI_MC/DetVars/neutrinoselection_filt_\"+Params[\"Run\"]+f\"_overlay_WireModThetaXZ.root\")[Constants.root_dir+\"/\"+Constants.main_tree]\n",
    "df_overlay = NuMI_MC_overlay.pandas.df(Params[\"variables_MC\"], flatten=Params[\"FLATTEN\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66992ec9-5e1f-4ed7-a9e1-c395466e0005",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba15158-027a-4324-865b-f3a3729cffb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_pkls = \"pkl_files/\"+Params[\"Run\"]+\"/current_files/\"+Params[\"variables_string\"]+\"/\"\n",
    "file = pd.read_pickle(loc_pkls+f\"DetVars/overlay_run3_my_vars_WireModThetaXZ_flattened.pkl\")\n",
    "red_file = pd.read_pickle(loc_pkls+f\"DetVars/overlay_run3_my_vars_WireModThetaXZ_flattened_reduced_evs.pkl\")\n",
    "new_file = pd.read_pickle(loc_pkls+f\"DetVars/overlay_run3_my_vars_WireModThetaXZ_flattened_reduced_evs_FINAL.pkl\")\n",
    "\n",
    "print(len(file))\n",
    "print(len(red_file))\n",
    "print(len(new_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bfef0f-2b9e-408a-97f9-0f9ce8e7d904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = Functions.Make_fiducial_vars(df_overlay)\n",
    "n_pfps = df_overlay[\"n_pfps\"].groupby(level=\"entry\").apply(max)\n",
    "df_placeholder = df_overlay.query(\"trk_sce_start_x_v>-1e4\").copy()\n",
    "n_pfps_2 = df_placeholder[\"n_pfps\"].groupby(level=\"entry\").apply(max)\n",
    "print(\"Length df \" + str(len(df_overlay)))\n",
    "print(\"Length n_pfps \" + str(len(n_pfps)))\n",
    "print(\"Length n_pfps_2 \" + str(len(n_pfps_2)))\n",
    "print(\"Length placeholder \" + str(len(df_overlay)))\n",
    "\n",
    "min_x=df_placeholder[[\"trk_sce_start_x_v\",\"trk_sce_end_x_v\"]].min(axis=1).groupby(level=\"entry\").apply(min)\n",
    "max_x=df_placeholder[[\"trk_sce_start_x_v\",\"trk_sce_end_x_v\"]].max(axis=1).groupby(level=\"entry\").apply(max)\n",
    "min_y=df_placeholder[[\"trk_sce_start_y_v\",\"trk_sce_end_y_v\"]].min(axis=1).groupby(level=\"entry\").apply(min)\n",
    "print(\"Length min_x \" + str(len(min_x)))\n",
    "print(\"Length max_x \" + str(len(max_x)))\n",
    "print(\"Length min_y \" + str(len(min_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d734b282-be6c-4e3e-994d-6b56c386617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 65535\n",
    "n_pfps.head(20)\n",
    "pfp_ids = n_pfps.index.values\n",
    "min_x_ids = min_x.index.values\n",
    "\n",
    "for val in pfp_ids:\n",
    "    if val not in min_x_ids:\n",
    "        print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665a9cb2-92e6-4e24-a5b9-dd7082c070c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pfps.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0da1da5-c69f-47d3-9447-a14e11c009ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pfps[65535]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f61e7a-f7ad-4dc1-a28f-2682c0179493",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_overlay.loc[[65535]]\n",
    "test_placeholder = df_placeholder.loc[[65535]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b75ee2-8702-472c-98ea-42af2ef59786",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53955c6f-db58-4a9f-9069-82c905fc23c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['trk_sce_start_x_v']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70777aa6-7404-444c-a57f-c269c6f87dac",
   "metadata": {},
   "source": [
    "# Finished code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7d4558-5d0a-406f-a5f5-6431250fa3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "New_feature_list = ['shrclusdir2', 'n_tracks', 'trk_energy', 'shr_theta_v', 'contained_sps_ratio', 'trk_chipr_best', 'shr_px_v',\n",
    "                    'trk_end_x_v', 'n_pfps', 'pfnplanehits_V', 'pfnplanehits_U', 'trk_calo_energy_u_v', 'nu_flashmatch_score', 'trk_score_v',\n",
    "                    'NeutrinoEnergy2', 'shr_phi_v', 'pfnplanehits_Y', 'shr_pz_v', 'trk_theta_v', 'trk_phi_v', 'trk_energy_hits_tot',\n",
    "                    'trk_dir_z_v', 'SliceCaloEnergy2'] \n",
    "\n",
    "Preselection_vars = [\"nslice\",\"flash_time\",\"nu_flashmatch_score\",\"NeutrinoEnergy2\",\"contained_fraction\",\"trk_score\",\"trk_score_v\",\"n_pfps\"]\n",
    "\n",
    "non_duplicate_vars = []\n",
    "\n",
    "for var in Preselection_vars:\n",
    "    if var not in New_feature_list:\n",
    "        non_duplicate_vars.append(var)\n",
    "\n",
    "print(non_duplicate_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d63351-7d26-4550-8dce-6ce2815a6cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'nuselection'\n",
    "main_tree = 'NeutrinoSelectionFilter'\n",
    "loc_pkls = f\"pkl_files/{Run}/current_files/{variables_string}/\"\n",
    "\n",
    "for sample in samples: #Looping over all samples, should make a function for this.\n",
    "    if sample in Constants.Detector_variations: #Checks if it is an overlay Detector Variation sample\n",
    "        print(f\"Loading overlay {sample} {Run} with uproot\")\n",
    "        NuMI_MC_overlay = uproot3.open(f'../NuMI_MC/DetVars/neutrinoselection_filt_{Run}_overlay_{sample}.root')[root_dir+'/'+main_tree]\n",
    "        df_overlay = NuMI_MC_overlay.pandas.df(variables_MC, flatten=FLATTEN)\n",
    "        file = df_overlay\n",
    "        Functions.Edit_Weight_Tune(file)\n",
    "        Functions.MC_weight_branch(file)\n",
    "        Functions.make_unique_ev_id(file) #This creates \"rse_id\" branch\n",
    "        if Only_keep_common_DetVar_evs == True:\n",
    "            filtered = file.loc[(file['rse_id'].isin(common_evs['rse_id']))]\n",
    "            new_overlay = filtered.copy()\n",
    "            del(file)\n",
    "            del(filtered)\n",
    "        else:\n",
    "            new_overlay = file.copy()\n",
    "            del(file)\n",
    "        print(f\"Pickling {Run} overlay {sample} file\")\n",
    "        new_overlay.to_pickle(loc_pkls+f\"DetVars/overlay_{Run}_{variables_string}_{sample}_{Flat_state}_{Reduced_state}.pkl\")\n",
    "        del(new_overlay)\n",
    "    else: #Standard sample types\n",
    "        print(f\"Loading {sample} {Run} file with uproot\")\n",
    "        if Constants.sample_type[sample] == \"MC_signal\":\n",
    "            for HNL_mass in Constants.HNL_mass_samples:\n",
    "                uproot_file = uproot3.open(sample_loc[sample]+f'{HNL_mass}_Umu4_majorana_numi_{current}.root')[root_dir+'/'+main_tree]\n",
    "                df_signal = uproot_file.pandas.df(variables, flatten=FLATTEN)\n",
    "                file = df_signal\n",
    "                new_signal = file.copy()\n",
    "                del(file)\n",
    "                print(f\"Pickling {Run} {HNL_mass}MeV file\")\n",
    "                new_signal.to_pickle(loc_pkls+f\"signal_{HNL_mass}MeV_{Run}_{variables_string}_\"+Flat_state+\".pkl\")\n",
    "                del(new_signal)\n",
    "        else:\n",
    "            uproot_file = uproot3.open(sample_loc[sample])[root_dir+'/'+main_tree]\n",
    "            if Constants.sample_type[sample] == \"MC\":\n",
    "                df = uproot_file.pandas.df(variables_MC, flatten=FLATTEN)\n",
    "                file = df\n",
    "                Functions.Edit_Weight_Tune(file)\n",
    "                Functions.MC_weight_branch(file)\n",
    "            else:\n",
    "                df = uproot_file.pandas.df(variables, flatten=FLATTEN)\n",
    "                file = df\n",
    "            new_file = file.copy()\n",
    "            del(file)\n",
    "            print(f\"Pickling {Run} {sample} file\")\n",
    "            new_file.to_pickle(loc_pkls+f\"{sample}_{Run}_{variables_string}_\"+Flat_state+\".pkl\")\n",
    "            del(new_file)\n",
    "\n",
    "print(\"\\n\"+\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2e1b62-8645-4050-9f19-215bd3eacede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing loading reweighting branches\n",
    "sys_variables = Variables.sys_vars + Variables.event_vars + Variables.weight_related\n",
    "\n",
    "NuMI_MC_overlay = uproot3.open(loc_overlay_run1)[root_dir+'/'+main_tree]\n",
    "df_overlay = NuMI_MC_overlay.pandas.df(sys_variables, flatten=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e0568f-cb79-4674-9813-ad73fd773c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_from_pkl = pd.read_pickle(loc_pkls+\"overlay_run1_my_vars_flattened.pkl\")\n",
    "\n",
    "Preselection_efficiency_signal = [1.0]\n",
    "\n",
    "Preselection_with_list(overlay_from_pkl, Constants.Preselection_dict, Preselection_efficiency_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70324d4d-940e-4fd6-b046-2a464d5ec72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(overlay_from_pkl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1961b90-a667-4c17-814d-f8b9ff09a853",
   "metadata": {},
   "source": [
    "# Plotting Variables before preselection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc881b1-8578-4383-8a68-84dda5266f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "My_vars = Variables.First_pass_vars\n",
    "My_vars_MC = Variables.First_pass_vars_MC\n",
    "\n",
    "overlay_from_pkl = pd.read_pickle(loc_pkls+\"overlay_run1_my_vars1_flattened.pkl\")\n",
    "dirt_from_pkl = pd.read_pickle(loc_pkls+\"dirt_run1_my_vars1_flattened.pkl\")\n",
    "EXT_from_pkl = pd.read_pickle(loc_pkls+\"EXT_run1_my_vars1_flattened.pkl\")\n",
    "signal_from_pkl = pd.read_pickle(loc_pkls+f\"signal_100MeV_run1_my_vars1_flattened.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837d5b44-7f5f-4e66-9e90-ef52693eb0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {\"overlay\":overlay_from_pkl,\n",
    "           \"dirtoverlay\":dirt_from_pkl,\n",
    "           \"beamoff\":EXT_from_pkl,\n",
    "           \"signal\":signal_from_pkl}\n",
    "sample_norms = {\"overlay\":SF_overlay_run1,\n",
    "           \"dirtoverlay\":SF_dirt_run1,\n",
    "           \"beamoff\":SF_EXT_run1,\n",
    "           \"signal\":SF_signal_run1}\n",
    "\n",
    "PT.Plot_preselection_variable(\"n_pfps\", samples, sample_norms, xlabel=[],xlims=[1,8],bins=7,figsize=[8,8],HNLplotscale=10000000,logy=\"False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7ef9d7-7746-4137-9ac5-c2b7fa3aa38f",
   "metadata": {},
   "source": [
    "## Load in all branches for small number of events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3366238c-f1f4-4f58-b627-c36fa72f073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NuMI_MC_dirt_run1 = uproot3.open(loc_dirt_run1)[root_dir+'/'+main_tree]\n",
    "NuMI_EXT_run1 = uproot3.open(loc_EXT_run1)[root_dir+'/'+main_tree]\n",
    "#NuMI_beamgood_run1 = uproot3.open(loc_beamgood_run1)[root_dir+'/'+main_tree]\n",
    "Signal_run1 = uproot3.open(loc_signal_run1)[root_dir+'/'+main_tree]\n",
    "\n",
    "print(\"----MC OVERLAY BACKGROUND----\")\n",
    "print(\"Number of branches is \" + str(len(NuMI_MC_overlay_run1.keys()))) \n",
    "print(\"Number of events is \" + str(NuMI_MC_overlay_run1.numentries))\n",
    "print(\"----MC DIRT BACKGROUND----\")\n",
    "print(\"Number of branches is \" + str(len(NuMI_MC_dirt_run1.keys()))) \n",
    "print(\"Number of events is \" + str(NuMI_MC_dirt_run1.numentries))\n",
    "print(\"----EXT BACKGROUND----\")\n",
    "print(\"Number of branches is \" + str(len(NuMI_EXT_run1.keys()))) \n",
    "print(\"Number of events is \" + str(NuMI_EXT_run1.numentries))\n",
    "# print(\"----DATA----\")\n",
    "# print(\"Number of branches is \" + str(len(NuMI_beamgood_run1.keys()))) \n",
    "# print(\"Number of events is \" + str(NuMI_beamgood_run1.numentries))\n",
    "print(\"----SIGNAL----\")\n",
    "print(\"Number of branches is \" + str(len(Signal_run1.keys()))) \n",
    "print(\"Number of events is \" + str(Signal_run1.numentries))\n",
    "\n",
    "NumEvents = 10\n",
    "FLATTEN = False\n",
    "\n",
    "df_overlay_run1 = NuMI_MC_overlay_run1.pandas.df(\"*\", entrystop=NumEvents, flatten=FLATTEN)\n",
    "df_dirt_run1 = NuMI_MC_dirt_run1.pandas.df(\"*\", entrystop=NumEvents, flatten=FLATTEN)\n",
    "df_EXT_run1 = NuMI_EXT_run1.pandas.df(\"*\", entrystop=NumEvents, flatten=FLATTEN)\n",
    "df_signal_run1 = Signal_run1.pandas.df(\"*\", entrystop=NumEvents, flatten=FLATTEN)\n",
    "\n",
    "overlay_vars = df_overlay_run1.keys()\n",
    "dirt_vars = df_dirt_run1.keys()\n",
    "EXT_vars = df_EXT_run1.keys()\n",
    "signal_vars = df_signal_run1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dada42-73c8-4a7a-b440-984e3c61bb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in overlay_vars:\n",
    "#     print(i)\n",
    "    \n",
    "overlay_no_truth_vars = []\n",
    "    \n",
    "for j in overlay_vars:\n",
    "    if 'true' in j:\n",
    "        continue\n",
    "    if 'truth' in j:\n",
    "        continue\n",
    "    if 'mc_' in j:\n",
    "        continue\n",
    "    overlay_no_truth_vars.append(j)\n",
    "    #print(j)\n",
    "\n",
    "print(len(overlay_no_truth_vars))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2689b2-77d1-41cd-ac56-a176c0af2079",
   "metadata": {},
   "source": [
    "# Testing other ways of saving .pkls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3722fdf5-4465-4a9a-a945-43430ce04219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_common_evs_list(df_list): #Takes a list of dataframes\n",
    "    common_events = df_list[0]['rse_id'].to_list()\n",
    "    for df in df_list:\n",
    "        temp_rse_list = df['rse_id'].to_list()\n",
    "        for entry in common_events: #Looping over all events in the dataframe\n",
    "            if entry not in temp_rse_list:\n",
    "                common_events.remove(entry)\n",
    "        print(\"Done one\") \n",
    "    print(\"Number of common events is \" + str(len(common_events)))\n",
    "    return common_events\n",
    "\n",
    "def only_keep_evs_in_list(df, ev_list):\n",
    "    print(\"Length of dataframe is \" + str(len(df)))\n",
    "    if pd.Series(['rse_id']).isin(df.columns).all():\n",
    "        for entry in df.index: #Looping over all events in the dataframe\n",
    "            if df['rse_id'][entry] not in ev_list:\n",
    "                df.drop(entry)\n",
    "        print(\"Length after dropping events is \" + str(len(df)))\n",
    "    else:\n",
    "        print(\"Dataframe needs \\\"rse_id\\\" column.\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2cd767-4fba-4020-b4e6-a8e200d02f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run1_samples = [overlay_from_pkl, dirt_from_pkl, EXT_from_pkl, signal_from_pkl]\n",
    "# run1_sample_names = [\"df_overlay_run1\", \"df_dirt_run1\", \"df_EXT_run1\", \"df_signal_run1\"] #Better way to do this, dictionary?\n",
    "\n",
    "# loc_pkls = \"pkl_files/\"\n",
    "# i = 0\n",
    "\n",
    "# for sample in run1_samples:\n",
    "#     sample.to_pickle(loc_pkls+run1_sample_names[i]+\"_full.pkl\")\n",
    "#     i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa9d314-2e43-4346-a802-1096c4f2f0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flattened_overlay_from_pkl = pd.read_pickle(loc_pkls+\"overlay_run1_Aditya_vars_flattened.pkl\")\n",
    "\n",
    "# NumEvs_overlay_run1 = 914728 #Should have this saved somewhere, or perhaps accessed direcly from uproot? \n",
    "\n",
    "# print(flattened_overlay_from_pkl['nslice'])\n",
    "# print(flattened_overlay_from_pkl['nslice'][0])\n",
    "\n",
    "# number_evs_removed = 0\n",
    "# number_evs_kept = 0\n",
    "# for entry in range(NumEvs_overlay_run1):\n",
    "#     #if entry in flattened_overlay_from_pkl['nslice']:\n",
    "#     if entry in flattened_overlay_from_pkl.index:\n",
    "#         number_evs_kept += 1\n",
    "#     else:\n",
    "#         number_evs_removed += 1\n",
    "\n",
    "# print(\"Number of events kept is \" + str(number_evs_kept))\n",
    "# print(\"Number of events removed is \" + str(number_evs_removed))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be57b8d-f7f9-4194-be18-cbae304f988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fraction with nslice of 1 is 0.41223401929316694\n",
    "fraction_reco = number_evs_kept/(number_evs_kept+number_evs_removed)\n",
    "print(\"Fraction with nslice of 1 is \" + str(fraction_reco))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bd9a0a-a821-46a6-944f-2450e56a9520",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
