{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ab81f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.24/06\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "import os,sys,string, time\n",
    "import ROOT\n",
    "from math import *\n",
    "from ROOT import gPad, TTree, TObject, TFile, gDirectory, TH1D, TH2D, TH3D, TCanvas, gROOT, TGaxis, gStyle, TColor, TLegend, THStack, TChain, TLatex, TText, TCollection, kRed, kBlue\n",
    "from array import array\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import uproot\n",
    "import pandas as pd\n",
    "from root_pandas import read_root\n",
    "from platform import python_version\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import uproot3\n",
    "import math\n",
    "from matplotlib.patches import Rectangle\n",
    "import pickle\n",
    "import functools\n",
    "from importlib import reload\n",
    "\n",
    "import Utilities.Plotter as PT\n",
    "import Utilities.Constants as Constants\n",
    "import Utilities.Variables_list as Variables\n",
    "import Utilities.Functions as Functions\n",
    "from Utilities.ipython_exit import exit\n",
    "\n",
    "print ('Success')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec8c084-e0ee-4f9a-9a99-c25ee62304d9",
   "metadata": {},
   "source": [
    "# Setting which samples to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3bfdae0-160d-4f43-bc28-aa18b62013f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Params = {\"Run\":\"run3\", #The run number, so far either \"run1\" or \"run3\"\n",
    "          \"Load_single_file\":False, #This will override everything else, put the desired file in the \"single_file\" line\n",
    "          \"single_file\":'beamgood',\n",
    "          \"Load_lepton_signal\":False, #Just e+e- samples\n",
    "          \"Load_standard_bkgs\":False, #Backgrounds\n",
    "          \"Load_DetVars\":False,\n",
    "          \"Only_keep_common_DetVar_evs\":True, #For overlay only atm\n",
    "          \"Load_Signal_DetVars\":False,\n",
    "          \"Load_data\":False,\n",
    "          \"FLATTEN\":True, #Have one row per reconstructed object in the analysis dataframe\n",
    "          \"only_presel\":False,#Create small files containing only variables necessary for pre-selection, for making pre-selection plots\n",
    "          \"Load_truth_vars\":False, #Load the \"mc_\" type variables for signal\n",
    "          \"Load_pi0_signal\":False,\n",
    "          \"Load_pi0_signal_DetVars\":True,\n",
    "          \"Load_sys_vars\":False} #Load in the signal samples where the HNL decays to pi0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aa22359-c175-46a1-ace4-a3820bcbe7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading these run3 samples: \n",
      "['150_WireModX', '150_WireModYZ', '150_WireModThetaXZ', '150_WireModThetaYZ', '150_WireModdEdX', '150_LYDown', '150_LYRayleigh', '150_LYAttenuation', '150_SCE', '150_Recomb2', '150_CV', '180_WireModX', '180_WireModYZ', '180_WireModThetaXZ', '180_WireModThetaYZ', '180_WireModdEdX', '180_LYDown', '180_LYRayleigh', '180_LYAttenuation', '180_SCE', '180_Recomb2', '180_CV', '200_WireModX', '200_WireModYZ', '200_WireModThetaXZ', '200_WireModThetaYZ', '200_WireModdEdX', '200_LYDown', '200_LYRayleigh', '200_LYAttenuation', '200_SCE', '200_Recomb2', '200_CV', '220_WireModX', '220_WireModYZ', '220_WireModThetaXZ', '220_WireModThetaYZ', '220_WireModdEdX', '220_LYDown', '220_LYRayleigh', '220_LYAttenuation', '220_SCE', '220_Recomb2', '220_CV', '240_WireModX', '240_WireModYZ', '240_WireModThetaXZ', '240_WireModThetaYZ', '240_WireModdEdX', '240_LYDown', '240_LYRayleigh', '240_LYAttenuation', '240_SCE', '240_Recomb2', '240_CV', '245_WireModX', '245_WireModYZ', '245_WireModThetaXZ', '245_WireModThetaYZ', '245_WireModdEdX', '245_LYDown', '245_LYRayleigh', '245_LYAttenuation', '245_SCE', '245_Recomb2', '245_CV']\n"
     ]
    }
   ],
   "source": [
    "Params, samples = Functions.create_sample_list(Params)\n",
    "\n",
    "sample_loc = {\"overlay\":f'../NuMI_MC/SLIMMED_neutrinoselection_filt_'+Params[\"Run\"]+'_overlay.root',\n",
    "              \"dirtoverlay\":f'../NuMI_MC/neutrinoselection_filt_'+Params[\"Run\"]+'_dirt_overlay.root',\n",
    "              \"beamoff\":f'../NuMI_data/neutrinoselection_filt_'+Params[\"Run\"]+'_beamoff.root',\n",
    "              \"signal\":f'../NuMI_signal/KDAR_dump/sfnues/sfnues_KDAR_dump_',\n",
    "              \"pi0_signal\":f'../NuMI_signal/KDAR_dump/sfnues/pi0/sfnues_KDAR_dump_',\n",
    "              \"beamgood\":f'../NuMI_data/neutrinoselection_filt_'+Params[\"Run\"]+'_beamon_beamgood.root'}\n",
    "\n",
    "root_dir = 'nuselection'\n",
    "main_tree = 'NeutrinoSelectionFilter'\n",
    "loc_pkls = \"pkl_files/\"+Params[\"Run\"]+\"/current_files/\"+Params[\"variables_string\"]+\"/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "360cb25b-5dec-4cd3-b733-bf28d6f4bb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'sub', 'evt', 'nslice', 'n_pfps', 'n_tracks', 'n_showers', 'swtrig_pre', 'swtrig_post', 'trk_sce_start_x_v', 'trk_sce_start_y_v', 'trk_sce_start_z_v', 'trk_sce_end_x_v', 'trk_sce_end_y_v', 'trk_sce_end_z_v', 'shr_theta_v', 'shr_phi_v', 'shr_px_v', 'shr_py_v', 'shr_pz_v', 'shrclusdir0', 'shrclusdir1', 'shrclusdir2', 'shr_energy_tot', 'trk_theta_v', 'trk_phi_v', 'trk_dir_x_v', 'trk_dir_y_v', 'trk_dir_z_v', 'trk_energy', 'trk_energy_hits_tot', 'trk_energy_tot', 'trk_score_v', 'trk_calo_energy_u_v', 'trk_end_x_v', 'trk_chipr_best', 'pfnplanehits_U', 'pfnplanehits_V', 'pfnplanehits_Y', 'NeutrinoEnergy2', 'SliceCaloEnergy2', 'nu_flashmatch_score', 'contained_sps_ratio', 'flash_time', 'contained_fraction', 'trk_score', 'crtveto', 'weightSplineTimesTune', 'ppfx_cv', 'npi0']\n"
     ]
    }
   ],
   "source": [
    "print(Params[\"variables_MC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e55f9bc8-e9b6-416b-be2b-7a65655a5cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'sub', 'evt', 'nslice', 'n_pfps', 'n_tracks', 'n_showers', 'swtrig_pre', 'swtrig_post', 'trk_sce_start_x_v', 'trk_sce_start_y_v', 'trk_sce_start_z_v', 'trk_sce_end_x_v', 'trk_sce_end_y_v', 'trk_sce_end_z_v', 'shr_theta_v', 'shr_phi_v', 'shr_px_v', 'shr_py_v', 'shr_pz_v', 'shrclusdir0', 'shrclusdir1', 'shrclusdir2', 'shr_energy_tot', 'trk_theta_v', 'trk_phi_v', 'trk_dir_x_v', 'trk_dir_y_v', 'trk_dir_z_v', 'trk_energy', 'trk_energy_hits_tot', 'trk_energy_tot', 'trk_score_v', 'trk_calo_energy_u_v', 'trk_end_x_v', 'trk_chipr_best', 'pfnplanehits_U', 'pfnplanehits_V', 'pfnplanehits_Y', 'NeutrinoEnergy2', 'SliceCaloEnergy2', 'nu_flashmatch_score', 'contained_sps_ratio', 'flash_time', 'contained_fraction', 'trk_score', 'crtveto', 'weightSplineTimesTune', 'ppfx_cv', 'npi0']\n"
     ]
    }
   ],
   "source": [
    "if Params[\"Load_sys_vars\"] == True:\n",
    "    Params[\"variables_MC\"] += Variables.sys_vars\n",
    "    \n",
    "print(Params[\"variables_MC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3e6110f-cd17-47da-9da9-87599220c582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading only run, subrun, event numbers\n",
      "\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/HNL/ee_decays/Utilities/Functions.py:180: FutureWarning: Passing 'suffixes' which cause duplicate columns {'run_x', 'evt_x', 'sub_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  overlapping_df = functools.reduce(lambda left,right: pd.merge(left, right, on=['rse_id'], how='inner'), df_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length is of common events list is 9159\n",
      "180\n",
      "Length is of common events list is 8672\n",
      "200\n",
      "Length is of common events list is 0\n",
      "220\n",
      "Length is of common events list is 8732\n",
      "240\n",
      "Length is of common events list is 9323\n",
      "245\n",
      "Length is of common events list is 9010\n"
     ]
    }
   ],
   "source": [
    "if (Params[\"Load_DetVars\"] == True) and (Params[\"Only_keep_common_DetVar_evs\"] == True):\n",
    "    df_rse_list = []\n",
    "    print(\"Loading only run, subrun, event numbers\" + \"\\n\")\n",
    "    for sample in samples: #Looping over all samples, should make a function for this.\n",
    "        if sample in Constants.Detector_variations: #Checks if it is an overlay Detector Variation sample\n",
    "            print(f\"Loading overlay {sample} \"+Params[\"Run\"]+\" with uproot\")\n",
    "            NuMI_MC_overlay = uproot3.open(\"../NuMI_MC/DetVars/neutrinoselection_filt_\"+Params[\"Run\"]+f\"_overlay_{sample}.root\")[root_dir+\"/\"+main_tree]\n",
    "            df_overlay = NuMI_MC_overlay.pandas.df(['run','sub','evt'], flatten=Params[\"FLATTEN\"])\n",
    "            file = df_overlay\n",
    "            Functions.make_unique_ev_id(file) #This creates \"rse_id\" branch\n",
    "            new_overlay = file.copy()\n",
    "            df_rse_list.append(new_overlay)\n",
    "\n",
    "    common_evs = Functions.make_common_evs_df(df_rse_list)\n",
    "    \n",
    "elif (Params[\"Load_Signal_DetVars\"] == True) and (Params[\"Only_keep_common_DetVar_evs\"] == True): #WRONG\n",
    "    common_evs_dict = {}\n",
    "    print(\"Loading only run, subrun, event numbers\" + \"\\n\")\n",
    "    if Params[\"Run\"] == \"run1\": HNL_samples = [150]\n",
    "    if Params[\"Run\"] == \"run3\": HNL_samples = [2, 10, 20, 50, 100]\n",
    "    for HNL_mass in HNL_samples: #Currently don't have 150MeV detvar samples for run3\n",
    "        df_rse_list = []\n",
    "        for DetVar in Constants.Detector_variations: #Looping over all samples, should make a function for this.\n",
    "            #print(f\"Loading overlay {sample} \"+Params[\"Run\"]+\" with uproot\")\n",
    "            NuMI_MC_signal = uproot3.open(\"../NuMI_signal/KDAR_dump/sfnues/DetVars/\"+f\"{HNL_mass}_{DetVar}_\"+Params[\"Run\"]+\".root\")[root_dir+\"/\"+main_tree]\n",
    "            df_signal = NuMI_MC_signal.pandas.df(['run','sub','evt'], flatten=Params[\"FLATTEN\"])\n",
    "            file = df_signal\n",
    "            Functions.make_unique_ev_id(file) #This creates \"rse_id\" branch\n",
    "            new_signal = file.copy()\n",
    "            df_rse_list.append(new_signal)\n",
    "\n",
    "        common_evs = Functions.make_common_evs_df(df_rse_list)\n",
    "        common_evs_dict[HNL_mass] = common_evs\n",
    "        \n",
    "elif (Params[\"Load_pi0_signal_DetVars\"] == True) and (Params[\"Only_keep_common_DetVar_evs\"] == True): #WRONG\n",
    "    common_evs_dict = {}\n",
    "    print(\"Loading only run, subrun, event numbers\" + \"\\n\")\n",
    "    if Params[\"Run\"] == \"run1\": HNL_samples = []\n",
    "    if Params[\"Run\"] == \"run3\": HNL_samples = [150,180,200,220,240,245]\n",
    "    for HNL_mass in HNL_samples: #Currently don't have 150MeV detvar samples for run3\n",
    "        print(HNL_mass)\n",
    "        df_rse_list = []\n",
    "        for DetVar in Constants.Detector_variations: #Looping over all samples, should make a function for this.\n",
    "            #print(f\"Loading overlay {sample} \"+Params[\"Run\"]+\" with uproot\")\n",
    "            NuMI_MC_signal = uproot3.open(\"../NuMI_signal/KDAR_dump/sfnues/pi0/DetVars/\"+f\"{HNL_mass}_{DetVar}_\"+Params[\"Run\"]+\".root\")[root_dir+\"/\"+main_tree]\n",
    "            df_signal = NuMI_MC_signal.pandas.df(['run','sub','evt'], flatten=Params[\"FLATTEN\"])\n",
    "            file = df_signal\n",
    "            Functions.make_unique_ev_id(file) #This creates \"rse_id\" branch\n",
    "            new_signal = file.copy()\n",
    "            df_rse_list.append(new_signal)\n",
    "\n",
    "        common_evs = Functions.make_common_evs_df(df_rse_list)\n",
    "        common_evs_dict[HNL_mass] = common_evs\n",
    "else: common_evs = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57978fb1-26d1-4303-b051-eb7fe4921765",
   "metadata": {},
   "source": [
    "## Making new variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8204d9ac-fca4-4fe5-bda9-14e4d2dbaea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_first_new_variables(df): #Only for variables which can be directly made from the ntuple variables with no manipulation/selection\n",
    "    df['subcluster'] = df['shrsubclusters0'] + df['shrsubclusters1'] + df['shrsubclusters2']\n",
    "    df['trkfit'] = df['shr_tkfit_npointsvalid'] / df['shr_tkfit_npoints']\n",
    "    #Something like shr_tkfit_distance\n",
    "    return df.copy\n",
    "\n",
    "#Works, but takes a while, ignored objects with huge negative numbers for the positions.\n",
    "def Make_fiducial_vars(df):\n",
    "    print(len(df))\n",
    "    n_pfps = df[\"n_pfps\"].groupby(level=\"entry\").apply(max)\n",
    "    df_placeholder = df.query(\"trk_sce_start_x_v>-1e4\").copy()\n",
    "    print(len(df_placeholder))\n",
    "    min_x=df_placeholder[[\"trk_sce_start_x_v\",\"trk_sce_end_x_v\"]].min(axis=1).groupby(level=\"entry\").apply(min)\n",
    "    max_x=df_placeholder[[\"trk_sce_start_x_v\",\"trk_sce_end_x_v\"]].max(axis=1).groupby(level=\"entry\").apply(max)\n",
    "    \n",
    "    min_y=df_placeholder[[\"trk_sce_start_y_v\",\"trk_sce_end_y_v\"]].min(axis=1).groupby(level=\"entry\").apply(min)\n",
    "    max_y=df_placeholder[[\"trk_sce_start_y_v\",\"trk_sce_end_y_v\"]].max(axis=1).groupby(level=\"entry\").apply(max)\n",
    "    \n",
    "    min_z=df_placeholder[[\"trk_sce_start_z_v\",\"trk_sce_end_z_v\"]].min(axis=1).groupby(level=\"entry\").apply(min)\n",
    "    max_z=df_placeholder[[\"trk_sce_start_z_v\",\"trk_sce_end_z_v\"]].max(axis=1).groupby(level=\"entry\").apply(max)\n",
    "    \n",
    "    del df_placeholder\n",
    "    \n",
    "    df2 = df.copy()\n",
    "    \n",
    "    df2[\"min_x\"]=np.array(np.repeat(min_x, np.array(n_pfps)))\n",
    "    df2[\"max_x\"]=np.array(np.repeat(max_x, np.array(n_pfps)))\n",
    "    df2[\"min_y\"]=np.array(np.repeat(min_y, np.array(n_pfps)))\n",
    "    df2[\"max_y\"]=np.array(np.repeat(max_y, np.array(n_pfps)))\n",
    "    df2[\"min_z\"]=np.array(np.repeat(min_z, np.array(n_pfps)))\n",
    "    df2[\"max_z\"]=np.array(np.repeat(max_z, np.array(n_pfps)))\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd79c64d-6189-4a86-b3d3-285da3f0e560",
   "metadata": {},
   "source": [
    "# Reading in and pickling files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "636f0e78-fe3f-4708-87e5-fb65afe11b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "if ((Params[\"Load_Signal_DetVars\"] == True)or(Params[\"Load_pi0_signal_DetVars\"] == True)) and (Params[\"Only_keep_common_DetVar_evs\"] == True):\n",
    "    Functions.Load_and_pkl_samples(samples, sample_loc, loc_pkls, common_evs_dict, Params, save_str=\"_FINAL\")\n",
    "else:\n",
    "    Functions.Load_and_pkl_samples(samples, sample_loc, loc_pkls, common_evs, Params, save_str=\"_FINAL\") #Remove \"_New_gen\" str for data\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70777aa6-7404-444c-a57f-c269c6f87dac",
   "metadata": {},
   "source": [
    "# Finished code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bd9a0a-a821-46a6-944f-2450e56a9520",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
