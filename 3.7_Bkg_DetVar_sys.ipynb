{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16c7e147-47c2-4b05-b456-5c464284013d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.24/06\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "import os,sys,string, time\n",
    "import ROOT\n",
    "from math import *\n",
    "from ROOT import gPad, TTree, TObject, TFile, gDirectory, TH1D, TH2D, TH3D, TCanvas, gROOT, TGaxis, gStyle, TColor, TLegend, THStack, TChain, TLatex, TText, TCollection, kRed, kBlue\n",
    "from array import array\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import uproot\n",
    "import pandas as pd\n",
    "from root_pandas import read_root\n",
    "from platform import python_version\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import uproot3\n",
    "import math\n",
    "from matplotlib.patches import Rectangle\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from importlib import reload\n",
    "\n",
    "import Utilities.Plotter as PT\n",
    "import Utilities.Constants as Constants\n",
    "import Utilities.Variables_list as Variables\n",
    "import Utilities.Functions as Functions\n",
    "from Utilities.ipython_exit import exit\n",
    "\n",
    "print ('Success')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9adad48-5d27-48b2-841f-0ab680824d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading these run1 samples: \n",
      "['WireModX', 'WireModYZ', 'WireModThetaXZ', 'WireModThetaYZ', 'WireModdEdX', 'LYDown', 'LYRayleigh', 'LYAttenuation', 'SCE', 'Recomb2', 'CV']\n"
     ]
    }
   ],
   "source": [
    "Params = {\"Run\":\"run1\", #The run number, so far either \"run1\" or \"run3\"\n",
    "          \"Load_single_file\":False, #This will override everything else, put the desired file in the \"single_file\" line\n",
    "          \"single_file\":10,\n",
    "          \"Load_standard\":False, #bkgs\n",
    "          \"Load_lepton_signal\":False,\n",
    "          \"Load_pi0_signal\":False,\n",
    "          \"Load_DetVars\":True, #This is for overlay\n",
    "          \"Only_keep_common_DetVar_evs\":True,\n",
    "          \"Load_Signal_DetVars\":False, #Don't do here, but in seperate script\n",
    "          \"Load_data\":False,\n",
    "          \"FLATTEN\":True, #Have one row per reconstructed object in the analysis dataframe\n",
    "          \"only_presel\":False, #Create small files containing only variables necessary for pre-selection, for making pre-selection plots\n",
    "          \"EXT_in_training\":False,\n",
    "          \"Use_logit\":True,\n",
    "          \"nbins\":5} \n",
    "\n",
    "feature_names = Variables.First_pass_vars_for_BDT #All variables\n",
    "feature_names_MC = feature_names + [\"weight\"]\n",
    "loc_pkls = \"pkl_files/\"+Params[\"Run\"]+\"/current_files/my_vars/\"\n",
    "\n",
    "samples = Functions.create_test_samples_list(Params)\n",
    "\n",
    "if Params[\"Load_pi0_signal\"] == True:\n",
    "    pi0_sample_strings = [] #Unfortunately need to make, to discriminate lepton final states from pi0 final states for signal\n",
    "    for pi0_point in Constants.HNL_mass_pi0_samples:\n",
    "        pi0_sample_strings += [str(pi0_point)+\"_pi0\"]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff8c3a34-8be9-42cd-aa3b-4c425ea5aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_dict = {}\n",
    "for sample in samples:\n",
    "    if sample in Constants.Detector_variations: #Reading in an overlay DetVar sample\n",
    "        loc=loc_pkls+\"DetVars/\"+\"Preselected_overlay_\"+Params[\"Run\"]+\"_my_vars\"+f\"_{sample}_flattened_reduced_evs.pkl\"\n",
    "        sample_test_dict[sample] = pd.read_pickle(loc)\n",
    "    elif Params[\"Load_Signal_DetVars\"] == True:\n",
    "        loc=loc_pkls+\"Signal_DetVars/\"+\"Preselected_\"+Params[\"Run\"]+f\"_{sample}_reduced_evs.pkl\"\n",
    "        sample_test_dict[sample] = pd.read_pickle(loc)\n",
    "    elif Params[\"Load_pi0_signal\"] == True:\n",
    "        if sample == 'overlay':\n",
    "            sample_test_dict[sample] = pd.read_pickle(loc_pkls+\"BDT_Test_dfs/pi0_selection/Test_overlay_\"+Params[\"Run\"]+\".pkl\")\n",
    "        elif sample in pi0_sample_strings:\n",
    "            sample_test_dict[sample] = pd.read_pickle(loc_pkls+f\"BDT_Test_dfs/pi0_selection/Test_signal_{sample}_\"+Params[\"Run\"]+\".pkl\")\n",
    "        elif (sample == 'beamoff') and (Params[\"EXT_in_training\"] == True): #EXT only if extra EXT has been added\n",
    "            sample_test_dict[sample] = pd.read_pickle(loc_pkls+\"BDT_Test_dfs/pi0_selection/Test_beamoff_\"+Params[\"Run\"]+\".pkl\")\n",
    "        else: \n",
    "            sample_test_dict[sample] = pd.read_pickle(loc_pkls+f\"pi0_selection/Preselected_\"+Params[\"Run\"]+f\"_{sample}.pkl\")\n",
    "    else: #Standard sample types\n",
    "        if sample == 'overlay':\n",
    "            sample_test_dict[sample] = pd.read_pickle(loc_pkls+\"BDT_Test_dfs/Test_overlay_\"+Params[\"Run\"]+\"_my_vars_flattened_FINAL.pkl\")\n",
    "        elif (Params[\"Load_single_file\"] == True) and (isinstance(sample,int)):\n",
    "            sample_test_dict[sample] = pd.read_pickle(loc_pkls+f\"BDT_Test_dfs/Test_signal_{sample}_\"+Params[\"Run\"]+\"_my_vars_flattened_FINAL.pkl\")\n",
    "        elif sample in Constants.HNL_mass_samples:\n",
    "            sample_test_dict[sample] = pd.read_pickle(loc_pkls+f\"BDT_Test_dfs/Test_signal_{sample}_\"+Params[\"Run\"]+\"_my_vars_flattened_FINAL.pkl\")\n",
    "        elif (sample == 'beamoff') and (Params[\"EXT_in_training\"] == True): #EXT only if extra EXT has been added\n",
    "            sample_test_dict[sample] = pd.read_pickle(loc_pkls+\"BDT_Test_dfs/Test_beamoff_\"+Params[\"Run\"]+\"_my_vars_flattened_FINAL.pkl\")\n",
    "        else: \n",
    "            sample_test_dict[sample] = pd.read_pickle(loc_pkls+f\"Preselected_{sample}_\"+Params[\"Run\"]+\"_my_vars_flattened_FINAL.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "905d4822-e05f-4971-b4a9-8574a9506bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New_feature_list = ['shrclusdir2', 'n_tracks', 'trk_energy', 'shr_theta_v', 'contained_sps_ratio', 'trk_chipr_best', 'shr_px_v', 'trk_end_x_v', \n",
    "#              'n_pfps', 'pfnplanehits_V', 'pfnplanehits_U', 'trk_calo_energy_u_v', 'nu_flashmatch_score', 'trk_score_v', 'NeutrinoEnergy2', \n",
    "#              'shr_phi_v', 'pfnplanehits_Y', 'shr_pz_v', 'trk_theta_v', 'trk_phi_v', 'trk_energy_hits_tot', 'trk_dir_z_v', 'SliceCaloEnergy2']\n",
    "New_feature_list = ['shrclusdir2', 'n_tracks', 'trk_energy', 'shr_theta_v', 'contained_sps_ratio', 'shr_px_v',\n",
    "                    'trk_end_x_v', 'n_pfps', 'pfnplanehits_V', 'pfnplanehits_U', 'trk_calo_energy_u_v', 'trk_score_v',\n",
    "                    'NeutrinoEnergy2', 'shr_phi_v', 'pfnplanehits_Y', 'shr_pz_v', 'trk_theta_v', 'trk_phi_v',\n",
    "                    'trk_dir_z_v']\n",
    "# bdt_vars = feature_names\n",
    "bdt_vars = New_feature_list\n",
    "xgb_test_dict = {}\n",
    "\n",
    "BDT_name = \"_FINAL.json\"\n",
    "\n",
    "for sample in sample_test_dict:\n",
    "    xgb_test_dict[sample] = xgboost.DMatrix(sample_test_dict[sample][bdt_vars])\n",
    "    # print(\"Done \" + str(sample))\n",
    "    \n",
    "if Params[\"Load_single_file\"] == True:\n",
    "    HNL_mass = Params[\"single_file\"]\n",
    "    bdt = xgboost.Booster()\n",
    "    bdt.load_model(f\"bdts/\"+Params[\"Run\"]+f\"_{HNL_mass}MeV\" + BDT_name)\n",
    "    for sample in xgb_test_dict:\n",
    "        results = bdt.predict(xgb_test_dict[sample])\n",
    "        sample_test_dict[sample][f\"BDT_output_{HNL_mass}MeV\"] = results\n",
    "    \n",
    "elif Params[\"Load_pi0_signal\"] == False:\n",
    "    for HNL_mass in Constants.HNL_mass_samples:\n",
    "        bdt = xgboost.Booster()\n",
    "        # bdt.load_model(f\"bdts/\"+Params[\"Run\"]+f\"_{HNL_mass}_MeV_My_variables_flattened_highest_E_1.json\")\n",
    "        bdt.load_model(\"bdts/\"+Params[\"Run\"]+f\"_{HNL_mass}MeV\" + BDT_name)\n",
    "        for sample in xgb_test_dict:\n",
    "            results = bdt.predict(xgb_test_dict[sample])\n",
    "            sample_test_dict[sample][f\"BDT_output_{HNL_mass}MeV\"] = results\n",
    "            \n",
    "if Params[\"Load_pi0_signal\"] == True:\n",
    "    for HNL_mass in Constants.HNL_mass_pi0_samples:\n",
    "        bdt = xgboost.Booster()\n",
    "        bdt.load_model(f\"bdts/pi0_selection/\"+Params[\"Run\"]+f\"_{HNL_mass}_MeV_pi0.json\")\n",
    "        for sample in xgb_test_dict:\n",
    "            results = bdt.predict(xgb_test_dict[sample])\n",
    "            sample_test_dict[sample][f\"BDT_output_{HNL_mass}MeV\"] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd9af25d-ef8a-4189-a832-a40fc8ace680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save_one_hist(hist,name,nbins,xlims):\n",
    "    # tData = ROOT.TH1F(name,name,nbins,xlims[0],xlims[1])\n",
    "    tData = ROOT.TH1F(name,name,len(nbins)-1,array(\"d\",nbins))\n",
    "    for i in range(len(nbins)-1):\n",
    "        tData.SetBinContent(i+1,hist['hist'][i])\n",
    "        tData.SetBinError(i+1,hist['err'][i])\n",
    "    return tData\n",
    "    \n",
    "def SaveToRoot_new(nbins,xlims,hist_samples,fileName='test.root'): \n",
    "    rFile = ROOT.TFile(f'bdt_output/{fileName}','RECREATE')\n",
    "    for name in hist_samples:\n",
    "        tData = Save_one_hist(hist_samples[name],name,nbins,xlims)\n",
    "        rFile.Write()\n",
    "    #rFile.Write()\n",
    "    rFile.Close()\n",
    "\n",
    "def make_stat_err(hist, SF):\n",
    "    stat_err = []\n",
    "    for i in range(0,len(hist[0])):\n",
    "        error = np.sqrt(hist[0][i])*np.sqrt(SF)\n",
    "        stat_err.append(error)\n",
    "    return stat_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e053c550-36ed-4e94-9e38-1c58a64fcb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_div(x,y):\n",
    "    if y == 0.0:\n",
    "        return 0\n",
    "    return x / y\n",
    "\n",
    "def Calc_RMS_quadsum(CV_hist, dict_detvar_hists): #Currently assuming \"mean\" value to be the CV, I believe this is the correct thing to do\n",
    "    nbins = len(CV_hist)\n",
    "    RMS_on_bins = np.zeros(nbins)\n",
    "    Quad_sum_on_bins = np.zeros(nbins)\n",
    "    RMS_on_bins_frac = np.zeros(nbins)\n",
    "    Quad_sum_on_bins_frac = np.zeros(nbins)\n",
    "    num_samples = len(dict_detvar_hists) #This should NOT include the CV hist\n",
    "    for j in range(nbins): #Looping over bins\n",
    "        sum_diffs_squared = 0\n",
    "        for detvar in dict_detvar_hists:\n",
    "            diff = dict_detvar_hists[detvar][j]-CV_hist[j] #Difference between the number in the CV sample and the DetVar sample\n",
    "            sum_diffs_squared += diff**2\n",
    "        variance = sum_diffs_squared/num_samples\n",
    "        RMS_on_bins[j] = np.sqrt(variance) #The total RMS error on the bin\n",
    "        Quad_sum_on_bins[j] = np.sqrt(sum_diffs_squared)\n",
    "        RMS_on_bins_frac[j] = safe_div(np.sqrt(variance),CV_hist[j]) #Need to calculate here to avoid problems with zero divisor\n",
    "        Quad_sum_on_bins_frac[j] = safe_div(np.sqrt(sum_diffs_squared),CV_hist[j])\n",
    "              \n",
    "    return {\"RMS\":RMS_on_bins, \"quadsum\":Quad_sum_on_bins, \"RMS_frac\":RMS_on_bins_frac, \"quadsum_frac\":Quad_sum_on_bins_frac}\n",
    "\n",
    "def Calc_frac_diff(CV_hist, dict_detvar_hists):\n",
    "    nbins = len(CV_hist)\n",
    "    frac_diff_dict = {}\n",
    "    perc_diff_dict = {}\n",
    "    for detvar in dict_detvar_hists: #Should NOT contain CV hist\n",
    "        frac_diff_on_bins = np.zeros(nbins)\n",
    "        perc_diff_on_bins = np.zeros(nbins)\n",
    "        for j in range(nbins): #Looping over bins\n",
    "            frac = safe_div(dict_detvar_hists[detvar][j],CV_hist[j])\n",
    "            frac_diff = frac - 1.0\n",
    "            perc_diff = (frac_diff*100)\n",
    "            frac_diff_on_bins[j] = frac_diff\n",
    "            perc_diff_on_bins[j] = perc_diff\n",
    "        frac_diff_dict[detvar] = frac_diff_on_bins\n",
    "        perc_diff_dict[detvar] = perc_diff_on_bins\n",
    "           \n",
    "    return frac_diff_dict, perc_diff_dict\n",
    "\n",
    "def Calc_stat_err(CV_hist, CV_hist_unweighted): #Calculate the statistical (Poisson) error on each bin for the central value histogram\n",
    "    nbins = len(CV_hist)\n",
    "    stat_err_on_bins = np.zeros(nbins)\n",
    "    for j in range(nbins): #Looping over bins\n",
    "        poisson_err = np.sqrt(CV_hist_unweighted[j])\n",
    "        SF = CV_hist_unweighted[j]/CV_hist[j] #The factor this bin is scaled by due to weighting\n",
    "        stat_err_on_bins[j] = poisson_err*SF #Need to scale the Poisson error by whatever the total scaling on the bin is\n",
    "    return stat_err_on_bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c429c5-382c-44ba-a385-3d365beae770",
   "metadata": {},
   "source": [
    "## Plotting overlay Detector variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7badf1-c186-458b-871d-477c14563e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_dict = {}\n",
    "filename = 'logit_FINAL_2.root'\n",
    "for HNL_mass in Constants.HNL_mass_samples:\n",
    "    hist_placeholder = uproot.open(f'bdt_output/'+Params[\"Run\"]+f'_{HNL_mass}MeV_'+filename)\n",
    "    bins_dict[HNL_mass] = hist_placeholder['bkg_overlay'].to_numpy()[1] #A tuple of bin edges\n",
    "print(\"Loaded bins for \" + str(bins_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8502e89-62b0-43fc-babc-7b916db2970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want to swap this out for the neater script below. However, below currently getting problems with zero divisors and not plotting merged bins\n",
    "DetVar_percentages_dict = {}\n",
    "savefig = False\n",
    "display = False\n",
    "\n",
    "figsize=(14, 6)\n",
    "linewidth = 1\n",
    "h_line_1 = 50 #Line displaying this % difference\n",
    "h_line_2 = 80\n",
    "\n",
    "for HNL_mass in Constants.HNL_mass_samples: #Looping over all mass points\n",
    "    \n",
    "    print(f\"Plotting {HNL_mass}MeV histogram\") \n",
    "    if Params[\"Use_logit\"] == True:\n",
    "        bins = bins_dict[HNL_mass]\n",
    "        nbins = len(bins)-1\n",
    "        xrange = [bins_dict[HNL_mass][0], bins_dict[HNL_mass][-1]]\n",
    "        # xlims = [-0.5, 7]\n",
    "        # xticks = [0, 1, 2, 3, 4, 5]\n",
    "        if Params[\"Run\"] == \"run1\": \n",
    "            xlims = [-5, 11]\n",
    "            xticks = [-5, -4, -3, -2, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7]\n",
    "        if Params[\"Run\"] == \"run3\": \n",
    "            xlims = [-5, 12]\n",
    "            xticks = [-5, -4, -3, -2, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "    else:\n",
    "        bins = np.linspace(0,1, 11)\n",
    "        nbins = len(bins)-1\n",
    "        xrange = [bins[0], bins[-1]]\n",
    "        xlims = [0,1.4]\n",
    "        xticks = [0, 0.2, 0.4, 0.8, 1.0]\n",
    "    \n",
    "    plt.figure(figsize=figsize,facecolor='white')\n",
    "    RMS=np.zeros(nbins)\n",
    "    frac_RMS=np.zeros(nbins)\n",
    "    quad_sum=np.zeros(nbins)\n",
    "    frac_quad_sum=np.zeros(nbins)\n",
    "    sum_squares = np.zeros(nbins)\n",
    "    stat_err = np.zeros(nbins)\n",
    "    SF_on_bin = np.zeros(nbins)\n",
    "    upvals = np.zeros(nbins+1)\n",
    "    lowvals = np.zeros(nbins+1)\n",
    "    upvals_frac = np.zeros(nbins+1)\n",
    "    lowvals_frac = np.zeros(nbins+1)\n",
    "    x_coords = bins_dict[HNL_mass]\n",
    "    max_y = 0\n",
    "    \n",
    "    if Params[\"Use_logit\"] == False:\n",
    "        cv_hist, cv_bins = np.histogram(sample_test_dict[\"CV\"][f'BDT_output_{HNL_mass}MeV'],\n",
    "        range=xrange,\n",
    "        bins=nbins,\n",
    "        weights=sample_test_dict[\"CV\"][\"weight\"])\n",
    "    if Params[\"Use_logit\"] == True:\n",
    "        cv_hist, cv_bins = np.histogram(Functions.logit(sample_test_dict[\"CV\"][f'BDT_output_{HNL_mass}MeV']),\n",
    "        range=xrange,\n",
    "        bins=bins,\n",
    "        weights=sample_test_dict[\"CV\"][\"weight\"])\n",
    "    bins_cent=(cv_bins[:-1]+cv_bins[1:])/2\n",
    "    for DetVar in Constants.Detector_variations:\n",
    "        if DetVar == \"CV\":\n",
    "            continue\n",
    "        perc_list = []\n",
    "        if Params[\"Use_logit\"] == False:\n",
    "            detvar_hist, bins = np.histogram(sample_test_dict[DetVar][f'BDT_output_{HNL_mass}MeV'],\n",
    "            range=xrange,\n",
    "            bins=nbins,\n",
    "            weights=sample_test_dict[DetVar][\"weight\"])\n",
    "        if Params[\"Use_logit\"] == True:\n",
    "            detvar_hist, bins = np.histogram(Functions.logit(sample_test_dict[DetVar][f'BDT_output_{HNL_mass}MeV']),\n",
    "            range=xrange,\n",
    "            bins=bins,\n",
    "            weights=sample_test_dict[DetVar][\"weight\"])\n",
    "        for i in range(len(detvar_hist)):\n",
    "            frac = safe_div(detvar_hist[i],cv_hist[i])\n",
    "            frac_diff = frac - 1.0\n",
    "            perc_list.append(frac_diff*100)\n",
    "        \n",
    "        DetVar_percentages_dict[DetVar] = perc_list\n",
    "        plt.hist(bins_cent,weights=DetVar_percentages_dict[DetVar], bins=bins,range=xrange,label=f'{DetVar}',\n",
    "                lw=linewidth,histtype=\"step\") #just 1 entry for each bin, then \"weight\" becomes what the percentage is (hacky way, could do something nicer)\n",
    "        \n",
    "    cv_no_weighting = np.histogram(Functions.logit(sample_test_dict[\"CV\"][f'BDT_output_{HNL_mass}MeV']),\n",
    "        range=xrange,\n",
    "        bins=bins)[0]\n",
    "    \n",
    "    for j in range(len(cv_hist)):\n",
    "        for DetVar in Constants.Detector_variations:\n",
    "            if DetVar == \"CV\":\n",
    "                continue\n",
    "            if Params[\"Use_logit\"] == False:\n",
    "                hist_input = sample_test_dict[DetVar][f'BDT_output_{HNL_mass}MeV']\n",
    "            if Params[\"Use_logit\"] == True:\n",
    "                hist_input = Functions.logit(sample_test_dict[DetVar][f'BDT_output_{HNL_mass}MeV'])\n",
    "                    \n",
    "            detvar_hist, bins = np.histogram(hist_input,\n",
    "                                             range=xrange, \n",
    "                                             bins=bins, \n",
    "                                             weights=sample_test_dict[DetVar][\"weight\"])\n",
    "            \n",
    "            diff = cv_hist[j] - detvar_hist[j]\n",
    "            diff_squared = diff**2\n",
    "            sum_squares[j] = sum_squares[j]+diff_squared\n",
    "            \n",
    "            # SF_on_bin[j] = cv_hist[j]/cv_no_weighting[j] #This effective scale factor comes in by weighting on events\n",
    "            SF_on_bin[j] = safe_div(cv_hist[j],cv_no_weighting[j])\n",
    "            stat_err[j] = np.sqrt(cv_no_weighting[j])*SF_on_bin[j]\n",
    "            upvals[j] = cv_hist[j]+stat_err[j]\n",
    "            lowvals[j] = cv_hist[j]-stat_err[j]\n",
    "            upvals_frac[j] = safe_div(upvals[j],cv_hist[j])*100-100\n",
    "            lowvals_frac[j] = safe_div(lowvals[j],cv_hist[j])*100-100\n",
    "        \n",
    "        RMS[j] = np.sqrt(sum_squares[j]/(len(Constants.Detector_variations)-1))\n",
    "        frac_RMS[j] = safe_div(RMS[j],cv_hist[j])\n",
    "        quad_sum[j] = np.sqrt(sum_squares[j])\n",
    "        frac_quad_sum[j] = safe_div(quad_sum[j],cv_hist[j])#quad_sum[j]/cv_hist[j]\n",
    "    # max_y = max(frac_quad_sum)\n",
    "    max_y = 2\n",
    "    \n",
    "    # print(max_y)\n",
    "    ylims = [max_y*(-1.2)*100, max_y*(1.2)*100]\n",
    "    plt.hist(bins_cent, weights=frac_quad_sum*100, bins=bins,range=xrange,label=f'Quadrature sum',lw=linewidth+2,\n",
    "             histtype=\"step\", color=\"black\")\n",
    "    plt.hist(bins_cent, weights=frac_quad_sum*(-100), bins=bins,range=xrange,lw=linewidth+2,\n",
    "             histtype=\"step\", color=\"black\")\n",
    "    \n",
    "    # plt.hist(bins_cent, weights=frac_RMS*100, bins=bins,range=xrange,label=f'RMS',lw=linewidth+2,\n",
    "    #          histtype=\"step\", color=\"black\")\n",
    "    # plt.hist(bins_cent, weights=frac_RMS*(-100), bins=bins,range=xrange,lw=linewidth+2,\n",
    "    #          histtype=\"step\", color=\"black\")\n",
    "    \n",
    "    if Params[\"Use_logit\"] == True:plt.fill_between(x_coords, lowvals_frac, upvals_frac, step=\"post\",color=\"grey\",alpha=0.3,zorder=2)\n",
    "    \n",
    "    plt.legend(loc='center right',frameon=True, framealpha=1.0)\n",
    "    plt.ylim(ylims)\n",
    "    plt.xlim(xlims) #Goes up to 7 to leave space for the legend\n",
    "    # plt.xlim([-5, 9]) #Goes up to 7 to leave space for the legend\n",
    "    plt.xlabel(f'BDT Score {HNL_mass} MeV', fontsize=30)\n",
    "    plt.ylabel('% Difference', fontsize=30)\n",
    "    \n",
    "    if max_y*100 > h_line_1:\n",
    "        plt.axhline(y=h_line_1, lw=2, color='green', linestyle = 'dashed')\n",
    "        plt.axhline(y=-1*(h_line_1), lw=2, color='green', linestyle = 'dashed')\n",
    "        plt.text(-4, 22, \"50%\", color='green')\n",
    "    \n",
    "    if max_y*100 > h_line_2:\n",
    "        plt.axhline(y=h_line_2, lw=2, color='orange', linestyle = 'dashed')\n",
    "        plt.axhline(y=-1*(h_line_2), lw=2, color='orange', linestyle = 'dashed')\n",
    "        plt.text(-4, 85, \"80%\", color='orange')\n",
    "    \n",
    "    plt.xticks(xticks) #Only keeping values for BDT scores which are possible.\n",
    "    # plt.xticks([-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5]) #Only keeping values for BDT scores which are possible.\n",
    "    #plt.yscale()\n",
    "    plt.tight_layout()\n",
    "    if savefig == True:\n",
    "        plt.savefig(\"plots/Sys_uncertainty/Overlay/DetVar/bkg_DetVars_\" + Params[\"Run\"] + \"_\" + str(HNL_mass) + \"MeV_Qaudsum_zoomed.pdf\")\n",
    "        plt.savefig(\"plots/Sys_uncertainty/Overlay/DetVar/bkg_DetVars_\" + Params[\"Run\"] + \"_\" + str(HNL_mass) + \"MeV_Qaudsum_zoomed.png\")\n",
    "    if display == False:\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e149e71-386c-493b-963d-fe7aaa03f9a3",
   "metadata": {},
   "source": [
    "## Printing specific bin numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8557836-0207-437d-a6d8-04e27e0d76ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "HNL_mass_list = [2, 10, 20, 50, 220]\n",
    "for HNL_mass in HNL_mass_list:\n",
    "    print(f\"{HNL_mass}MeV\")\n",
    "    bins = bins_dict[HNL_mass]\n",
    "    nbins = len(bins)-1\n",
    "    xrange = [bins_dict[HNL_mass][0], bins_dict[HNL_mass][-1]]\n",
    "    print(np.histogram(Functions.logit(sample_test_dict[\"CV\"][f'BDT_output_{HNL_mass}MeV']),range=xrange,bins=bins,weights=sample_test_dict[\"CV\"][\"weight\"])[0])\n",
    "    print(np.histogram(Functions.logit(sample_test_dict[\"CV\"][f'BDT_output_{HNL_mass}MeV']),range=xrange,bins=bins)[0]) #unweighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c458989-8426-4f21-8de3-42dbbd51bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_overlay_detvar = 0.5 #The fraction of overlay detector variation error\n",
    "flat_signal_detvar = 0.15 #The fraction of signal detector variation error\n",
    "overlay_detvar_dict, overlay_detvar_frac_dict = {}, {}\n",
    "signal_detvar_dict, signal_detvar_frac_dict = {}, {}\n",
    "\n",
    "loc_hists = \"Uncertainties/\"\n",
    "\n",
    "for HNL_mass in Constants.HNL_mass_samples:\n",
    "    with uproot.open(loc_hists+Params[\"Run\"]+f'_{HNL_mass}MeV_'+filename) as file:\n",
    "        bkg_vals_placeholder=file['bkg_overlay'].values()\n",
    "        signal_vals_placeholder=file['signal'].values()\n",
    "    overlay_detvar_dict[HNL_mass] = bkg_vals_placeholder*flat_overlay_detvar\n",
    "    signal_detvar_dict[HNL_mass] = signal_vals_placeholder*flat_signal_detvar\n",
    "    overlay_detvar_frac_dict[HNL_mass] = np.ones_like(bkg_vals_placeholder)*flat_overlay_detvar\n",
    "    signal_detvar_frac_dict[HNL_mass] = np.ones_like(signal_vals_placeholder)*flat_signal_detvar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86e22e9-1863-4ec6-99cc-006f79a62064",
   "metadata": {},
   "source": [
    "## Saving .root files with DetVar uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b3d87b-4f7f-4fc6-9ba6-56d56d6294f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_hists = \"Uncertainties/\"\n",
    "\n",
    "for HNL_mass in Constants.HNL_mass_samples:\n",
    "    bins_cent=(bins_dict[HNL_mass][:-1]+bins_dict[HNL_mass][1:])/2\n",
    "\n",
    "    values_dict = {'overlay_DetVar_uncertainty': overlay_detvar_dict[HNL_mass], \n",
    "                   'overlay_DetVar_uncertainty_frac': overlay_detvar_frac_dict[HNL_mass], \n",
    "                   'signal_DetVar_uncertainty':signal_detvar_dict[HNL_mass],\n",
    "                   'signal_DetVar_uncertainty_frac':signal_detvar_frac_dict[HNL_mass]} \n",
    "    hist_samples = {}\n",
    "\n",
    "    #make array with all values 1, then weight by value\n",
    "    for name in values_dict:\n",
    "        test_hist = np.histogram(bins_cent, weights=values_dict[name], bins=bins_dict[HNL_mass], \n",
    "                                 range=[bins_dict[HNL_mass][0], bins_dict[HNL_mass][-1]])\n",
    "        hist_samples[name] = test_hist\n",
    "\n",
    "    stop_writing = False\n",
    "    dont_save = []\n",
    "    with uproot.open(loc_hists+Params[\"Run\"]+f'_{HNL_mass}MeV_'+filename) as file: #Check what is already in the file (read-only)\n",
    "        for name in hist_samples:\n",
    "            if str(name)+\";1\" in file.keys():\n",
    "                dont_save.append(name)\n",
    "\n",
    "    with uproot.update(loc_hists+Params[\"Run\"]+f'_{HNL_mass}MeV_'+filename) as file: #Add new hists into the file\n",
    "        for name in hist_samples:\n",
    "            if name in dont_save:\n",
    "                print(f\"Not saving {name}\")\n",
    "            else:\n",
    "                file[name] = hist_samples[name]\n",
    "                \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e78fe23-648b-4a7f-ae4d-c237d68a34b4",
   "metadata": {},
   "source": [
    "## End of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d0cf0b-17b8-4224-b002-c3e442986ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the histograms\n",
    "hist_dict = {}\n",
    "no_cv_hist_dict = {}\n",
    "unweighted_CV_hist_dict = {}\n",
    "bins_cent_dict = {}\n",
    "for HNL_mass in Constants.HNL_mass_samples:\n",
    "    detvar_hist_dict = {}\n",
    "    bins = bins_dict[HNL_mass]\n",
    "    nbins = len(bins)-1\n",
    "    xrange = [bins_dict[HNL_mass][0], bins_dict[HNL_mass][-1]]\n",
    "    \n",
    "    unweighted_CV_hist_dict[HNL_mass] = np.histogram(Functions.logit(sample_test_dict[\"CV\"][f'BDT_output_{HNL_mass}MeV']),\n",
    "        range=xrange,\n",
    "        bins=nbins)[0]\n",
    "    bins_cent_dict[HNL_mass]=(bins[:-1]+bins[1:])/2\n",
    "    for DetVar in Constants.Detector_variations:\n",
    "        detvar_hist_dict[DetVar] = np.histogram(Functions.logit(sample_test_dict[DetVar][f'BDT_output_{HNL_mass}MeV']),\n",
    "        range=xrange,\n",
    "        bins=nbins,\n",
    "        weights=sample_test_dict[DetVar][\"weight\"])[0]\n",
    "    hist_dict[HNL_mass] =  detvar_hist_dict   \n",
    "    detvar_no_cv_dict = {key: val for key,\n",
    "                         val in detvar_hist_dict.items() if key != 'CV'}\n",
    "    no_cv_hist_dict[HNL_mass] = detvar_no_cv_dict\n",
    "print(\"Created all detector variation hists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe743a2c-5763-40b4-b005-6daefd13116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unweighted_CV_hist_dict[220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d445ce83-ef25-4b80-a0a9-ff32627eadb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig = False\n",
    "display = True\n",
    "\n",
    "figsize=(14, 5)\n",
    "linewidth = 1\n",
    "h_line_1 = 50 #Line displaying this % difference\n",
    "h_line_2 = 80\n",
    "\n",
    "xlims = [-5, 9]\n",
    "xticks = [-5, -4, -3, -2, -2, -1, 0, 1, 2, 3, 4, 5]\n",
    "\n",
    "for HNL_mass in Constants.HNL_mass_samples: #Looping over all mass points\n",
    "    print(f\"Plotting {HNL_mass}MeV histogram\") \n",
    "    plt.figure(figsize=figsize,facecolor='white')\n",
    "    frac_diff_dict, perc_diff_dict = Calc_frac_diff(hist_dict[HNL_mass][\"CV\"], no_cv_hist_dict[HNL_mass])\n",
    "    Calcs = Calc_RMS_quadsum(hist_dict[HNL_mass][\"CV\"], no_cv_hist_dict[HNL_mass])\n",
    "    RMS, quadsum, RMS_frac, quadsum_frac = Calcs[\"RMS\"], Calcs[\"quadsum\"], Calcs[\"RMS_frac\"], Calcs[\"quadsum_frac\"]\n",
    "    quadsum = Calc_RMS_quadsum(hist_dict[HNL_mass][\"CV\"], no_cv_hist_dict[HNL_mass])[\"quadsum\"]\n",
    "    stat_err = Calc_stat_err(hist_dict[HNL_mass][\"CV\"], unweighted_CV_hist_dict[HNL_mass])\n",
    "    x_coords = bins_dict[HNL_mass]\n",
    "    for DetVar in Constants.Detector_variations:\n",
    "        if DetVar == \"CV\":\n",
    "            continue\n",
    "        else:\n",
    "            plt.hist(bins_cent_dict[HNL_mass],weights=perc_diff_dict[DetVar], bins=bins,range=[bins[0],bins[-1]],label=f'{DetVar}',\n",
    "                     lw=linewidth,histtype=\"step\")\n",
    "    \n",
    "    # frac_RMS = np.divide(RMS,hist_dict[HNL_mass][\"CV\"]) #Can't do this because of zero divisor occuring\n",
    "    # frac_quadsum = np.divide(quadsum,hist_dict[HNL_mass][\"CV\"])\n",
    "    \n",
    "    max_y = max(RMS_frac)\n",
    "    ylims = [max_y*(-1.2)*100, max_y*(1.2)*100]\n",
    "    plt.hist(bins_cent_dict[HNL_mass], weights=RMS_frac*100, bins=bins,range=xrange,label=f'RMS',lw=linewidth+2,\n",
    "             histtype=\"step\", color=\"red\", linestyle = 'dashed')\n",
    "    plt.hist(bins_cent_dict[HNL_mass], weights=RMS_frac*(-100), bins=bins,range=xrange,lw=linewidth+2,\n",
    "             histtype=\"step\", color=\"red\", linestyle = 'dashed')\n",
    "    plt.hist(bins_cent_dict[HNL_mass], weights=quadsum_frac*100, bins=bins,range=xrange,label=f'Quadrature sum',lw=linewidth+2,\n",
    "             histtype=\"step\", color=\"black\")\n",
    "    plt.hist(bins_cent_dict[HNL_mass], weights=quadsum_frac*(-100), bins=bins,range=xrange,lw=linewidth+2,\n",
    "             histtype=\"step\", color=\"black\")\n",
    "\n",
    "    # plt.fill_between(x_coords, lowvals_frac, upvals_frac, step=\"post\",color=\"grey\",alpha=0.3,zorder=2)\n",
    "    \n",
    "    plt.legend(loc='upper right',frameon=True)\n",
    "    plt.ylim(ylims)\n",
    "    plt.xlim(xlims) #Goes up to 7 to leave space for the legend\n",
    "    # plt.xlim([-5, 9]) #Goes up to 7 to leave space for the legend\n",
    "    plt.xlabel(Params[\"Run\"] + f' BDT Score {HNL_mass} MeV', fontsize=30)\n",
    "    plt.ylabel('% Difference', fontsize=30)\n",
    "    \n",
    "    plt.axhline(y=h_line_1, lw=2, color='green', linestyle = 'dashed')\n",
    "    plt.axhline(y=-1*(h_line_1), lw=2, color='green', linestyle = 'dashed')\n",
    "    plt.text(-3, 30, \"50%\", color='green')\n",
    "    \n",
    "    plt.axhline(y=h_line_2, lw=2, color='orange', linestyle = 'dashed')\n",
    "    plt.axhline(y=-1*(h_line_2), lw=2, color='orange', linestyle = 'dashed')\n",
    "    plt.text(-3, 90, \"80%\", color='orange')\n",
    "    \n",
    "    plt.xticks(xticks)\n",
    "    \n",
    "    if savefig == True:\n",
    "        plt.savefig(\"plots/Sys_uncertainty/Overlay/DetVar/\" + Params[\"Run\"] + \"_\" + str(HNL_mass) + \"_MeV_DetVars_lines.png\")\n",
    "    if display == False:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b462d5-9a32-4ab4-83f0-6c32ff52a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the histograms for detector variations\n",
    "HNL_mass = 200 # - Plot just one\n",
    "if Params[\"Load_DetVars\"] == True:\n",
    "    for DetVar in Constants.Detector_variations:\n",
    "        linewidth = 1\n",
    "        if DetVar == \"CV\":\n",
    "            linewidth = 3\n",
    "        if Params[\"Use_logit\"] == False:\n",
    "            plt.hist(sample_test_dict[DetVar][f'BDT_output_{HNL_mass}MeV'], weights=sample_test_dict[DetVar][\"weight\"], \n",
    "                     bins=Params[\"nbins\"],range=[0,1.0],label=f'{DetVar}',lw=linewidth,histtype=\"step\")\n",
    "        if Params[\"Use_logit\"] == True:\n",
    "            plt.hist(Functions.logit(sample_test_dict[DetVar][f'BDT_output_{HNL_mass}MeV']), weights=sample_test_dict[DetVar][\"weight\"], \n",
    "                     bins=5,range=[0.0,5.0],label=f'{DetVar}',lw=linewidth,histtype=\"step\")\n",
    "            \n",
    "    plt.xlabel(f'BDT_output_{HNL_mass}MeV')\n",
    "    #plt.legend()\n",
    "    #plt.yscale(\"log\")\n",
    "    plt.yscale(\"linear\")\n",
    "    # plt.ylim(1, maxium*1.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
