{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ab81f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "import os,sys,string, time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import uproot\n",
    "import pandas as pd\n",
    "from platform import python_version\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import uproot3\n",
    "import math\n",
    "from matplotlib.patches import Rectangle\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "from importlib import reload\n",
    "import pickle\n",
    "\n",
    "import Utilities.Plotter as PT\n",
    "import Utilities.Constants as Constants\n",
    "import Utilities.Variables_list as Variables\n",
    "import Utilities.Functions as Functions\n",
    "from Utilities.ipython_exit import exit\n",
    "\n",
    "print ('Success')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775a3504-392d-4b23-a225-0db439fcb0f5",
   "metadata": {},
   "source": [
    "## Reading in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84e41222-cb45-4107-a206-3b3653d23ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Params = {\"Run\":\"run1\", #The run number, so far either \"run1\" or \"run3\"\n",
    "          \"Load_single_file\":False, #This will override everything else, put the desired file in the \"single_file\" line\n",
    "          \"single_file\":10,\n",
    "          \"Load_standard\":True,\n",
    "          \"Load_DetVars\":False,\n",
    "          \"Only_keep_common_DetVar_evs\":True,\n",
    "          \"Load_data\":False,\n",
    "          \"FLATTEN\":True, #Have one row per reconstructed object in the analysis dataframe\n",
    "          \"only_presel\":False, #Create small files containing only variables necessary for pre-selection, for making pre-selection plots\n",
    "          \"EXT_in_training\":True,\n",
    "          \"Load_pi0_signal\":False} #Otherwise loads e+e- samples by default\n",
    "\n",
    "loc_pkls = \"pkl_files/\"+Params[\"Run\"]+\"/current_files/my_vars/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2d786fc-af51-48e5-88d4-d0ee5bcd2bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['run', 'sub', 'evt', 'nslice', 'n_pfps', 'n_tracks', 'n_showers',\n",
      "       'swtrig_pre', 'swtrig_post', 'trk_sce_start_x_v', 'trk_sce_start_y_v',\n",
      "       'trk_sce_start_z_v', 'trk_sce_end_x_v', 'trk_sce_end_y_v',\n",
      "       'trk_sce_end_z_v', 'shr_theta_v', 'shr_phi_v', 'shr_px_v', 'shr_py_v',\n",
      "       'shr_pz_v', 'shrclusdir0', 'shrclusdir1', 'shrclusdir2',\n",
      "       'shr_energy_tot', 'trk_theta_v', 'trk_phi_v', 'trk_dir_x_v',\n",
      "       'trk_dir_y_v', 'trk_dir_z_v', 'trk_energy', 'trk_energy_hits_tot',\n",
      "       'trk_energy_tot', 'trk_score_v', 'trk_calo_energy_u_v', 'trk_end_x_v',\n",
      "       'trk_chipr_best', 'pfnplanehits_U', 'pfnplanehits_V', 'pfnplanehits_Y',\n",
      "       'NeutrinoEnergy2', 'SliceCaloEnergy2', 'nu_flashmatch_score',\n",
      "       'contained_sps_ratio', 'flash_time', 'contained_fraction', 'trk_score',\n",
      "       'crtveto', 'shr_tkfit_dedx_U', 'shr_tkfit_dedx_V', 'shr_tkfit_dedx_Y',\n",
      "       'shr_tkfit_dedx_max', 'shr_tkfit_2cm_dedx_Y', 'shr_chipr',\n",
      "       'trk_bragg_p', 'trk_bragg_p_v', 'trk_chipr', 'subcluster',\n",
      "       'shr_moliere_avg_v', 'shrmoliereavg', 'topological_score',\n",
      "       'weightSplineTimesTune', 'ppfx_cv', 'npi0', 'min_x', 'max_x', 'min_y',\n",
      "       'max_y', 'min_z', 'max_z', 'weight', 'rse_id', 'highest_E'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "signal_samples_dict = {}\n",
    "# end_string = \"_FINAL\"\n",
    "end_string = \"_full_Finished\"\n",
    "\n",
    "Presel_overlay = pd.read_pickle(loc_pkls+\"Preselected_overlay_\"+Params[\"Run\"]+f\"_flattened{end_string}.pkl\")\n",
    "\n",
    "#Always load in EXT for pre-selection, even though might not be used in the training\n",
    "Presel_EXT = pd.read_pickle(loc_pkls+\"Preselected_beamoff_\"+Params[\"Run\"]+f\"_flattened{end_string}.pkl\")\n",
    "Presel_dirt = pd.read_pickle(loc_pkls+\"Preselected_dirtoverlay_\"+Params[\"Run\"]+f\"_flattened{end_string}.pkl\")\n",
    "\n",
    "start_load_str = loc_pkls\n",
    "if Params[\"Load_pi0_signal\"] == False: HNL_samples = Constants.HNL_ee_samples_names\n",
    "if Params[\"Load_pi0_signal\"] == True: \n",
    "    start_load_str += f\"pi0_selection/\"\n",
    "    HNL_samples = Constants.HNL_mass_pi0_samples_names\n",
    "if Params[\"Load_single_file\"] == True: HNL_samples = [Params[\"single_file\"]]\n",
    "    \n",
    "for HNL_mass in HNL_samples:\n",
    "    Presel_signal = pd.read_pickle(start_load_str+f\"Preselected_{HNL_mass}_\"+Params[\"Run\"]+f\"_flattened{end_string}.pkl\")\n",
    "    signal_samples_dict[HNL_mass] = Presel_signal\n",
    "\n",
    "print(Presel_overlay.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb76888-7925-407b-9a82-b6a997a12e5e",
   "metadata": {},
   "source": [
    "## Splitting into test and training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9873ba6f-b41a-4eb2-9343-c0dfd7032455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length overlay train 23028\n",
      "Length overlay test 23028\n",
      "Length EXT train 1987\n",
      "Length EXT test 4639\n",
      "Length 2_ee train 7413\n",
      "Length 2_ee test 7413\n",
      "Length 10_ee train 6297\n",
      "Length 10_ee test 6297\n",
      "Length 20_ee train 6950\n",
      "Length 20_ee test 6951\n",
      "Length 50_ee train 6351\n",
      "Length 50_ee test 6352\n",
      "Length 100_ee train 6606\n",
      "Length 100_ee test 6607\n",
      "Length 150_ee train 6376\n",
      "Length 150_ee test 6376\n"
     ]
    }
   ],
   "source": [
    "#overlay_train_frac, signal_train_frac, EXT_train_frac\n",
    "overlay_train, overlay_test, EXT_train, EXT_test, signal_train_dict, signal_test_dict = Functions.Split_samples(Presel_overlay, signal_samples_dict, \n",
    "                                                                                                      Presel_EXT, 0.5, 0.5, 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7ef77c7-0f1d-4d58-a0b8-7d6fb95fdf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features is 19\n",
      "Saving variables used as _full_Finished_3_run1.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['2_ee', '10_ee', '20_ee', '50_ee', '100_ee', '150_ee'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ultimate_feature_list = ['n_pfps', 'n_tracks', 'shr_theta_v', 'shr_phi_v', 'shr_pz_v', 'shrclusdir2', 'shr_energy_tot',\n",
    "                         'trk_theta_v', 'trk_phi_v','trk_dir_z_v', 'trk_energy', 'trk_energy_tot', 'trk_score_v',\n",
    "                         'pfnplanehits_U', 'pfnplanehits_V', 'pfnplanehits_Y', 'NeutrinoEnergy2']#, 'nu_flashmatch_score']\n",
    "\n",
    "ultimate_feature_list += ['shr_tkfit_dedx_max', 'topological_score']\n",
    "if Params[\"Run\"]==\"run3\":\n",
    "    ultimate_feature_list += ['nu_flashmatch_score']\n",
    "print(f\"Number of features is {len(ultimate_feature_list)}\")\n",
    "\n",
    "bdt_vars = ultimate_feature_list #This is using just the most important variables list\n",
    "\n",
    "if Params[\"Load_pi0_signal\"] == False: BDT_name = f\"{end_string}\"\n",
    "if Params[\"Load_pi0_signal\"] == True: BDT_name = f\"{end_string}\"\n",
    "if Params[\"EXT_in_training\"] == True: BDT_name = f\"{end_string}\"\n",
    "\n",
    "BDT_name = \"_full_Finished_3\"\n",
    "\n",
    "var_list = bdt_vars\n",
    "\n",
    "print(f\"Saving variables used as {BDT_name}_\"+Params[\"Run\"]+\".pkl\")\n",
    "if Params[\"Load_pi0_signal\"] == False:\n",
    "    with open(f\"bdts/input_vars/{BDT_name}_\"+Params[\"Run\"], \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(var_list, fp)\n",
    "elif Params[\"Load_pi0_signal\"] == True:\n",
    "    with open(f\"bdts/pi0_selection/input_vars/{BDT_name}_\"+Params[\"Run\"], \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(var_list, fp)\n",
    "        \n",
    "signal_samples_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d06c2490-bb46-49dc-a1be-a3f0853f7c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to save the test sample pkls? y/n  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not saved .pkls\n"
     ]
    }
   ],
   "source": [
    "save_pkls = input(\"Do you want to save the test sample pkls? y/n \")\n",
    "\n",
    "if save_pkls == \"y\":\n",
    "    Functions.Save_test_pkls(Params, loc_pkls, \"_full_Finished_new\", overlay_test, signal_test_dict, EXT_test)\n",
    "else: print(\"Not saved .pkls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23f3f899-8eef-408e-b520-a2483ec89a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding overlay, EXT and dirt into test set\n"
     ]
    }
   ],
   "source": [
    "combined_dict, labels_dict, bkg_train = Functions.Make_train_labels_and_dicts(Params, bdt_vars, overlay_train, EXT_train, signal_train_dict)\n",
    "\n",
    "if Params[\"EXT_in_training\"] == True:\n",
    "    print(\"Adding overlay, EXT and dirt into test set\")\n",
    "    bkg_test = pd.concat([overlay_test,EXT_test, Presel_dirt])\n",
    "else: bkg_test = overlay_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23fc7ce8-8cb0-469d-ab0e-815c25a9aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(Functions)   \n",
    "def Test_vs_train_plots(test_sig, test_bkg, train_sig, train_bkg, bdt_dict, bins_dict):\n",
    "    \"\"\"\n",
    "    Plotting the BDT score results for test and training sets to check for overtraining.\n",
    "    \"\"\"\n",
    "    test_results_sig_dict, test_results_bkg_dict = {}, {}\n",
    "    train_results_sig_dict, train_results_bkg_dict = {}, {}\n",
    "    \n",
    "    for HNL_mass in test_sig:\n",
    "        results_sig = Functions.logit(bdt_dict[HNL_mass].predict(test_sig[HNL_mass]))\n",
    "        results_bkg = Functions.logit(bdt_dict[HNL_mass].predict(test_bkg))\n",
    "\n",
    "        train_results_sig = Functions.logit(bdt_dict[HNL_mass].predict(train_sig[HNL_mass]))\n",
    "        train_results_bkg = Functions.logit(bdt_dict[HNL_mass].predict(train_bkg))\n",
    "\n",
    "        test_results_sig_dict.update({HNL_mass:results_sig})\n",
    "        test_results_bkg_dict.update({HNL_mass:results_bkg})\n",
    "\n",
    "        train_results_sig_dict.update({HNL_mass:train_results_sig})\n",
    "        train_results_bkg_dict.update({HNL_mass:train_results_bkg})\n",
    "    \n",
    "    # hist_range=[0,1.0] #For when NOT using logit(results)\n",
    "    # n_bins=20\n",
    "\n",
    "    for HNL_mass in test_sig:\n",
    "        plt.figure(figsize=(10,7))\n",
    "        # plt.hist(train_results_sig_dict[HNL_mass],bins=n_bins, range=hist_range, density=True,alpha=0.4,color='red',label=f'Train {HNL_mass}MeV HNL' )\n",
    "        plt.hist(train_results_sig_dict[HNL_mass],bins=bins_dict[HNL_mass], density=True,alpha=0.4,color='red',label=f'Train {HNL_mass} MeV HNL' )\n",
    "        counts,bin_edges = np.histogram(test_results_sig_dict[HNL_mass],bins=bins_dict[HNL_mass],density=True)\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:])/2.\n",
    "        plt.plot(bin_centers,counts,marker='o',linestyle=\"None\",color='red',label=f'Test {HNL_mass} MeV HNL')\n",
    "\n",
    "        # plt.hist(train_results_bkg_dict[HNL_mass], bins = n_bins, range = hist_range, density = True, alpha = 0.4, color = 'orange', label = r'Train overlay')\n",
    "        plt.hist(train_results_bkg_dict[HNL_mass], bins=bins_dict[HNL_mass], density = True, alpha = 0.4, color = 'orange', label = r'Train bkg')\n",
    "        counts,bin_edges = np.histogram(test_results_bkg_dict[HNL_mass],bins=bins_dict[HNL_mass],density = True)\n",
    "        bin_centers = (bin_edges[:-1] +  bin_edges[1:])/2.\n",
    "        plt.plot(bin_centers,counts,marker='o',linestyle =\"None\",color='orange',label = r'Test bkg')\n",
    "        plt.legend()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "159feff4-fafc-4770-b656-26e86f0c7d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train_dict, xgb_sig_train_dict, xgb_sig_test_dict, xgb_train_bkg, xgb_test_bkg = Functions.Prepare_for_xgb(Params, bdt_vars, combined_dict, \n",
    "                                                                                                     signal_train_dict, bkg_train,  signal_test_dict, \n",
    "                                                                                                     bkg_test, labels_dict, missing=-9999.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faf7e9ed-286e-4580-959a-4460ee9dab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_test_dict, labels_test_dict={}, {}\n",
    "for HNL_mass in xgb_sig_train_dict:\n",
    "    combined_test_dict[HNL_mass] = pd.concat([signal_test_dict[HNL_mass][bdt_vars], bkg_test[bdt_vars]])\n",
    "    labels_test_dict[HNL_mass] = [1]*len(signal_test_dict[HNL_mass]) + [0]*len(bkg_test)\n",
    "\n",
    "xgb_combined_test_dict = {}\n",
    "for HNL_mass in xgb_sig_train_dict:\n",
    "    xgb_combined_test_dict[HNL_mass] = xgboost.DMatrix(combined_test_dict[HNL_mass][bdt_vars], label=labels_test_dict[HNL_mass], \n",
    "                                                   missing=-9999.0, feature_names=bdt_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9689a4ae-9dcf-4d9c-9963-0501e234ac92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BDT name is _full_Finished_3\n"
     ]
    }
   ],
   "source": [
    "xgb_param = {'booster': 'dart',\n",
    "             'max_depth':6,\n",
    "             'eta':0.3,\n",
    "             'objective':'binary:logistic',\n",
    "             # 'eval_metric':'auc', #area under ROC curve\n",
    "             'eval_metric':'logloss',\n",
    "             # 'eval_metric':'mae',\n",
    "             'tree_method':'hist',\n",
    "             'rate_drop': 0.1,\n",
    "             'skip_drop': 0.3,\n",
    "#        'subsample':0.5,\n",
    "             'scale_pos_weight': float(len(bkg_train))/float(len(signal_train_dict[HNL_mass]))\n",
    "            }\n",
    "progress = dict()\n",
    "\n",
    "print(f\"BDT name is {BDT_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f578c614-7042-4a20-af02-511d25607f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to train new BDT models with names _full_Finished_3? y/n  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 2_ee BDT\n",
      "\n",
      "Training 10_ee BDT\n",
      "\n",
      "Training 20_ee BDT\n",
      "\n",
      "Training 50_ee BDT\n",
      "\n",
      "Training 100_ee BDT\n",
      "\n",
      "Training 150_ee BDT\n",
      "\n",
      "Finished all!\n"
     ]
    }
   ],
   "source": [
    "train_BDTs = input(f\"Do you want to train new BDT models with names {BDT_name}? y/n \")\n",
    "\n",
    "if train_BDTs == \"y\":\n",
    "    Functions.Train_BDTs(Params, bdt_vars, BDT_name, xgb_train_dict, xgb_sig_test_dict, xgb_test_bkg, xgb_param, xgb_combined_test_dict, \n",
    "               progress, num_round = 150, early_stop=20)\n",
    "    print(\"Finished all!\")\n",
    "else: print(\"Not retraining BDTs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f85ce2-bb05-4bd8-a69b-4760a1044102",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Optimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa12cc4-ba42-4182-a457-8fe53a924161",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized params = {'booster': 'dart', 'max_depth': 7, 'eta': 0.3, 'objective': 'binary:logistic', 'eval_metric': 'logloss',\n",
    "                    'tree_method': 'hist', 'scale_pos_weight': 3.923306148055207,\n",
    "                    'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 1.0, 'rate_drop': 0.1, 'skip_drop': 0.3}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a15850a-deca-4470-9541-82272e6cc275",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIMIZING\n",
    "\n",
    "HNL_mass = \"100_ee\"\n",
    "\n",
    "old_params = {'booster': 'dart',\n",
    "             'max_depth':6,\n",
    "             'eta':0.3,\n",
    "             'objective':'binary:logistic',\n",
    "             'tree_method':'hist',\n",
    "             'rate_drop': 0.1,\n",
    "             'skip_drop': 0.5#,\n",
    "#        'subsample':0.5,\n",
    "#        'scale_pos_weight': float(len(data_bkg_train))/float(len(data_sig_train)),\n",
    "            }\n",
    "\n",
    "old_watchlist = [(xgb_train_dict[HNL_mass], 'train'), (xgb_sig_test_dict[HNL_mass], 'test_sig'), (xgb_test_bkg,'test_bkg')]\n",
    "\n",
    "cv_results = xgboost.cv(\n",
    "    xgb_param,\n",
    "    xgb_train_dict[HNL_mass],\n",
    "    num_boost_round=100,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    metrics={'auc'},\n",
    "    early_stopping_rounds=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838e5374-46c9-461a-a747-9f76bd3a57b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results\n",
    "\n",
    "print(cv_results[\"test-auc-mean\"].max())\n",
    "print(cv_results[\"test-auc-mean\"].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b200c716-27ee-4814-ba18-63e0dd80f58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(4,10)\n",
    "    for min_child_weight in range(1,6)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83afd19-5f88-4011-b44a-76286d62fc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define initial best params and MAE\n",
    "max_auc = 0.0\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))    # Update our parameters\n",
    "    xgb_param['max_depth'] = max_depth\n",
    "    xgb_param['min_child_weight'] = min_child_weight    # Run CV\n",
    "    cv_results = xgboost.cv(\n",
    "        xgb_param,\n",
    "        xgb_train_dict[HNL_mass],\n",
    "        num_boost_round=100,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'auc'},\n",
    "        early_stopping_rounds=10\n",
    "    )    # Update best eval metric\n",
    "    mean_auc = cv_results[\"test-auc-mean\"].max()\n",
    "    boost_rounds = cv_results[\"test-auc-mean\"].argmax()\n",
    "    print(\"\\tAUC {} for {} rounds\".format(mean_auc, boost_rounds))\n",
    "    if mean_auc > max_auc:\n",
    "        max_auc = mean_auc\n",
    "        best_params = (max_depth, min_child_weight)\n",
    "    \n",
    "print(\"Best params: {}, {}, AUC: {}\".format(best_params[0], best_params[1], max_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58435900-1996-4ff5-842d-78ca15c84dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = xgboost.cv(\n",
    "    xgb_param,\n",
    "    xgb_train_dict[HNL_mass],\n",
    "    num_boost_round=100,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    metrics={'logloss'},\n",
    "    early_stopping_rounds=5\n",
    ")\n",
    "\n",
    "cv_results\n",
    "\n",
    "print(cv_results[\"test-logloss-mean\"].min())\n",
    "print(cv_results[\"test-logloss-mean\"].argmin())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e054b914-0224-42b9-b8e9-160b30c8c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define initial best params and MAE\n",
    "min_logloss = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))    # Update our parameters\n",
    "    xgb_param['max_depth'] = max_depth\n",
    "    xgb_param['min_child_weight'] = min_child_weight    # Run CV\n",
    "    cv_results = xgboost.cv(\n",
    "        xgb_param,\n",
    "        xgb_train_dict[HNL_mass],\n",
    "        num_boost_round=100,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'logloss'},\n",
    "        early_stopping_rounds=10\n",
    "    )    # Update best eval metric\n",
    "    mean_logloss = cv_results[\"test-logloss-mean\"].min()\n",
    "    boost_rounds = cv_results[\"test-logloss-mean\"].argmin()\n",
    "    print(\"\\tlogloss {} for {} rounds\".format(mean_logloss, boost_rounds))\n",
    "    if mean_logloss < min_logloss:\n",
    "        min_logloss = mean_logloss\n",
    "        best_params = (max_depth, min_child_weight)\n",
    "    \n",
    "print(\"Best params: {}, {}, logloss: {}\".format(best_params[0], best_params[1], min_logloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f93dc32-2183-4ddd-aa70-799ad63f131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param['max_depth'] = 7\n",
    "xgb_param['min_child_weight'] = 1\n",
    "xgb_param['eval_metric'] = \"logloss\"\n",
    "\n",
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]\n",
    "\n",
    "print(gridsearch_params)\n",
    "print(xgb_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54614689-69f0-44da-93b4-5870203bdb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_logloss = float(\"Inf\")\n",
    "best_params = None\n",
    "for subsample, colsample in gridsearch_params:\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))    # Update our parameters\n",
    "    xgb_param['subsample'] = subsample\n",
    "    xgb_param['colsample_bytree'] = colsample    # Run CV\n",
    "    cv_results = xgboost.cv(\n",
    "        xgb_param,\n",
    "        xgb_train_dict[HNL_mass],\n",
    "        num_boost_round=100,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'logloss'},\n",
    "        early_stopping_rounds=10\n",
    "    )    # Update best eval metric\n",
    "    mean_logloss = cv_results[\"test-logloss-mean\"].min()\n",
    "    boost_rounds = cv_results[\"test-logloss-mean\"].argmin()\n",
    "    print(\"\\tlogloss {} for {} rounds\".format(mean_logloss, boost_rounds))\n",
    "    if mean_logloss < min_logloss:\n",
    "        min_logloss = mean_logloss\n",
    "        best_params = (subsample, rate_drop)\n",
    "    \n",
    "print(\"Best params: {}, {}, logloss: {}\".format(best_params[0], best_params[1], min_logloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11066beb-282f-4994-aa82-0ec60f5bbc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param['subsample'] = 1.0\n",
    "xgb_param['colsample_bytree'] = 1.0\n",
    "\n",
    "print(xgb_param)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416b2fed-2bd1-4e99-b4ab-857e83e3a77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.20378282252634553 for 0.0 rate drop and skip drop\n",
    "\n",
    "gridsearch_params = [\n",
    "    (rate_drop, skip_drop)\n",
    "    for rate_drop in [i/10. for i in range(1,8)]\n",
    "    for skip_drop in [i/10. for i in range(1,11)]\n",
    "]\n",
    "\n",
    "print(gridsearch_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64754ed-d361-43d1-8e53-6c8425fab605",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_logloss = float(\"Inf\")\n",
    "best_params = None\n",
    "for rate_drop, skip_drop in gridsearch_params:\n",
    "    print(\"CV with rate_drop={}, skip_drop={}\".format(\n",
    "                             rate_drop,\n",
    "                             skip_drop))    # Update our parameters\n",
    "    xgb_param['rate_drop'] = rate_drop\n",
    "    xgb_param['skip_drop'] = skip_drop    # Run CV\n",
    "    cv_results = xgboost.cv(\n",
    "        xgb_param,\n",
    "        xgb_train_dict[HNL_mass],\n",
    "        num_boost_round=100,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'logloss'},\n",
    "        early_stopping_rounds=10\n",
    "    )    # Update best eval metric\n",
    "    mean_logloss = cv_results[\"test-logloss-mean\"].min()\n",
    "    boost_rounds = cv_results[\"test-logloss-mean\"].argmin()\n",
    "    print(\"\\tlogloss {} for {} rounds\".format(mean_logloss, boost_rounds))\n",
    "    if mean_logloss < min_logloss:\n",
    "        min_logloss = mean_logloss\n",
    "        best_params = (rate_drop, skip_drop)\n",
    "    \n",
    "print(\"Best params: {}, {}, logloss: {}\".format(best_params[0], best_params[1], min_logloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928cefb6-81bf-4b0b-9439-1170d48a4707",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param['rate_drop'] = 0.1\n",
    "xgb_param['skip_drop'] = 0.3\n",
    "\n",
    "print(xgb_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddc5b52-ac6d-47dc-afda-e84de3cc101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "min_logloss = float(\"Inf\")\n",
    "best_params = None\n",
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))    # We update our parameters\n",
    "    xgb_param['eta'] = eta    # Run and time CV\n",
    "    cv_results = xgboost.cv(\n",
    "            xgb_param,\n",
    "            xgb_train_dict[HNL_mass],\n",
    "            num_boost_round=300,\n",
    "            seed=42,\n",
    "            nfold=5,\n",
    "            metrics=['logloss'],\n",
    "            early_stopping_rounds=10\n",
    "            )    # Update best score\n",
    "    mean_logloss = cv_results[\"test-logloss-mean\"].min()\n",
    "    boost_rounds = cv_results[\"test-logloss-mean\"].argmin()\n",
    "    print(\"\\tlogloss {} for {} rounds\\n\".format(mean_logloss, boost_rounds))\n",
    "    if mean_logloss < min_logloss:\n",
    "        min_logloss = mean_logloss\n",
    "        best_params = eta\n",
    "        \n",
    "print(\"Best params: {}, logloss: {}\".format(best_params, min_logloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41018d83-9a4f-4f4d-bd30-a1bea2b4bbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param['eta'] = 0.3\n",
    "\n",
    "print(xgb_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d8146e-c3fc-4e76-a608-273bcc7cd5f4",
   "metadata": {},
   "source": [
    "## Test vs. train results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9637a803-c855-4248-b9da-1fb61c9e784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loading BDT models named {BDT_name}\")\n",
    "\n",
    "sample_names = xgb_train_dict.keys()\n",
    "bdt_model_dict = {}\n",
    "sig_results_test_dict, bkg_results_test_dict = {}, {}\n",
    "sig_results_train_dict, bkg_results_train_dict = {}, {}\n",
    "\n",
    "max_sig_results, max_bkg_results = {}, {}\n",
    "min_sig_results, min_bkg_results = {}, {}\n",
    "\n",
    "bins_dict={}\n",
    "\n",
    "if Params[\"Load_pi0_signal\"]==False: sample_type = \"ee\"\n",
    "if Params[\"Load_pi0_signal\"]==True: sample_type = \"pi0\"\n",
    "\n",
    "for HNL_mass in sample_names:\n",
    "    bdt = xgboost.Booster()\n",
    "    if HNL_mass.split(\"_\")[1] == \"pi0\": loc = \"bdts/pi0_selection/\"\n",
    "    if HNL_mass.split(\"_\")[1] == \"ee\": loc = \"bdts/\"\n",
    "    bdt.load_model(loc+Params[\"Run\"]+f\"_{HNL_mass}{BDT_name}.json\")\n",
    "    \n",
    "    bdt_model_dict[HNL_mass] = bdt\n",
    "    \n",
    "    sig_results_test_dict[HNL_mass] = Functions.logit(bdt.predict(xgb_sig_test_dict[HNL_mass]))\n",
    "    bkg_results_test_dict[HNL_mass] = Functions.logit(bdt.predict(xgb_test_bkg))\n",
    "    \n",
    "    sig_results_train_dict[HNL_mass] = Functions.logit(bdt.predict(xgb_sig_train_dict[HNL_mass]))\n",
    "    bkg_results_train_dict[HNL_mass] = Functions.logit(bdt.predict(xgb_train_bkg))\n",
    "    \n",
    "    max_sig_results[HNL_mass] = max([max(sig_results_test_dict[HNL_mass]), max(sig_results_train_dict[HNL_mass])])\n",
    "    max_bkg_results[HNL_mass] = max([max(bkg_results_test_dict[HNL_mass]), max(bkg_results_train_dict[HNL_mass])])\n",
    "    \n",
    "    min_sig_results[HNL_mass] = min([min(sig_results_test_dict[HNL_mass]), min(sig_results_train_dict[HNL_mass])])\n",
    "    min_bkg_results[HNL_mass] = min([min(bkg_results_test_dict[HNL_mass]), min(bkg_results_train_dict[HNL_mass])])\n",
    "    \n",
    "    low_edge_sig, low_edge_bkg = np.floor(min_sig_results[HNL_mass]), np.floor(min_bkg_results[HNL_mass])\n",
    "    high_edge_sig, high_edge_bkg = np.ceil(max_sig_results[HNL_mass]), np.ceil(max_bkg_results[HNL_mass])\n",
    "\n",
    "    bins_dict[HNL_mass] = np.arange(low_edge_bkg, high_edge_sig)\n",
    "    \n",
    "    \n",
    "print(bdt_model_dict.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ce69e5-3d7b-4967-912c-3315cc6161aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(Functions)\n",
    "sample_norms = Functions.Get_sample_norms(Params, sample_names, 0.5, 0.5, 0.3)\n",
    "\n",
    "print(sample_norms)\n",
    "\n",
    "xgb_overlay = xgboost.DMatrix(overlay_test[bdt_vars], label=[0]*len(overlay_test), missing=-9999.0, feature_names=bdt_vars)\n",
    "xgb_beamoff = xgboost.DMatrix(EXT_test[bdt_vars], label=[0]*len(EXT_test), missing=-9999.0, feature_names=bdt_vars)\n",
    "xgb_dirt = xgboost.DMatrix(Presel_dirt[bdt_vars], label=[0]*len(Presel_dirt), missing=-9999.0, feature_names=bdt_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b71a1ac-ecc3-41c4-9d39-5c997abea491",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_vs_train_plots(xgb_sig_test_dict, xgb_test_bkg, xgb_sig_train_dict, xgb_train_bkg,bdt_model_dict, bins_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff24f79-31f9-4fc7-9b33-af88795a4be8",
   "metadata": {},
   "source": [
    "## ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917adb1c-6040-4b6d-88c7-786f730ea1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_names = xgb_train_dict.keys()\n",
    "bdt_model_dict = {}\n",
    "sig_results_test_dict, bkg_results_test_dict = {}, {}\n",
    "sig_results_train_dict, bkg_results_train_dict = {}, {}\n",
    "overlay_test_results, beamoff_test_results, dirt_test_results = {}, {}, {}\n",
    "\n",
    "if Params[\"Load_pi0_signal\"]==False: sample_type = \"ee\"\n",
    "if Params[\"Load_pi0_signal\"]==True: sample_type = \"pi0\"\n",
    "\n",
    "# xgb_overlay \n",
    "# xgb_beamoff \n",
    "# xgb_dirt\n",
    "\n",
    "for HNL_mass in sample_names:\n",
    "    bdt = xgboost.Booster()\n",
    "    if HNL_mass.split(\"_\")[1] == \"pi0\": loc = \"bdts/pi0_selection/\"\n",
    "    if HNL_mass.split(\"_\")[1] == \"ee\": loc = \"bdts/\"\n",
    "    bdt.load_model(loc+Params[\"Run\"]+f\"_{HNL_mass}{BDT_name}.json\")\n",
    "    \n",
    "    bdt_model_dict[HNL_mass] = bdt\n",
    "    \n",
    "    sig_results_test_dict[HNL_mass] = bdt.predict(xgb_sig_test_dict[HNL_mass])\n",
    "    bkg_results_test_dict[HNL_mass] = bdt.predict(xgb_test_bkg)\n",
    "    \n",
    "    sig_results_train_dict[HNL_mass] = bdt.predict(xgb_sig_train_dict[HNL_mass])\n",
    "    bkg_results_train_dict[HNL_mass] = bdt.predict(xgb_train_bkg)\n",
    "    \n",
    "    overlay_test_results[HNL_mass] = bdt.predict(xgb_overlay)\n",
    "    beamoff_test_results[HNL_mass] = bdt.predict(xgb_beamoff)\n",
    "    dirt_test_results[HNL_mass] = bdt.predict(xgb_dirt)\n",
    "    \n",
    "print(bdt_model_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c04e982-bb46-4845-9806-ae1c89168913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RocCurves_test(test_sig,test_bkg,mass_label):\n",
    "    \"\"\"\n",
    "    For plotting ROC curves of test samples only.\n",
    "    \"\"\"\n",
    "    \n",
    "    def PosRate(cut_val,var):\n",
    "        return len(var[var>cut_val])/len(var)\n",
    "    \n",
    "    def NegRate(cut_val,var):\n",
    "        return len(var[var<cut_val])/len(var)\n",
    "    \n",
    "    def CalcRate(sig,bkg):\n",
    "        cuts=np.linspace(0,1,200)\n",
    "        FPs=[]\n",
    "        TPs=[]\n",
    "\n",
    "\n",
    "        for cut in cuts:\n",
    "            FPs.append(NegRate(cut,bkg))\n",
    "            TPs.append(PosRate(cut,sig))\n",
    "\n",
    "        FPs=np.array(FPs)\n",
    "        TPs=np.array(TPs)\n",
    "\n",
    "        AUC=-1.0*sum(((TPs[:-1]+TPs[1:])/2)*(FPs[:-1]-FPs[1:]))\n",
    "        rounded_AUC = round(AUC,3)\n",
    "\n",
    "        plt.plot(FPs,TPs,label=f'{mass_label} MeV, AUC={AUC:.{3}g}')\n",
    "        # plt.plot(FPs,TPs,label=f'{mass_label} MeV, AUC={rounded_AUC}')\n",
    "        \n",
    "    CalcRate(test_sig,test_bkg)\n",
    "    \n",
    "def RocCurves_normalised(test_sig, sample_norms, test_overlay, test_beamoff, test_dirt, mass_label):\n",
    "    \"\"\"\n",
    "    For plotting ROC curves of test samples only. \n",
    "    Correctly accounted for POT normalisation but not individual weights (effect minimal).\n",
    "    \"\"\"\n",
    "    \n",
    "    def PosRate(cut_val,var): #Fraction of signal events above cut_val\n",
    "        return len(var[var>cut_val])/len(var)\n",
    "    \n",
    "    def NegRate(cut_val,overlay,beamoff,dirt): #Fraction of all bkg events above cut_val (normalised, not weighted)\n",
    "        num=(len(overlay[overlay<cut_val])*sample_norms[\"overlay\"])+(len(beamoff[beamoff<cut_val])*sample_norms[\"beamoff\"])+(len(dirt[dirt<cut_val])*sample_norms[\"dirtoverlay\"])\n",
    "        dom=(len(overlay)*sample_norms[\"overlay\"])+(len(beamoff)*sample_norms[\"beamoff\"])+(len(dirt)*sample_norms[\"dirtoverlay\"])\n",
    "        return num/dom\n",
    "    \n",
    "    def CalcRate(sig,overlay,beamoff,dirt):\n",
    "        cuts=np.linspace(0,1,50)\n",
    "        FPs=[]\n",
    "        TPs=[]\n",
    "        \n",
    "        for cut in cuts:\n",
    "            FPs.append(NegRate(cut,overlay,beamoff,dirt))\n",
    "            TPs.append(PosRate(cut,sig))\n",
    "\n",
    "        FPs=np.array(FPs)\n",
    "        TPs=np.array(TPs)\n",
    "\n",
    "        AUC=-1.0*sum(((TPs[:-1]+TPs[1:])/2)*(FPs[:-1]-FPs[1:]))\n",
    "        rounded_AUC = round(AUC,3)\n",
    "\n",
    "        plt.plot(FPs,TPs,label=f'{mass_label} MeV, AUC={AUC:.{3}g}')\n",
    "        \n",
    "    CalcRate(test_sig, test_overlay, test_beamoff, test_dirt)\n",
    "    \n",
    "def RocCurves_test_train(test_sig,test_bkg,train_sig,train_bkg, mass_label):\n",
    "    \"\"\"\n",
    "    For plotting ROC curves of test samples only.\n",
    "    \"\"\"\n",
    "    \n",
    "    def PosRate(cut_val,var):\n",
    "        return len(var[var>cut_val])/len(var)\n",
    "    \n",
    "    def NegRate(cut_val,var):\n",
    "        return len(var[var<cut_val])/len(var)\n",
    "    \n",
    "    def CalcRate(sig,bkg,linestyle):\n",
    "        cuts=np.linspace(0,1,200)\n",
    "        FPs=[]\n",
    "        TPs=[]\n",
    "\n",
    "\n",
    "        for cut in cuts:\n",
    "            FPs.append(NegRate(cut,bkg))\n",
    "            TPs.append(PosRate(cut,sig))\n",
    "\n",
    "        FPs=np.array(FPs)\n",
    "        TPs=np.array(TPs)\n",
    "\n",
    "\n",
    "        AUC=-1.0*sum(((TPs[:-1]+TPs[1:])/2)*(FPs[:-1]-FPs[1:]))\n",
    "        rounded_AUC = round(AUC,3)\n",
    "        \n",
    "        plt.plot(FPs,TPs,label=f'{mass_label} MeV, AUC={AUC:.{3}g}',linestyle=linestyle)\n",
    "        # plt.plot(FPs,TPs,label=f'{mass_label} MeV, AUC={rounded_AUC}')\n",
    "        plt.xlabel(\"False Positives\")\n",
    "        plt.ylabel(\"True Positives\")\n",
    "        plt.legend()\n",
    "        \n",
    "        \n",
    "    CalcRate(test_sig,test_bkg,linestyle=\"solid\")\n",
    "    CalcRate(train_sig,train_bkg,linestyle=\"dashed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecb63ea-beab-4141-9ec1-01331afd160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8,8])\n",
    "\n",
    "save_fig = input(\"Do you want to save the Figure? y/n \")\n",
    "\n",
    "for HNL_mass in sig_results_test_dict:\n",
    "    mass_label = HNL_mass.split(\"_\")[0]\n",
    "    if mass_label == \"2\": continue\n",
    "    # RocCurves_test(sig_results_test_dict[HNL_mass],bkg_results_test_dict[HNL_mass], mass_label)\n",
    "    RocCurves_normalised(sig_results_test_dict[HNL_mass], sample_norms, overlay_test_results[HNL_mass], beamoff_test_results[HNL_mass], \n",
    "                         dirt_test_results[HNL_mass], mass_label)\n",
    "    \n",
    "x_flat_line=np.linspace(0,1,50)\n",
    "y_flat_line = []\n",
    "for i, x in enumerate(x_flat_line):\n",
    "    y_flat_line.append(1-x)\n",
    "    \n",
    "plt.plot(x_flat_line, y_flat_line, linestyle=\"dashed\", color=\"black\")\n",
    "    \n",
    "plt.xlabel(\"Signal Efficiency\")\n",
    "plt.ylabel(\"Background Rejection\")\n",
    "plt.legend(fontsize=19)\n",
    "\n",
    "if save_fig == \"y\":\n",
    "    plt.savefig(f\"plots/BDT_output/BDT_performance/Test_set_normalised_ROC_\" + Params[\"Run\"] + f\"_{sample_type}{BDT_name}.png\")\n",
    "    plt.savefig(f\"plots/BDT_output/BDT_performance/Test_set_normalised_ROC_\" + Params[\"Run\"] + f\"_{sample_type}{BDT_name}.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f81bca8-0b4c-4c8c-ae4c-87f813b66184",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8,8])\n",
    "\n",
    "save_fig = input(\"Do you want to save the Figure? y/n \")\n",
    "\n",
    "for HNL_mass in sig_results_test_dict:\n",
    "    mass_label = HNL_mass.split(\"_\")[0]\n",
    "    if mass_label == \"2\": continue\n",
    "    RocCurves_test_train(sig_results_test_dict[HNL_mass],bkg_results_test_dict[HNL_mass],\n",
    "                         sig_results_train_dict[HNL_mass],bkg_results_train_dict[HNL_mass], mass_label)\n",
    "    \n",
    "x_flat_line=np.linspace(0,1,200)\n",
    "y_flat_line = []\n",
    "for i, x in enumerate(x_flat_line):\n",
    "    y_flat_line.append(1-x)\n",
    "    \n",
    "plt.plot(x_flat_line, y_flat_line, linestyle=\"dashed\", color=\"black\")\n",
    "    \n",
    "plt.xlabel(\"False Positives\")\n",
    "plt.ylabel(\"True Positives\")\n",
    "plt.legend(fontsize=19)\n",
    "\n",
    "if save_fig == \"y\":\n",
    "    plt.savefig(f\"plots/BDT_output/BDT_performance/Test_and_train_ROC_\" + Params[\"Run\"] + f\"_{sample_type}{BDT_name}.png\")\n",
    "    plt.savefig(f\"plots/BDT_output/BDT_performance/Test_and_train_ROC_\" + Params[\"Run\"] + f\"_{sample_type}{BDT_name}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa754b8-6edb-43bf-8ed4-5864a4c4a46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = bdt_vars\n",
    "\n",
    "# BDT_name = \"New_20_variables_FIXED\"\n",
    "if Params[\"Load_pi0_signal\"] == False:\n",
    "    with open(f\"bdts/input_vars/{BDT_name}_\"+Params[\"Run\"], \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(var_list, fp)\n",
    "elif Params[\"Load_pi0_signal\"] == True:\n",
    "    with open(f\"bdts/pi0_selection/input_vars/{BDT_name}_\"+Params[\"Run\"], \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(var_list, fp)\n",
    "\n",
    "# with open(\"bdts/input_vars/\"+BDT_name, \"rb\") as fp:   # Unpickling\n",
    "#     b = pickle.load(fp)\n",
    "    \n",
    "# print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d5a815-d856-4b76-86af-1abd2b38f6d7",
   "metadata": {},
   "source": [
    "# Finished Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293380da-31c0-4d08-b5f5-7ac71386a1ef",
   "metadata": {},
   "source": [
    "## Checking variable correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2ce0d0-4404-4a8c-9acd-642687cf8462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bdt_vars = feature_names\n",
    "HNL_mass = \"150_pi0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ad1892-8b6b-48f2-af3b-02622353d09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taken from Luis' code\n",
    "# for HNL_mass in HNL_masses:\n",
    "method = 'kendall'\n",
    "correlations = signal_samples_dict[HNL_mass][bdt_vars].astype(np.float64).corr(method=method)\n",
    "plt.figure(figsize=(15,12))\n",
    "sns.heatmap(correlations,vmin=-1,annot=False,square=True,cbar_kws={'label':method+' correlation'},cmap = 'RdBu_r')\n",
    "plt.title('Input Variable Correlations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd62bb6-b92f-448f-8514-9d5243a9aac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just looking at most correlated \n",
    "corr=signal_samples_dict[HNL_mass][bdt_vars].corr()\n",
    "high_corr_var=np.where(corr>0.999)\n",
    "high_corr_var=[(corr.columns[x],corr.columns[y]) for x,y in zip(*high_corr_var) if x!=y and x<y]\n",
    "#high_corr_var\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f50740e-dd5e-4cb7-ac69-396d483a0428",
   "metadata": {},
   "source": [
    "## Looking at feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0608634a-1eb0-4ff2-a83a-cfdd282d7e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"150_ee\"\n",
    "print(a.split(\"_\")[1])\n",
    "\n",
    "print(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6351d3da-76cc-4079-9036-548307e99353",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make an importances dict   \n",
    "def Top_N_vars(bdt_model, N_vars):\n",
    "    importance = bdt.get_score(importance_type=\"gain\")\n",
    "    # for key in importance.keys():\n",
    "    #     importance[key] = round(importance[key],1)\n",
    "    sorted_importance = dict(sorted(importance.items(), key=lambda item: item[1]))\n",
    "    sorted_importance_list = list(sorted_importance.values())\n",
    "    sorted_importance_keys= list(sorted_importance.keys())\n",
    "    top_N = sorted_importance_keys[-N_vars:]\n",
    "    \n",
    "    return top_N\n",
    "\n",
    "def Sorted_importance(bdt_model):\n",
    "    importance = bdt.get_score(importance_type=\"gain\")\n",
    "    return importance\n",
    "\n",
    "top_N_dict = {}\n",
    "importance_dict = {}\n",
    "list_of_lists = []\n",
    "# BDT_name = \"ee_Finished\"\n",
    "# BDT_name = \"pi0\"\n",
    "\n",
    "# if Params[\"Load_pi0_signal\"] == False: \n",
    "#     sample_names = Constants.HNL_ee_samples_names\n",
    "#     loc = \"bdts/\"\n",
    "# if Params[\"Load_pi0_signal\"] == True: \n",
    "#     sample_names = Constants.HNL_mass_pi0_samples_names #I should load BOTH\n",
    "#     loc = \"bdts/pi0_selection/\"\n",
    "sample_names = Constants.HNL_ee_samples_names #+ Constants.HNL_mass_pi0_samples_names\n",
    "# for HNL_mass in Constants.HNL_mass_samples:\n",
    "for HNL_mass in sample_names:\n",
    "    bdt = xgboost.Booster()\n",
    "    if HNL_mass.split(\"_\")[1] == \"pi0\": loc = \"bdts/pi0_selection/\"\n",
    "    if HNL_mass.split(\"_\")[1] == \"ee\": loc = \"bdts/\"\n",
    "    # bdt.load_model(\"bdts/\"+Params[\"Run\"]+f\"_{HNL_mass}MeV_ultimate.json\")\n",
    "    # bdt.load_model(\"bdts/\"+Params[\"Run\"]+f\"_{HNL_mass}MeV_{BDT_name}.json\")\n",
    "    bdt.load_model(loc+Params[\"Run\"]+f\"_{HNL_mass}{BDT_name}.json\")\n",
    "    # print(\"Number of entries in top20 is \" + str(len(Top_N_vars(bdt, 20))))\n",
    "    # top_N_dict[HNL_mass] = Top_N_vars(bdt, 20)\n",
    "    top_N = Top_N_vars(bdt, 50)\n",
    "    top_N_dict[HNL_mass] = Top_N_vars(bdt, 50)\n",
    "    list_of_lists.append(Top_N_vars(bdt, 50))\n",
    "    importance_dict[HNL_mass] = Sorted_importance(bdt)\n",
    "    \n",
    "elements_in_all = list(set.intersection(*map(set, list_of_lists)))\n",
    "print(len(elements_in_all))\n",
    "print(elements_in_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31be7c30-7f83-4734-b9d7-98bab2c7556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "highets_imps = ['n_showers', 'NeutrinoEnergy2', 'secondshower_Y_charge', 'trk_chipr_best', 'trk_energy_hits_tot', 'shr_energy_tot', \n",
    "                'contained_sps_ratio', 'pfnplanehits_Y', 'shrclusdir2', 'trk_dir_y_v', 'SliceCaloEnergy2', 'trk_theta_v', 'trk_start_x_v', \n",
    "                'pi0_radlen2', 'pfnplanehits_V', 'trk_energy', 'trk_score_v', 'shrclusdir0', 'trk_bragg_mip_v', 'shr_py_v', \n",
    "                'nu_flashmatch_score', 'n_pfps', 'CosmicIPAll3D', 'pi0_dir2_z']\n",
    "\n",
    "ultimate_feature_list = ['n_pfps', 'n_tracks', 'shr_theta_v', 'shr_phi_v', 'shr_pz_v', 'shrclusdir2', 'shr_energy_tot',\n",
    "                         'trk_theta_v', 'trk_phi_v','trk_dir_z_v', 'trk_energy', 'trk_energy_tot', 'trk_calo_energy_u_v', 'trk_score_v',\n",
    "                         'pfnplanehits_U', 'pfnplanehits_V', 'pfnplanehits_Y', 'NeutrinoEnergy2', 'nu_flashmatch_score']\n",
    "\n",
    "elements_in_all = list(set.intersection(*map(set, [highets_imps,ultimate_feature_list])))\n",
    "print(len(elements_in_all))\n",
    "print(elements_in_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedd2dc0-fc9a-4d54-b256-3785ba5e6baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(importance_dict[245].keys())\n",
    "print(len(importance_dict[245].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98de628a-83ec-4505-8147-3a1e92e5b001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for HNL_mass in Constants.HNL_mass_samples:\n",
    "savefig = True\n",
    "plt.figure(figsize=[20,8])\n",
    "if Params[\"Load_pi0_signal\"] == True: \n",
    "    colours = {\"150_pi0\":\"coral\", \"200_pi0\":\"cornflowerblue\", \"245_pi0\":\"olivedrab\"}\n",
    "    smaller_samples = [\"150_pi0\", \"200_pi0\", \"245_pi0\"]\n",
    "if Params[\"Load_pi0_signal\"] == False: \n",
    "    colours = {\"10_ee\":\"coral\", \"100_ee\":\"cornflowerblue\", \"150_ee\":\"olivedrab\"}\n",
    "    smaller_samples = [\"10_ee\", \"100_ee\", \"150_ee\"]\n",
    "    \n",
    "smaller_samples = [\"10_ee\", \"100_ee\", \"150_ee\"]#,\"150_pi0\", \"200_pi0\", \"245_pi0\"]\n",
    "color_cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "for i, HNL_mass in enumerate(smaller_samples):\n",
    "    plt.bar(importance_dict[HNL_mass].keys(),importance_dict[HNL_mass].values(), label=f\"{HNL_mass} model\", \n",
    "            fill=False,linewidth=3, edgecolor=color_cycle[i])\n",
    "    # plt.bar(importance_dict[HNL_mass].keys(),importance_dict[HNL_mass].values(), label=f\"{HNL_mass}MeV model\", \n",
    "    #         fill=False,linewidth=3, edgecolor=colours[HNL_mass], color=colours[HNL_mass])\n",
    "# plt.bar(importance_dict[245].keys(),importance_dict[245].values())\n",
    "plt.xticks(np.array(range(0, len(importance_dict[HNL_mass].keys()))),importance_dict[HNL_mass].keys(),rotation=80)\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.legend(fontsize=20)\n",
    "plt.tight_layout()\n",
    "\n",
    "if savefig==True:\n",
    "    plt.savefig(\"plots/BDT_output/variable_importance/\"+ Params[\"Run\"]+f\"_importances{BDT_name}.pdf\")\n",
    "    plt.savefig(\"plots/BDT_output/variable_importance/\"+ Params[\"Run\"]+f\"_importances{BDT_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d979aa2f-7260-47da-a99c-766ceabfc690",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,8])\n",
    "colours = {150:\"coral\", 200:\"cornflowerblue\", 245:\"olivedrab\"}\n",
    "for HNL_mass in [245]:\n",
    "    plt.bar(importance_dict[HNL_mass].keys(),importance_dict[HNL_mass].values(), label=f\"{HNL_mass}MeV model\", \n",
    "            fill=False,linewidth=3, edgecolor=colours[HNL_mass], color=colours[HNL_mass])\n",
    "# plt.bar(importance_dict[245].keys(),importance_dict[245].values())\n",
    "plt.xticks(np.array(range(0, len(importance_dict[HNL_mass].keys()))),importance_dict[HNL_mass].keys(),rotation=80)\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.legend(fontsize=20)\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"plots/BDT_output/variable_importance/\"+ Params[\"Run\"]+f\"_importances_{BDT_name}.pdf\")\n",
    "# plt.savefig(\"plots/BDT_output/variable_importance/\"+ Params[\"Run\"]+f\"_importances_{BDT_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea472ee-95b7-425f-9eaa-845b4da3425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[20,20])\n",
    "ax1 = fig.add_subplot(projection='3d')\n",
    "\n",
    "mass_list = [\"2MeV\", \"100MeV\", \"245MeV\"]\n",
    "x = importance_dict[2].keys()\n",
    "y = mass_list\n",
    "data = np.array([list(importance_dict[2].values()),\n",
    "                 list(importance_dict[100].values()),\n",
    "                 list(importance_dict[245].values())])\n",
    "\n",
    "numOfCols = len(x)\n",
    "numOfRows = len(y)\n",
    "\n",
    "xpos = np.arange(0, numOfCols, 1)\n",
    "ypos = np.arange(0, numOfRows, 1)\n",
    "xpos, ypos = np.meshgrid(xpos + 0.5, ypos + 0.5)\n",
    "\n",
    "xpos = xpos.flatten()\n",
    "ypos = ypos.flatten()\n",
    "zpos = np.zeros(numOfCols * numOfRows)\n",
    "\n",
    "dx = np.ones(numOfRows * numOfCols) * 0.5\n",
    "dy = np.ones(numOfCols * numOfRows) * 0.5\n",
    "dz = data.flatten()\n",
    "\n",
    "mass_list_labels = [\" \",\" \", \"2MeV\",\" \", \"100MeV\",\" \", \"245MeV\"]\n",
    "\n",
    "ax1.bar3d(xpos, ypos, zpos, dx, dy, dz)\n",
    "ax1.set_xticklabels(list(importance_dict[2].keys()),rotation=45)\n",
    "# ax1.set_xticklabels(list(importance_dict[2].keys()))\n",
    "ax1.set_yticklabels(mass_list_labels)\n",
    "\n",
    "ax1.set_xlabel('Variable')\n",
    "ax1.set_ylabel('Model')\n",
    "ax1.set_zlabel('Importance')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380877bb-f8ed-4648-88fd-3e4eec8c6c1d",
   "metadata": {},
   "source": [
    "# Finished code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28366e0-1cea-490c-840e-bcccdfd88413",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_test_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966bb616-3075-4722-bbad-57a1e9afb281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirt_matrix = xgboost.DMatrix(dirt_BDT[bdt_vars])\n",
    "# EXT_matrix = xgboost.DMatrix(EXT_BDT[bdt_vars])\n",
    "\n",
    "test_results_sig_dict = {}\n",
    "test_results_bkg_dict = {}\n",
    "\n",
    "train_results_sig_dict = {}\n",
    "train_results_bkg_dict = {}\n",
    "\n",
    "for HNL_mass in Constants.HNL_mass_samples:\n",
    "\n",
    "    bdt = xgboost.Booster()\n",
    "    bdt.load_model(\"bdts/\"+Params[\"Run\"]+f\"_{HNL_mass}_MeV_New_20_variables_FIXED.json\")\n",
    "    #bdt.load_model(f'bdts/{Run}_{HNL_mass}_MeV_REDUCED_variables_flattened_highest_E_2.json')\n",
    "    \n",
    "    importance = bdt.get_score(importance_type=\"gain\")\n",
    "    \n",
    "    for key in importance.keys():\n",
    "        importance[key] = round(importance[key],1)\n",
    "        \n",
    "    #importance_dict[HNL_mass] = importance\n",
    "\n",
    "    results_sig = bdt.predict(xgb_test_dict[HNL_mass])\n",
    "    results_bkg = bdt.predict(xgb_test_bkg)\n",
    "    \n",
    "    train_results_sig = bdt.predict(xgb_sig_train_dict[HNL_mass])\n",
    "    train_results_bkg = bdt.predict(xgb_bkg_train_dict[HNL_mass])\n",
    "    \n",
    "    test_results_sig_dict.update({HNL_mass:results_sig})\n",
    "    test_results_bkg_dict.update({HNL_mass:results_bkg})\n",
    "    \n",
    "    train_results_sig_dict.update({HNL_mass:train_results_sig})\n",
    "    train_results_bkg_dict.update({HNL_mass:train_results_bkg})\n",
    "\n",
    "    # results_dirt = bdt.predict(dirt_matrix)\n",
    "    # results_EXT = bdt.predict(EXT_matrix)\n",
    "    \n",
    "    # dirt_BDT[f'BDT_output_{HNL_mass}MeV'] = results_dirt\n",
    "    # EXT_BDT[f'BDT_output_{HNL_mass}MeV'] = results_EXT\n",
    "\n",
    "    # overlay_test_BDT[f'BDT_output_{HNL_mass}MeV'] = results_bkg\n",
    "    # #Can add in a second loop over HNL_masses so that I predict each signal mass point with every other mass point bdt\n",
    "    # signal_test_BDT_dict[HNL_mass][f'BDT_output'] = results_sig\n",
    "    \n",
    "    #Plotting importances of variables\n",
    "    plt.figure(figsize=(12,12),facecolor='white')\n",
    "    print(f\"Plotting {HNL_mass}MeV importances:\")\n",
    "    a = xgboost.plot_importance(importance,max_num_features=10,importance_type='gain')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd91c75b-3da4-4991-8cdb-aa6644bba871",
   "metadata": {},
   "source": [
    "## Test vs. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab0164d-636e-4e96-9b92-56e108ccae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_range=[0,1.0]\n",
    "n_bins=20\n",
    "\n",
    "for HNL_mass in Constants.HNL_mass_samples:\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.hist(train_results_sig_dict[HNL_mass],bins=n_bins, range=hist_range, density=True,alpha=0.4,color='red',label=f'Train {HNL_mass}MeV HNL' )\n",
    "    counts,bin_edges = np.histogram(test_results_sig_dict[HNL_mass],bins=n_bins,range=hist_range,density=True)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:])/2.\n",
    "    plt.plot(bin_centers,counts,marker='o',linestyle=\"None\",color='red',label=f'Test {HNL_mass}MeV HNL')\n",
    "\n",
    "    plt.hist(train_results_bkg_dict[HNL_mass], bins = n_bins, range = hist_range, density = True, alpha = 0.4, color = 'orange', label = r'Train overlay')\n",
    "    counts,bin_edges = np.histogram(test_results_bkg_dict[HNL_mass],bins = n_bins, range= hist_range,density = True)\n",
    "    bin_centers = (bin_edges[:-1] +  bin_edges[1:])/2.\n",
    "    plt.plot(bin_centers,counts,marker='o',linestyle =\"None\",color='orange',label = r'Test overlay')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915f34d7-408f-40ce-9ca6-2d74dce1e6f1",
   "metadata": {},
   "source": [
    "## Checking variable correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08a4680-42f1-4f9b-954d-1197dd26917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taken from Luis' code\n",
    "# for HNL_mass in HNL_masses:\n",
    "method = 'kendall'\n",
    "correlations = cleaned_signal_dict[100][bdt_vars].astype(np.float64).corr(method=method)\n",
    "plt.figure(figsize=(15,12))\n",
    "sns.heatmap(correlations,vmin=-1,annot=False,square=True,cbar_kws={'label':method+' correlation'},cmap = 'RdBu_r')\n",
    "plt.title('Input Variable Correlations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a32c08-e4b9-4d6c-8037-4aa3bc074521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just looking at most correlated \n",
    "corr=cleaned_signal_dict[100][bdt_vars].corr()\n",
    "high_corr_var=np.where(corr>0.95)\n",
    "high_corr_var=[(corr.columns[x],corr.columns[y]) for x,y in zip(*high_corr_var) if x!=y and x<y]\n",
    "high_corr_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b7d7ce-cb79-4e2f-a35d-88717247cdf0",
   "metadata": {},
   "source": [
    "# End of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442ebabd-3c77-4278-914d-0c65d0201329",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
