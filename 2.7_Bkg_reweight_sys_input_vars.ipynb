{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced5e536-c413-4447-b2d4-8b0ed1c50021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,string, time\n",
    "import ROOT\n",
    "from math import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import uproot\n",
    "import pandas as pd\n",
    "from root_pandas import read_root\n",
    "from platform import python_version\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import uproot3\n",
    "import math\n",
    "from matplotlib.patches import Rectangle\n",
    "import pickle\n",
    "from importlib import reload\n",
    "\n",
    "import Utilities.Plotter as PT\n",
    "import Utilities.Constants as Constants\n",
    "import Utilities.Variables_list as Variables\n",
    "import Utilities.Functions as Functions\n",
    "import Utilities.Variables_bins as Var_bins\n",
    "import Utilities.Sys_unc_variables as sys_unc\n",
    "from Utilities.ipython_exit import exit\n",
    "\n",
    "print ('Success')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce878578-1431-44ef-937e-f139e58caf9b",
   "metadata": {},
   "source": [
    "# Loading in the \"results\" dataframe after full selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a5f612-8b8c-427d-9201-adbecb1b2a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Run = \"run3\" #so far either \"run1\" or \"run3\"\n",
    "\n",
    "HNL_masses = Constants.HNL_mass_samples\n",
    "\n",
    "loc_pkl = f'pkl_files/{Run}/current_files/Results/'\n",
    "\n",
    "# overlay_results = pd.read_pickle(loc_pkl+\"overlay_results.pkl\") #This will contain all of the BDT output scores and rse_id\n",
    "\n",
    "# loc_hists = 'bdt_output/'\n",
    "\n",
    "# bins_dict = {}\n",
    "# for HNL_mass in HNL_masses:\n",
    "#     hist_placeholder = uproot.open(loc_hists+f'{Run}_{HNL_mass}MeV_logit_top_20_merged_FIXED.root')\n",
    "#     bins_dict[HNL_mass] = hist_placeholder['bkg_overlay'].to_numpy()[1] #A tuple of bin edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84092bd1-a783-45cb-95e0-20bcdad50e0e",
   "metadata": {},
   "source": [
    "## Loading in the preselected dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc1e995-babf-44c0-97a9-37adada9eb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_pkls_presel = \"pkl_files/\"+Run+\"/current_files/my_vars/\"\n",
    "Presel_overlay = pd.read_pickle(loc_pkls_presel+\"Preselected_overlay_\"+Run+\"_my_vars_flattened.pkl\")\n",
    "print(Presel_overlay.keys())\n",
    "# print(len(Presel_overlay))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff28413-ae20-47cc-9464-4c260937d3e5",
   "metadata": {},
   "source": [
    "# Reading in the overlay .root file with reweight branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a4c5de-0103-44bf-8404-7463d7a77ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_variables = Variables.sys_vars + Variables.event_vars + Variables.weight_related\n",
    "\n",
    "if Run == \"run1\":\n",
    "    NuMI_MC_overlay = uproot3.open('../NuMI_MC/SLIMMED_neutrinoselection_filt_run1_overlay.root')['nuselection/NeutrinoSelectionFilter']\n",
    "    Norm = Constants.SF_overlay_run1\n",
    "elif Run == \"run3\":\n",
    "    NuMI_MC_overlay = uproot3.open('../NuMI_MC/SLIMMED_neutrinoselection_filt_run3_overlay.root')['nuselection/NeutrinoSelectionFilter']\n",
    "    Norm = Constants.SF_overlay_run3\n",
    "\n",
    "df_overlay_weights = NuMI_MC_overlay.pandas.df(sys_variables, flatten=False) #Perhaps I can do this in a more clever way than just making a dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71c9948-3875-445d-aaaf-9c4e881d2969",
   "metadata": {},
   "source": [
    "# Keeping only the events which pass selection in the weight dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8885864f-01e9-48e0-b041-1407ba8a5a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_unique_ev_id(df): #df must have 'run', 'sub' and 'evt' branches\n",
    "    if pd.Series(['run', 'sub', 'evt']).isin(df.columns).all():\n",
    "        rse_list = []\n",
    "        for entry in df.index: #Looping over all events in the dataframe\n",
    "            rse = str(df['run'][entry]) + \"_\" + str(df['sub'][entry]) + \"_\" + str(df['evt'][entry])\n",
    "            rse_list.append(rse)\n",
    "        df['rse_id'] = rse_list #Writing a new branch with the unique event id\n",
    "        return df.copy()\n",
    "    else:\n",
    "        print(\"Dataframe needs \\\"run\\\", \\\"sub\\\" and \\\"evt\\\" columns.\")\n",
    "        return 0\n",
    "    \n",
    "def check_duplicate_events(df):\n",
    "    rse_list = df['rse_id'].to_list()\n",
    "\n",
    "    seen = set()\n",
    "    dupes = []\n",
    "\n",
    "    for x in rse_list:\n",
    "        if x in seen:\n",
    "            dupes.append(x)\n",
    "        else:\n",
    "            seen.add(x)\n",
    "    print(\"Number of duplicates is \" + str(len(dupes)))\n",
    "    print(\"Number of unique events is \" + str(len(seen)))\n",
    "\n",
    "overlay_rse = make_unique_ev_id(Presel_overlay)\n",
    "df_overlay_weights_rse = make_unique_ev_id(df_overlay_weights)\n",
    "\n",
    "#Deleting any duplicates of events, should be able to avoid if correctly filtered for one event per row\n",
    "overlay_rse.drop_duplicates(subset=['rse_id'], keep='first', inplace=True)\n",
    "\n",
    "print(\"Number of events in weights file is \" + str(len(df_overlay_weights_rse)))\n",
    "print(\"Number of events in results file is \" + str(len(overlay_rse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00863fdf-66f9-4e0e-9e57-6e3db102152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keeping only those events in the final selection\n",
    "filtered_weights = df_overlay_weights_rse.loc[(df_overlay_weights_rse['rse_id'].isin(overlay_rse['rse_id']))]\n",
    "\n",
    "print(\"Number of events in the filtered weights file is \" + str(len(filtered_weights)))\n",
    "print(\"Number of events in results file is \" + str(len(overlay_rse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a9a5f9-bf48-45d7-a35b-909d3bc5eb88",
   "metadata": {},
   "source": [
    "## Calculating uncertainty for a BDT input variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db4a8c2-831d-41ae-a044-cede9b82ca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_weights.keys())\n",
    "print(overlay_rse.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a011daf9-bd65-4994-be73-c9bd49d8c471",
   "metadata": {},
   "outputs": [],
   "source": [
    "have_sys = sys_unc.run3_Sys_unc.keys()\n",
    "want_sys = ['shrclusdir2', 'n_tracks', 'trk_energy',\n",
    "       'shr_theta_v', 'contained_sps_ratio', 'trk_chipr_best', 'shr_px_v',\n",
    "       'trk_end_x_v', 'n_pfps', 'pfnplanehits_V', 'pfnplanehits_U',\n",
    "       'trk_calo_energy_u_v', 'nu_flashmatch_score', 'trk_score_v',\n",
    "       'NeutrinoEnergy2', 'shr_phi_v', 'pfnplanehits_Y', 'shr_pz_v',\n",
    "       'trk_theta_v', 'trk_phi_v', 'trk_energy_hits_tot', 'trk_dir_z_v',\n",
    "       'SliceCaloEnergy2', 'nslice', 'flash_time', 'contained_fraction',\n",
    "       'trk_score', 'crtveto', 'shr_energy_tot', 'trk_energy_tot', 'n_showers']\n",
    "make_sys = []\n",
    "for var in want_sys:\n",
    "    if var not in have_sys:\n",
    "        make_sys.append(var)\n",
    "print(len(want_sys))\n",
    "print(len(have_sys))\n",
    "# print(have_sys)\n",
    "print(len(make_sys))\n",
    "print(make_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fde3bb-303d-418e-a59e-e4c9402c4e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(Var_bins)\n",
    "bins_for = Var_bins.bins_var.keys()\n",
    "make_bins = []\n",
    "for var in make_sys:\n",
    "    if var not in bins_for:\n",
    "        make_bins.append(var)\n",
    "print(make_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c5f798-6355-4175-a963-48924bdcc2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HNL_masses = [20, 50, 100, 150, 180, 200] #Should get rid of this once made overlay branches with all results\n",
    "\n",
    "Variable_list = ['shr_energy_tot', 'trk_energy_tot', 'n_showers']\n",
    "\n",
    "just_score_df = overlay_rse[Variable_list + ['rse_id','weight']].copy()\n",
    "\n",
    "final_merged = pd.merge(filtered_weights,just_score_df, how='outer', on=['rse_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46550de-cd6b-496e-9677-61660d78615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1cb880-1197-4d4e-b75e-5b93223a1e21",
   "metadata": {},
   "source": [
    "# Plotting the BDT score with all different multisims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44b551c-b4ca-4171-bc17-c89a78fe522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def All_reweight_err(df, var_name, BINS, x_range, Norm, logit=False):\n",
    "    results_dict = {}\n",
    "    n_bins = len(BINS)-1\n",
    "    for Multisim in Constants.Multisim_univs:\n",
    "        Nuniverse = Constants.Multisim_univs[Multisim]\n",
    "        n_tot = np.empty([Nuniverse, n_bins])\n",
    "        n_cv_tot = np.empty(n_bins)\n",
    "        n_tot.fill(0)\n",
    "        n_cv_tot.fill(0)\n",
    "        \n",
    "        if logit == True:\n",
    "            variable = Functions.logit(df[var_name]) #The BDT output score\n",
    "        else:\n",
    "            variable = df[var_name] #The BDT output score\n",
    "        syst_weights = df[Multisim] #An array of length of the number of events, each entry is an array of length Nunivs\n",
    "        spline_fix_cv  = df[\"weight\"]*Norm\n",
    "        spline_fix_var = df[\"weight\"]*Norm\n",
    "        \n",
    "        s = syst_weights\n",
    "        df_weights = pd.DataFrame(s.values.tolist())\n",
    "        n_cv, bins = np.histogram(variable, range=x_range, bins=BINS, weights=spline_fix_cv)\n",
    "        n_cv_tot += n_cv\n",
    "        \n",
    "        if(Multisim == \"weightsGenie\"): #special treatment as [\"weightSplineTimesTune\"] is included in genie weights\n",
    "            if not df_weights.empty:\n",
    "                for i in range(Nuniverse):\n",
    "                    weight = df_weights[i].values / 1000.\n",
    "                    weight[weight == 1]= df[\"weightSplineTimesTune\"].iloc[weight == 1]\n",
    "                    weight[np.isnan(weight)] = df[\"weightSplineTimesTune\"].iloc[np.isnan(weight)]\n",
    "                    weight[weight > 50] = df[\"weightSplineTimesTune\"].iloc[weight > 50] # why 30 not 50?\n",
    "                    weight[weight <= 0] = df[\"weightSplineTimesTune\"].iloc[weight <= 0]\n",
    "                    weight[weight == np.inf] = df[\"weightSplineTimesTune\"].iloc[weight == np.inf]\n",
    "                \n",
    "                    n, bins = np.histogram(variable, \n",
    "                                           weights=np.nan_to_num(weight*spline_fix_var/df[\"weightSplineTimesTune\"]), range=x_range, bins=BINS)\n",
    "                    n_tot[i] += n\n",
    "                    \n",
    "        if(Multisim == \"weightsPPFX\"): #special treatment as [\"PPFXPcv\"] is included in ppfx weights\n",
    "            if not df_weights.empty:\n",
    "                for i in range(Nuniverse):\n",
    "                    weight = df_weights[i].values / 1000.\n",
    "                    weight[weight == 1]= df[\"ppfx_cv\"].iloc[weight == 1]\n",
    "                    weight[np.isnan(weight)] = df[\"ppfx_cv\"].iloc[np.isnan(weight)]\n",
    "                    weight[weight > 100] = df[\"ppfx_cv\"].iloc[weight > 100]\n",
    "                    weight[weight < 0] = df[\"ppfx_cv\"].iloc[weight < 0]\n",
    "                    weight[weight == np.inf] = df[\"ppfx_cv\"].iloc[weight == np.inf]\n",
    "                \n",
    "                    n, bins = np.histogram(variable, weights=weight*np.nan_to_num(spline_fix_var/df[\"ppfx_cv\"]), range=x_range, bins=BINS)\n",
    "                    n_tot[i] += n\n",
    "        \n",
    "        if(Multisim == \"weightsReint\"):\n",
    "            if not df_weights.empty:\n",
    "                for i in range(Nuniverse):\n",
    "                    weight = df_weights[i].values / 1000.\n",
    "                    weight[np.isnan(weight)] = 1\n",
    "                    weight[weight > 100] = 1\n",
    "                    weight[weight < 0] = 1\n",
    "                    weight[weight == np.inf] = 1\n",
    "                    n, bins = np.histogram(variable, weights=weight*spline_fix_var, range=x_range, bins=BINS)\n",
    "                    n_tot[i] += n\n",
    "        cov = np.empty([len(n_cv), len(n_cv)])\n",
    "        cov.fill(0)\n",
    "\n",
    "        for n in n_tot:\n",
    "            for i in range(len(n_cv)):\n",
    "                for j in range(len(n_cv)):\n",
    "                    cov[i][j] += (n[i] - n_cv_tot[i]) * (n[j] - n_cv_tot[j])\n",
    "\n",
    "        cov /= Nuniverse\n",
    "        results_dict[Multisim] = [cov,n_cv_tot,n_tot,bins]\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b39c478-004d-4d76-a5c6-3f3d43e6677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(Var_bins)\n",
    "bins_dict =  Var_bins.bins_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42735701-a7c6-42ff-992f-24424ae620ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HNL_mass = 50\n",
    "results_dict = {}\n",
    "for Variable in Variable_list:\n",
    "    print(f\"Calculating {Variable} uncertainties.\")\n",
    "    results_dict[Variable] = All_reweight_err(final_merged, Variable, bins_dict[Variable],\n",
    "                                    [bins_dict[Variable][0], bins_dict[Variable][-1]], Norm)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc3f472-a3ae-40ad-8c0a-1473efb9b697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_multisim(results_dict, Variable, savefig=False, display=True):\n",
    "    for Multisim in results_dict:\n",
    "        Nuniverse = Constants.Multisim_univs[Multisim]\n",
    "        cov = results_dict[Multisim][0]\n",
    "        cv = results_dict[Multisim][1]\n",
    "        n_tot = results_dict[Multisim][2]\n",
    "        bins = results_dict[Multisim][3]\n",
    "        xlims = [min(bins), max(bins)]\n",
    "        \n",
    "        fig,ax = plt.subplots(nrows=2, ncols=1, sharex=True, gridspec_kw={'height_ratios': [3, 1]}, figsize=[10,10],dpi=200)\n",
    "        plt.sca(ax[0])\n",
    "\n",
    "        # bins=np.linspace(0,1.0,21)\n",
    "\n",
    "        bins_cent=(bins[:-1]+bins[1:])/2\n",
    "        bins_centlong=np.tile(bins_cent,Nuniverse)\n",
    "\n",
    "        nybins=70\n",
    "\n",
    "        plt.title(Multisim + \" Variations\",fontsize=20)\n",
    "\n",
    "        plt.hist(bins_cent,bins,weights=cv,color=\"red\",histtype=\"step\",label=\"Central Value\",lw=2,linestyle='-')\n",
    "        plt.legend()\n",
    "        bins_cent=(bins[:-1]+bins[1:])/2\n",
    "        bins_centlong=np.tile(bins_cent,Nuniverse)\n",
    "\n",
    "        plt.ylabel(\"Events\")\n",
    "        plt.hist2d(bins_centlong,n_tot.flatten(),bins=[bins,nybins],cmin=1,range=[xlims,[0,max(cv)*1.4]],rasterized=True)\n",
    "\n",
    "        plt.colorbar(pad=0,use_gridspec=True)\n",
    "        #fig.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap),pad=0,use_gridspec=True)\n",
    "        plt.ylim(0,max(cv)*1.4)\n",
    "        # plt.yscale(\"log\")\n",
    "\n",
    "        plt.sca(ax[1])\n",
    "        \n",
    "        #ax[1].tick_params(labelright=False, length=0)\n",
    "        pos = ax[0].get_position()\n",
    "        pos2 = ax[1].get_position()\n",
    "        ax[1].set_position([pos.x0,pos2.y0,pos.width,pos2.height])\n",
    "        \n",
    "        plt.hist(bins_cent,bins,weights=np.sqrt(np.diag(cov))/cv*100,color=\"black\",histtype=\"step\",lw=3,linestyle='-')\n",
    "        maxy = 1.5*max(plt.hist(bins_cent,bins,weights=np.sqrt(np.diag(cov))/cv*100,color=\"black\",histtype=\"step\",lw=3,linestyle='-')[0])\n",
    "        plt.ylim(0,maxy)\n",
    "        plt.ylabel(\"% Uncertainity\")\n",
    "        #plt.yticks([])\n",
    "        plt.xlabel(f\"{Variable}\",fontsize=25)\n",
    "        # plt.tight_layout()\n",
    "        if savefig == True:\n",
    "            plt.savefig(\"plots/Sys_uncertainty/Overlay/BDT_input_vars/bkg_multisim_\" + Run + \"_\" + str(Variable) + \"_MeV_\" + Multisim + \".pdf\")\n",
    "            plt.savefig(\"plots/Sys_uncertainty/Overlay/BDT_input_vars/bkg_multisim_\" + Run + \"_\" + str(Variable) + \"_MeV_\" + Multisim + \".png\")\n",
    "        if display == False:\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1989da16-a516-4952-b1ea-19220aab0246",
   "metadata": {},
   "outputs": [],
   "source": [
    "HNL_masses = Constants.HNL_mass_samples\n",
    "for Variable in Variable_list:\n",
    "    print(Variable)\n",
    "    Plot_multisim(results_dict[Variable], Variable, savefig=False, display=False)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf5d438-aca0-45eb-961c-1e3c561e7ec8",
   "metadata": {},
   "source": [
    "## Check fraction is flat across distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b29ae4f-3942-4f37-abff-c8497f96545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_bkgerr_dict = {}\n",
    "tot_ppfx_err = {}\n",
    "tot_genie_err = {}\n",
    "tot_reint_err = {}\n",
    "plot_dict = {}\n",
    "\n",
    "for Variable in Variable_list:\n",
    "    plt.figure(figsize=[8,7],facecolor='white')\n",
    "    cov_ppfx = results_dict[Variable][\"weightsPPFX\"][0]\n",
    "    cov_genie = results_dict[Variable][\"weightsGenie\"][0]\n",
    "    cov_reint = results_dict[Variable][\"weightsReint\"][0]\n",
    "    # var_Overlay = samples_dict[\"overlay\"][Variable]\n",
    "\n",
    "    varis=final_merged[Variable]\n",
    "    weights=[final_merged[\"weight\"]*Norm]\n",
    "    labels=[fr\"In-Cryo $\\nu$\"]\n",
    "    xlims = [bins_dict[Variable][0],bins_dict[Variable][-1]]\n",
    "\n",
    "    weight_Overlay=final_merged[\"weight\"]*Norm\n",
    "    #weighted hists\n",
    "    overlaybkg_weighted=np.histogram(final_merged[Variable],bins=bins_dict[Variable],range=xlims,weights=weight_Overlay)[0]\n",
    "\n",
    "    mc_w=np.histogram(final_merged[Variable],bins=bins_dict[Variable],range=xlims,weights=weight_Overlay**2)\n",
    "\n",
    "    stat_bkgerr=np.sqrt(mc_w[0])\n",
    "    stat_bkgerr_dict[Variable]=stat_bkgerr\n",
    "    print(stat_bkgerr)\n",
    "\n",
    "    tot_ppfx_err[Variable]=np.sqrt(np.diag(cov_ppfx))\n",
    "    tot_genie_err[Variable]=np.sqrt(np.diag(cov_genie))\n",
    "    tot_reint_err[Variable]=np.sqrt(np.diag(cov_reint))\n",
    "\n",
    "    plot=plt.hist(varis, label=labels,range=xlims,bins=bins_dict[Variable],\n",
    "                  histtype=\"stepfilled\",stacked=True,density=False,linewidth=2,edgecolor=\"black\",weights=weights)\n",
    "    \n",
    "    plot_dict[Variable]=plot\n",
    "    \n",
    "    upvals=np.append((plot[0]+stat_bkgerr),(plot[0]+stat_bkgerr)[-1])\n",
    "    lowvals=np.append((plot[0]-stat_bkgerr),(plot[0]-stat_bkgerr)[-1])\n",
    "    \n",
    "    plt.fill_between(bins_dict[Variable], lowvals, upvals,step=\"post\",color=\"grey\",alpha=0.3,zorder=2)\n",
    "    plt.xlabel(Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d641fa03-a70c-488f-abad-60a2bef6591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_dict, frac_ppfx_dict, frac_genie_dict, frac_reint_dict = {}, {}, {}, {}\n",
    "for Variable in Variable_list:\n",
    "    plt.figure(figsize=[8,7],facecolor='white')\n",
    "    frac = np.divide(stat_bkgerr_dict[Variable], plot_dict[Variable][0])\n",
    "    frac_ppfx = np.divide(tot_ppfx_err[Variable], plot_dict[Variable][0])\n",
    "    frac_genie = np.divide(tot_genie_err[Variable], plot_dict[Variable][0])\n",
    "    frac_reint = np.divide(tot_reint_err[Variable], plot_dict[Variable][0])\n",
    "    \n",
    "    frac_dict[Variable], frac_ppfx_dict[Variable], frac_genie_dict[Variable], frac_reint_dict[Variable] = frac, frac_ppfx, frac_genie, frac_reint\n",
    "\n",
    "    bins_cent=(bins_dict[Variable][:-1]+bins_dict[Variable][1:])/2\n",
    "    plt.hist(bins_cent,weights=np.nan_to_num(frac),bins=bins_dict[Variable],range=xlims,density=False, label=\"stat\", histtype=\"step\", lw=4)\n",
    "    plt.hist(bins_cent,weights=np.nan_to_num(frac_ppfx),bins=bins_dict[Variable],range=xlims,density=False, label=\"ppfx\", histtype=\"step\", lw=4)\n",
    "    plt.hist(bins_cent,weights=np.nan_to_num(frac_genie),bins=bins_dict[Variable],range=xlims,density=False, label=\"genie\",  histtype=\"step\", lw=4)\n",
    "    plt.hist(bins_cent,weights=np.nan_to_num(frac_reint),bins=bins_dict[Variable],range=xlims,density=False, label=\"reint\",  histtype=\"step\", lw=4)\n",
    "    \n",
    "    plt.legend()\n",
    "\n",
    "    plt.xlabel(Variable)\n",
    "    plt.ylabel(f\"Fractional error\")\n",
    "    plt.savefig(\"plots/Data_MC_comparison/Overlay_sys_unc/\" + Run + f\"_{Variable}_ppfx_and_genie_frac_err.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef21aa15-7702-45f2-87b0-6bc5bf2346cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate average\n",
    "print(Run)\n",
    "for Variable in Variable_list:\n",
    "    length = len(frac_ppfx_dict[Variable])\n",
    "    total = sum(np.nan_to_num(frac_dict[Variable]))\n",
    "    total_ppfx = sum(np.nan_to_num(frac_ppfx_dict[Variable]))\n",
    "    total_genie = sum(np.nan_to_num(frac_genie_dict[Variable]))\n",
    "\n",
    "    mean = total/length\n",
    "    mean_ppfx = total_ppfx/length \n",
    "    mean_genie = total_genie/length \n",
    "\n",
    "    print(f\"mean stat is {mean}\")\n",
    "    print(f\"mean ppfx is {mean_ppfx}\")\n",
    "    print(f\"mean genie is {mean_genie}\")\n",
    "    print()\n",
    "    print(f\"\\\"{Variable}\\\": [{round(mean_ppfx,3)},{round(mean_genie,3)}]\")\n",
    "    print(\"---------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e59056e-2386-4959-9b21-db6bf28b0067",
   "metadata": {},
   "source": [
    "## Save uncertainty in Constants file\n",
    "Use %load Utilities/Sys_unc_variables.py at the start of the file. \n",
    "\n",
    "Then %%writefile Utilities/Sys_unc_variables.py after editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2dd3b0-666d-44d7-a3d0-756eeb2cc089",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load Utilities/Sys_unc_variables.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3b39f4-92e4-409a-a726-9c8af7380f5f",
   "metadata": {},
   "source": [
    "## End of code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
