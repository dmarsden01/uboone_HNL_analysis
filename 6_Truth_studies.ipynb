{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ab81f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "import os,sys,string, time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import uproot\n",
    "import pandas as pd\n",
    "from platform import python_version\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import uproot3\n",
    "import math\n",
    "from matplotlib.patches import Rectangle\n",
    "from particle import Particle\n",
    "\n",
    "import Utilities.Functions as Functions\n",
    "import Utilities.Plotter as PT\n",
    "import Utilities.Constants as Constants\n",
    "import Utilities.Variables_list as Variables\n",
    "from Utilities.ipython_exit import exit\n",
    "\n",
    "print ('Success')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca34c6d3-2ee8-4df7-8c15-4da5b588302f",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "The purpose of this script is to look at the kinematics of the various samples before and after selections. It should be able to inform decisions made in the full analysis chain. \n",
    "\n",
    "The kinematics vary signficantly between different masses of HNL, this script should make plots which give insight into those differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775a3504-392d-4b23-a225-0db439fcb0f5",
   "metadata": {},
   "source": [
    "# Reading in .pkl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "570e7d0e-617a-4ce9-8ce5-96854d8db079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading these run1 samples: \n",
      "['150_pi0', '180_pi0', '200_pi0', '220_pi0', '240_pi0', '245_pi0']\n"
     ]
    }
   ],
   "source": [
    "Params = {\"Run\":\"run1\", #The run number, so far either \"run1\" or \"run3\"\n",
    "          \"Load_lepton_signal\":False, #Just e+e- samples, Majorana\n",
    "          \"Load_pi0_signal\":True, #Just pi0 samples, Majorana\n",
    "          \"Load_lepton_dirac\":False, #Just e+e-, Dirac\n",
    "          \"Load_pi0_dirac\":False, #Just pi0, Dirac\n",
    "          \"Load_standard_bkgs\":False, #Backgrounds, 'overlay', 'dirtoverlay' and 'beamoff'\n",
    "          \"Load_data\":False, #'beamgood' sample\n",
    "          \"Load_DetVars\":False, #overlay Detector variations\n",
    "          \"Load_Signal_DetVars\":False, #e+e- Detector variation samples\n",
    "          \"Load_pi0_signal_DetVars\":False, #pi0 Detector variation samples\n",
    "          \"Only_keep_common_DetVar_evs\":True, #For DetVar samples, only keep events common between samples\n",
    "          \"FLATTEN\":False, #Have one row per reconstructed object in the dataframe\n",
    "          \"only_presel\":False, #Create small files containing only variables necessary for pre-selection, for making pre-selection plots\n",
    "          \"Load_truth_vars\":True, #Load the \"mc_\" type variables for signal\n",
    "          \"Load_single_file\":False, #This will override everything else, put the desired file in the \"single_file\" line\n",
    "          \"single_file\":'beamgood'} \n",
    "\n",
    "Params, samples = Functions.new_create_sample_list(Params)\n",
    "loc_pkls = \"pkl_files/\"+Params[\"Run\"]+\"/current_files/\"+Params[\"variables_string\"]+\"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97bb9696-f457-4275-9a63-b9234041b282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['150_pi0', '180_pi0', '200_pi0', '220_pi0', '240_pi0', '245_pi0'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_dict = Functions.Load_initial_pkls(samples, Params, loc_pkls, \"_full_Finished\")\n",
    "    \n",
    "samples_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f86fb588-5291-4df3-8273-9e9167704e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['run', 'sub', 'evt', 'mc_pdg', 'mc_E', 'mc_vx', 'mc_vy', 'mc_vz',\n",
       "       'mc_endx', 'mc_endy', 'mc_endz', 'mc_px', 'mc_py', 'mc_pz', 'nslice',\n",
       "       'n_pfps', 'n_tracks', 'n_showers', 'NeutrinoEnergy2', 'shr_theta_v',\n",
       "       'shr_phi_v', 'trk_theta_v', 'trk_phi_v', 'rse_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_dict['150_pi0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bef3fb8-549e-4a09-8022-4643e5e7d4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_variable(df,variable,debug=True): #The df should NOT be flattened. Will return a series which can be plotted. \n",
    "    first_entry = df.index[0]\n",
    "    if isinstance(df[variable][first_entry], (np.ndarray)):\n",
    "        if(debug):print(\"This variable has an array of entries per event.\")\n",
    "        Num_events = len(df[variable])\n",
    "        if(debug):print(\"The total number of events is \" + str(Num_events))\n",
    "        copy_column = df[variable].copy()\n",
    "        exploded = copy_column.explode(variable)\n",
    "        Num_nans = exploded.isna().sum()\n",
    "        if(debug):print(\"The number of events with empty arrays is \" + str(Num_nans))\n",
    "        if(debug):print(\"Fraction of non-empty arrays is \" + str(1-(Num_nans/Num_events)))\n",
    "        Nans_removed = exploded.dropna()\n",
    "        Num_entries = len(Nans_removed)\n",
    "        if(debug):print(\"The total number of entries is \" + str(Num_entries))\n",
    "        \n",
    "        return Nans_removed, Num_entries\n",
    "    if isinstance(df[variable][first_entry], (int,float,np.int32,np.float32,np.uint32,np.nan)):\n",
    "        if(debug):print(\"This variable has one entry per event.\")\n",
    "        Num_events = len(df[variable])\n",
    "        if(debug):print(\"The total number of events is \" + str(Num_events))\n",
    "        copy_column = df[variable].copy()\n",
    "        Num_nans = copy_column.isna().sum()\n",
    "        if Num_nans != 0:\n",
    "            if(debug):print(\"There are \" + str(Num_nans) + \" Nan values, removing now\")\n",
    "            copy_column.dropna()\n",
    "        Num_entries = len(copy_column)\n",
    "        return copy_column, Num_entries\n",
    "    else: print(\"Not sure what type this variable is!\")\n",
    "    \n",
    "def remove_non_reco_vals(df,debug=True): #Feed in the output of the check_variable\n",
    "    #value = -1e15\n",
    "    value = -9999\n",
    "    first_entry = df.index[0]\n",
    "    if(debug):print(\"Total number of entries is \" + str(len(df)))\n",
    "    if(debug):print(\"Number of very negative values is \" + str(len(df.loc[df < value])))\n",
    "\n",
    "    if(len(df.loc[df < value]) > 0):\n",
    "        new_df = df.drop(df.loc[df < value].index) #Removes values entirely\n",
    "        if(debug):print(\"New number of entries is \" + str(len(new_df)))\n",
    "            # if(len(df.loc[df == -1.0]) > 0):\n",
    "            #     df.loc[(df == -1.0), variable] = new_value #Sets the new value\n",
    "            # if(len(df.loc[df == np.nan]) > 0):\n",
    "            #     df.loc[(df == np.nan), variable] = new_value #Sets the new value\n",
    "            # if(len(df.loc[df == np.inf]) > 0):\n",
    "            #     df.loc[(df == np.inf), variable] = new_value #Sets the new value\n",
    "    else: new_df = df.copy()\n",
    "    return new_df, len(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d368690",
   "metadata": {},
   "outputs": [],
   "source": [
    "av_HNL_direction = [0.32, 0.74, -0.59] #obtianed from the weighted files, which save the HNL momenta\n",
    "\n",
    "Run = \"run1\" #so far either \"run1\" or \"run3\"\n",
    "\n",
    "load_lepton_signal = True\n",
    "load_pi0_signal = True\n",
    "\n",
    "FLATTEN = False #Mostly put as False\n",
    "\n",
    "Truth_vars = True\n",
    "\n",
    "only_presel = False\n",
    "\n",
    "load_bkgs = False\n",
    "\n",
    "signal_like = False #Should set lepton and pi0 loading vars to False\n",
    "\n",
    "if FLATTEN == True:\n",
    "    Flat_state = \"flattened\"\n",
    "else:\n",
    "    Flat_state = \"unflattened\"\n",
    "    \n",
    "if only_presel:\n",
    "    variables_string = \"Presel_vars\"\n",
    "elif Truth_vars:\n",
    "    variables_string = \"Truth_vars\"\n",
    "else:\n",
    "    variables_string = \"my_vars\"\n",
    "\n",
    "print(f\"Loading {Run} pickles\")\n",
    "\n",
    "loc_pkls = f\"pkl_files/{Run}/current_files/{variables_string}/\"\n",
    "\n",
    "end_str=\"_full_Finished\"\n",
    "\n",
    "if load_bkgs == True:\n",
    "    overlay_from_pkl = pd.read_pickle(loc_pkls+f\"overlay_{Run}_{variables_string}_{Flat_state}_New_gen.pkl\")\n",
    "    dirt_from_pkl = pd.read_pickle(loc_pkls+f\"dirt_{Run}_{variables_string}_{Flat_state}_New_gen.pkl\")\n",
    "    EXT_from_pkl = pd.read_pickle(loc_pkls+f\"EXT_{Run}_{variables_string}_{Flat_state}_New_gen.pkl\")\n",
    "    print(\"Overlay .pkl is \"+str(len(overlay_from_pkl))+\" entries long.\")\n",
    "    print(\"Dirt .pkl is \"+str(len(dirt_from_pkl))+\" entries long.\")\n",
    "    print(\"EXT .pkl is \"+str(len(EXT_from_pkl))+\" entries long.\")\n",
    "\n",
    "signal_samples_dict = {}\n",
    "\n",
    "# HNL_masses = [20, 50, 100, 150, 180, 200]\n",
    "HNL_masses = Constants.HNL_mass_samples\n",
    "\n",
    "if load_lepton_signal == True:\n",
    "    for HNL_mass in HNL_masses:\n",
    "        # signal_from_pkl = pd.read_pickle(loc_pkls+f\"signal_{HNL_mass}MeV_{Run}_{variables_string}_{Flat_state}_New_gen.pkl\")\n",
    "        signal_from_pkl = pd.read_pickle(loc_pkls+f\"signal_{HNL_mass}MeV_{Run}_{variables_string}_{Flat_state}_New_gen.pkl\")\n",
    "        signal_samples_dict[HNL_mass] = signal_from_pkl\n",
    "        print(f\"{HNL_mass}MeV Signal .pkl is \"+str(len(signal_samples_dict[HNL_mass]))+\" entries long.\")\n",
    "    \n",
    "if load_pi0_signal == True:\n",
    "    pi0_signal_samples_dict = {}\n",
    "    for HNL_mass in Constants.HNL_mass_pi0_samples:\n",
    "        # signal_from_pkl = pd.read_pickle(loc_pkls+f\"pi0_signal_{HNL_mass}MeV_{Run}_{variables_string}_{Flat_state}_truth.pkl\")\n",
    "        signal_from_pkl = pd.read_pickle(loc_pkls+f\"pi0_signal_{HNL_mass}MeV_{Run}_{variables_string}_{Flat_state}_truth.pkl\")\n",
    "        # pi0_signal_samples_dict[HNL_mass] = signal_from_pkl\n",
    "        signal_samples_dict[HNL_mass] = signal_from_pkl\n",
    "        print(f\"{HNL_mass}MeV pi0 signal .pkl is \"+str(len(signal_samples_dict[HNL_mass]))+\" entries long.\")\n",
    "\n",
    "elif signal_like == True:\n",
    "    signal_like_dict = {}\n",
    "    pkl_variable_tests_loc = f\"pkl_files/{Run}/current_files/Variable_tests/\"\n",
    "    for HNL_mass in HNL_masses:\n",
    "        signal_from_pkl = pd.read_pickle(pkl_variable_tests_loc+f\"signal_like_{HNL_mass}_MeV.pkl\")\n",
    "        signal_like_dict[HNL_mass] = signal_from_pkl\n",
    "        print(f\"{HNL_mass}MeV Signal .pkl is \"+str(len(signal_like_dict[HNL_mass]))+\" entries long.\")\n",
    "        \n",
    "print(f\"Successfully loaded {Run} pkls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32259517-881a-4dc3-8856-31519d88cccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_dict[\"150_ee\"].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffa75c2-9485-43dd-b6f6-2b35627bab15",
   "metadata": {},
   "source": [
    "## Reconstructed Multiplicity study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78401ec1-193f-43ff-a2d2-766fede6abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'n_showers'\n",
    "plot_dict = {}\n",
    "Num_entries_dict = {}\n",
    "debug = False\n",
    "\n",
    "plot_all_masses = True\n",
    "if plot_all_masses == True: plot_samples = samples_dict.keys()\n",
    "if plot_all_masses == False: plot_samples = [10, 100, 150]\n",
    "\n",
    "for sample in plot_samples:\n",
    "    print(f\"Mass is {sample} MeV\")\n",
    "    plot_dict[sample], Num_entries_dict[sample] = check_variable(samples_dict[sample],var,debug=debug)\n",
    "    plot_dict[sample], Num_entries_dict[sample] = remove_non_reco_vals(plot_dict[sample],debug=debug)\n",
    "    \n",
    "print()\n",
    "var_2 = 'n_tracks'\n",
    "plot_dict_2 = {}\n",
    "Num_entries_dict_2 = {}\n",
    "\n",
    "for sample in plot_samples:\n",
    "    print(f\"Mass is {sample} MeV\")\n",
    "    plot_dict_2[sample], Num_entries_dict_2[sample] = check_variable(samples_dict[sample],var_2,debug=debug)\n",
    "    plot_dict_2[sample], Num_entries_dict_2[sample] = remove_non_reco_vals(plot_dict_2[sample],debug=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2ab5dc-9af6-46b7-a872-4afb2df6c7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HNL_mass = 20\n",
    "savefig=True\n",
    "\n",
    "for HNL_mass in plot_dict.keys():\n",
    "    \n",
    "    mass_str = HNL_mass.split(\"_\")[0]\n",
    "    dec_type = HNL_mass.split(\"_\")[1]\n",
    "\n",
    "    n_showers = plot_dict[HNL_mass]\n",
    "    n_tracks = plot_dict_2[HNL_mass]\n",
    "\n",
    "    width = 10\n",
    "    aspect = 0.9\n",
    "    height = width*aspect\n",
    "    plt.figure(figsize=(width,height))\n",
    "    \n",
    "    BINS = np.arange(5)-0.5\n",
    "    lims = [-1, 5]\n",
    "    ticks = [0,1, 2, 3]\n",
    "    old_bins = 4\n",
    "    old_lims = [0,4]\n",
    "\n",
    "    plt.hist2d(n_showers, n_tracks, bins = BINS, range=[lims,lims], density=True)\n",
    "\n",
    "    counts, xedges, yedges, Image = plt.hist2d(n_showers, n_tracks, bins = BINS, range=[lims,lims], density=True)\n",
    "\n",
    "    dx = xedges[2]-xedges[1]\n",
    "    dy = yedges[2]-yedges[1]\n",
    "    for i in range(xedges.size-1):\n",
    "        for j in range(yedges.size-1):\n",
    "            xb = xedges[i] + 0.25*dx\n",
    "            yb = yedges[j] + 0.4*dy\n",
    "            plt.text(xb, yb, str(np.round(100.*counts[i,j],2)), fontsize=20)\n",
    "\n",
    "    plt.xticks(ticks)\n",
    "    plt.yticks(ticks)\n",
    "    if dec_type == \"ee\":\n",
    "        plt.title(str(mass_str) + r\" MeV HNL$\\rightarrow \\nu e^{+}e^{-}$\")\n",
    "    if dec_type == \"pi0\":\n",
    "        plt.title(str(mass_str) + r\" MeV HNL$\\rightarrow \\nu \\pi^{0}$\")\n",
    "    plt.xlabel(\"Reconstructed showers\")\n",
    "    plt.ylabel(\"Reconstructed tracks\")\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    if savefig==True:\n",
    "        Name = f\"Reconstructed_objects_{HNL_mass}_{Run}\"\n",
    "        if Params[\"Load_lepton_signal\"] == True: \n",
    "            plt.savefig(\"plots/Truth_studies/Signal_plots/\" + Name + \".png\")\n",
    "            plt.savefig(\"plots/Truth_studies/Signal_plots/\" + Name + \".pdf\")\n",
    "        if Params[\"Load_pi0_signal\"] == True: \n",
    "            plt.savefig(\"plots/Truth_studies/Signal_plots/pi0/\" + Name + \".png\")\n",
    "            plt.savefig(\"plots/Truth_studies/Signal_plots/pi0/\" + Name + \".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01096657-edcd-4bdb-8fc6-02f08bde9f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "eleven = Particle.from_pdgid(11)\n",
    "twelve = Particle.from_pdgid(12)\n",
    "thirteen = Particle.from_pdgid(13)\n",
    "fourteen = Particle.from_pdgid(14)\n",
    "one_one_one = Particle.from_pdgid(111)\n",
    "\n",
    "print(\"eleven is \" + str(eleven))\n",
    "print(\"twelve is \" + str(twelve))\n",
    "print(\"thirteen is \" + str(thirteen))\n",
    "print(\"fourteen is \" + str(fourteen))\n",
    "print(one_one_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ff221e-0aba-4ee6-a848-4f86c6701506",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLATTEN = True\n",
    "Flat_state = \"flattened\"\n",
    "\n",
    "flat_samples_dict = {}\n",
    "\n",
    "#Loading files for filtering ee events\n",
    "if load_lepton_signal == True:\n",
    "    for HNL_mass in HNL_masses:\n",
    "        # signal_from_pkl = pd.read_pickle(loc_pkls+f\"signal_{HNL_mass}MeV_{Run}_{variables_string}_{Flat_state}_New_gen.pkl\")\n",
    "        signal_from_pkl = pd.read_pickle(loc_pkls+f\"signal_{HNL_mass}MeV_{Run}_{variables_string}_{Flat_state}_truth.pkl\")\n",
    "        flat_samples_dict[HNL_mass] = signal_from_pkl\n",
    "        print(f\"{HNL_mass}MeV Signal .pkl is \"+str(len(flat_samples_dict[HNL_mass]))+\" entries long.\")\n",
    "    \n",
    "if load_pi0_signal == True:\n",
    "    for HNL_mass in Constants.HNL_mass_pi0_samples:\n",
    "        signal_from_pkl = pd.read_pickle(loc_pkls+f\"pi0_signal_{HNL_mass}MeV_{Run}_{variables_string}_{Flat_state}_truth.pkl\")\n",
    "        flat_samples_dict[HNL_mass] = signal_from_pkl\n",
    "        print(f\"{HNL_mass}MeV pi0 signal .pkl is \"+str(len(flat_samples_dict[HNL_mass]))+\" entries long.\")\n",
    "\n",
    "elif signal_like == True:\n",
    "    signal_like_dict = {}\n",
    "    pkl_variable_tests_loc = f\"pkl_files/{Run}/current_files/Variable_tests/\"\n",
    "    for HNL_mass in HNL_masses:\n",
    "        signal_from_pkl = pd.read_pickle(pkl_variable_tests_loc+f\"signal_like_{HNL_mass}_MeV.pkl\")\n",
    "        flat_samples_dict[HNL_mass] = signal_from_pkl\n",
    "        print(f\"{HNL_mass}MeV Signal .pkl is \"+str(len(signal_like_dict[HNL_mass]))+\" entries long.\")\n",
    "        \n",
    "print(f\"Successfully loaded {Run} pkls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e7b048-d5c5-440a-a2ce-0753f4c9a533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# signal_samples_dict[150].keys()\n",
    "flat_samples_dict[150].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb8f275-601c-41dd-9be0-2c29da9e9af6",
   "metadata": {},
   "source": [
    "## Remove e, mu, nu events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05afb355-2cc8-4613-b998-46c659abbd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make rse_id\n",
    "for HNL_mass in signal_samples_dict:\n",
    "    signal_samples_dict[HNL_mass] = Functions.make_unique_ev_id(signal_samples_dict[HNL_mass])\n",
    "    flat_samples_dict[HNL_mass] = Functions.make_unique_ev_id(flat_samples_dict[HNL_mass])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3402b43e-c26d-474d-8bb4-68f2ee5149b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#channels: nu,e+,e-, nu,mu,e, nu,mu+,mu- \n",
    "#need pdgs of minus 11 and 11. \n",
    "e_e_evs = {}\n",
    "mu_e_evs = {}\n",
    "mu_plus_e_evs = {}\n",
    "mu_mu_evs = {}\n",
    "mu_nu_mu_bar_evs = {}\n",
    "electrons_dict = {}\n",
    "positrons_dict = {}\n",
    "\n",
    "pi0_dict = {}\n",
    "nu_dict = {}\n",
    "\n",
    "if load_lepton_signal == True:\n",
    "    for HNL_mass in signal_samples_dict:\n",
    "        print(f\"Original length is of {HNL_mass}MeV \" + str(len(flat_samples_dict[HNL_mass])))\n",
    "        elec = flat_samples_dict[HNL_mass].query(\"mc_pdg==11\")\n",
    "        positron = flat_samples_dict[HNL_mass].query(\"mc_pdg==-11\")\n",
    "        \n",
    "        mu = flat_samples_dict[HNL_mass].query(\"mc_pdg==13\")\n",
    "        mu_bar = flat_samples_dict[HNL_mass].query(\"mc_pdg==-13\")\n",
    "        nu_mu_bar = flat_samples_dict[HNL_mass].query(\"mc_pdg==-14\")\n",
    "\n",
    "        electrons_dict[HNL_mass] = elec\n",
    "        positrons_dict[HNL_mass] = positron\n",
    "\n",
    "        e_e = Functions.make_common_evs_df([elec, positron])\n",
    "        mu_e = Functions.make_common_evs_df([positron, mu])\n",
    "        mu_plus_e = Functions.make_common_evs_df([mu_bar, elec])\n",
    "        mu_mu = Functions.make_common_evs_df([mu, mu_bar])\n",
    "        mu_nu_mu_bar = Functions.make_common_evs_df([mu_bar, nu_mu_bar])\n",
    "        # mu_mu = Functions.make_common_evs_df([mu, mu_bar, nu_mu_bar])\n",
    "        \n",
    "        e_e_evs[HNL_mass]=e_e\n",
    "        mu_e_evs[HNL_mass]=mu_e\n",
    "        mu_plus_e_evs[HNL_mass]=mu_plus_e\n",
    "        mu_mu_evs[HNL_mass]=mu_mu\n",
    "        mu_nu_mu_bar_evs[HNL_mass]=mu_nu_mu_bar\n",
    "        # print(\"Num ee decays is \" + str(len(common_evs[HNL_mass])*2))\n",
    "common_evs = {}\n",
    "if load_pi0_signal == True: \n",
    "    for HNL_mass in signal_samples_dict:\n",
    "        print(f\"Original length is of FLAT {HNL_mass}MeV \" + str(len(flat_samples_dict[HNL_mass])))\n",
    "        print(f\"Original length is of {HNL_mass}MeV \" + str(len(signal_samples_dict[HNL_mass])))\n",
    "        pi0 = flat_samples_dict[HNL_mass].query(\"mc_pdg==111\")\n",
    "        nu = flat_samples_dict[HNL_mass].query(\"mc_pdg==-12 or mc_pdg==12\")\n",
    "\n",
    "        pi0_dict[HNL_mass] = pi0\n",
    "        nu_dict[HNL_mass] = nu\n",
    "\n",
    "        common = Functions.make_common_evs_df([pi0, nu])\n",
    "        common_evs[HNL_mass]=common\n",
    "\n",
    "        print(\"Num pi0 decays is \" + str(len(common_evs[HNL_mass])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6837ba-2fe6-4ad2-81f2-d0f683a66923",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_ee, frac_mumu, frac_emu = {}, {}, {}\n",
    "frac_all_mus, frac_all_emus = {}, {}\n",
    "if load_lepton_signal == True:\n",
    "    for HNL_mass in signal_samples_dict:\n",
    "        frac_ee[HNL_mass] = len(e_e_evs[HNL_mass])/len(signal_samples_dict[HNL_mass])\n",
    "        frac_mumu[HNL_mass] = len(mu_mu_evs[HNL_mass])/len(signal_samples_dict[HNL_mass])\n",
    "        frac_emu[HNL_mass] = len(mu_e_evs[HNL_mass])/len(signal_samples_dict[HNL_mass])\n",
    "        frac_all_emus[HNL_mass] = (len(mu_e_evs[HNL_mass])+len(mu_plus_e_evs[HNL_mass]))/len(signal_samples_dict[HNL_mass])\n",
    "        frac_all_mus[HNL_mass] = (len(mu_mu_evs[HNL_mass])+len(mu_nu_mu_bar_evs[HNL_mass]))/len(signal_samples_dict[HNL_mass])\n",
    "        \n",
    "        print(f\"{HNL_mass} emu frac is \" + str(frac_all_emus[HNL_mass]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4930fea0-ff83-45e2-a73e-5a2a88f3be55",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_ee.keys()\n",
    "print(len(frac_ee.keys()))\n",
    "e_mu_plus_ee, mu_mu_plus_others = {}, {}\n",
    "for HNL_mass in signal_samples_dict:\n",
    "    e_mu_plus_ee[HNL_mass] =  frac_ee[HNL_mass]+frac_all_emus[HNL_mass]\n",
    "    print(e_mu_plus_ee[HNL_mass])\n",
    "    mu_mu_plus_others[HNL_mass] = e_mu_plus_ee[HNL_mass] + frac_mumu[HNL_mass]\n",
    "print(frac_ee.values())\n",
    "print(e_mu_plus_ee.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9257a3-66c4-4c16-bc3d-2acb3157311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_int_list = range(0, len(frac_ee.keys()))\n",
    "plt.bar(x_int_list, frac_ee.values(), label=r\"$\\nu e^{+}e^{-}$\", tick_label=list(frac_ee.keys()))\n",
    "plt.bar(x_int_list, frac_all_emus.values(), label=r\"$\\nu e\\mu$\", tick_label=list(frac_ee.keys()), bottom=list(frac_ee.values()))\n",
    "plt.bar(x_int_list, frac_all_mus.values(), label=r\"$\\nu \\mu\\mu$\", tick_label=list(frac_ee.keys()),bottom=list(e_mu_plus_ee.values()))\n",
    "\n",
    "plt.axhline(1.0,ls=\"--\", color=\"black\")\n",
    "plt.ylabel(\"Fraction of events\")\n",
    "plt.xlabel(\"HNL mass [MeV]\")\n",
    "plt.xlim(-0.5, 13)\n",
    "plt.legend(fontsize=22, loc=\"center right\")\n",
    "\n",
    "plt.savefig(\"plots/Generator/channel_fractions_current_samples.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b23e02-30c0-4448-acbb-bf7d635c9956",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_evs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0125a501-b3c0-4d51-b953-c0c6b35eb346",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_samples_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828aea3f-f641-4b9f-9910-ddaeeabd4d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# common_evs = e_e_evs\n",
    "filtered_dict, filtered_out_dict = {}, {}\n",
    "no_emu, no_category_dict = {}, {}\n",
    "nothing_dict, final_nothing_dict = {}, {}\n",
    "\n",
    "for HNL_mass in signal_samples_dict:\n",
    "    filtered_dict[HNL_mass] = signal_samples_dict[HNL_mass].loc[(signal_samples_dict[HNL_mass]['rse_id'].isin(common_evs[HNL_mass]['rse_id']))]\n",
    "    filtered_out_dict[HNL_mass] = signal_samples_dict[HNL_mass].loc[(~signal_samples_dict[HNL_mass]['rse_id'].isin(common_evs[HNL_mass]['rse_id']))]\n",
    "    \n",
    "#     no_emu[HNL_mass] =filtered_out_dict[HNL_mass].loc[(~filtered_out_dict[HNL_mass]['rse_id'].isin(mu_e_evs[HNL_mass]['rse_id']))]\n",
    "#     no_category_dict[HNL_mass] =no_emu[HNL_mass].loc[(~no_emu[HNL_mass]['rse_id'].isin(mu_mu_evs[HNL_mass]['rse_id']))]\n",
    "#     nothing_dict[HNL_mass] =no_category_dict[HNL_mass].loc[(~no_category_dict[HNL_mass]['rse_id'].isin(mu_nu_mu_bar_evs[HNL_mass]['rse_id']))]\n",
    "#     final_nothing_dict[HNL_mass]=nothing_dict[HNL_mass].loc[(~nothing_dict[HNL_mass]['rse_id'].isin(mu_plus_e_evs[HNL_mass]['rse_id']))]\n",
    "# print(len(final_nothing_dict[245]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a5e8c2-d5e1-46bb-90e5-22fb7968836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eleven is e-\n",
    "# twelve is nu(e)\n",
    "# thirteen is mu-\n",
    "# fourteen is nu(mu)\n",
    "# print(len(nothing_dict[240]))\n",
    "# final_nothing_dict[240][\"mc_pdg\"].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6e90a7-0c51-4c0c-9bdb-e16224bf0adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_index_dict = {}\n",
    "for HNL_mass in signal_samples_dict:\n",
    "    filtered_index_dict[HNL_mass] = filtered_dict[HNL_mass].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e679d0ba-fd42-463f-a87e-713f90784ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Num_evs = len(signal_samples_dict[150])\n",
    "print(Num_evs)\n",
    "entries = np.arange(0, Num_evs,1)\n",
    "print(entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeb5954-d3de-496f-9328-775df46809e3",
   "metadata": {},
   "source": [
    "## Creating new variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74122a3a-50e1-4877-a9d5-5b3d6acd8b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(signal_samples_dict[150]['mc_E'][0][0]/signal_samples_dict[150]['mc_E'][0][1])\n",
    "df = signal_samples_dict[150]\n",
    "dot_product = (df['mc_px'][0]*df['mc_px'][1] + df['mc_py'][0]*df['mc_py'][1] + df['mc_pz'][0]*df['mc_pz'][1])\n",
    "print(type(dot_product))\n",
    "print(dot_product)\n",
    "print(df['mc_px'][0])\n",
    "print(max(df['mc_px'][0]))\n",
    "print(min(df['mc_px'][0]))\n",
    "\n",
    "print(\"Num evs is \" + str(len(signal_samples_dict[150])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f844f42-f6b9-49b4-af83-1b755f7d8352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_new_variables(df, entries=[]): #For unflattened dfs\n",
    "    if isinstance(entries,list): \n",
    "        Num_evs = len(df)\n",
    "        entries_it = np.arange(0, Num_evs,1)\n",
    "    else: entries_it = entries\n",
    "    # Num_evs = len(df)\n",
    "    mc_p_magnitude = []\n",
    "    mc_px_sum, mc_py_sum, mc_pz_sum = [], [], []\n",
    "    mc_E_leading, mc_E_sub, mc_E_asymmetry = [], [], []\n",
    "    mc_cos_opening_angle, mc_opening_angle = [], []\n",
    "    \n",
    "    # for i in range(Num_evs):\n",
    "    for i in entries_it:\n",
    "        mc_p1 = np.sqrt(df['mc_px'][i][0]**2+df['mc_py'][i][0]**2+df['mc_pz'][i][0]**2)\n",
    "        mc_p2 = np.sqrt(df['mc_px'][i][1]**2+df['mc_py'][i][1]**2+df['mc_pz'][i][1]**2)\n",
    "        mc_p_magnitude.append(np.array([mc_p1,mc_p2]))\n",
    "        mc_px_sum.append(df['mc_px'][i][0]+df['mc_px'][i][1])\n",
    "        mc_py_sum.append(df['mc_py'][i][0]+df['mc_py'][i][1])\n",
    "        mc_pz_sum.append(df['mc_pz'][i][0]+df['mc_pz'][i][1])\n",
    "        mc_E_leading.append(max(df['mc_E'][i]))\n",
    "        mc_E_sub.append(min(df['mc_E'][i]))\n",
    "        mc_E_asymmetry.append(min(df['mc_E'][i]) / max(df['mc_E'][i]))\n",
    "        \n",
    "        dot_product = (df['mc_px'][i][0]*df['mc_px'][i][1] + df['mc_py'][i][0]*df['mc_py'][i][1] + df['mc_pz'][i][0]*df['mc_pz'][i][1])\n",
    "        magnitude_dot_product = mc_p1*mc_p2\n",
    "        mc_cos_opening_angle.append(dot_product/magnitude_dot_product)\n",
    "        mc_opening_angle.append(np.arccos(dot_product/magnitude_dot_product))\n",
    "        \n",
    "        \n",
    "    df2 = df.copy()\n",
    "    df2[\"mc_px_sum\"], df2[\"mc_py_sum\"], df2[\"mc_pz_sum\"] = np.array(mc_px_sum), np.array(mc_py_sum), np.array(mc_pz_sum)\n",
    "    df2[\"mc_p_magnitude\"] = mc_p_magnitude\n",
    "    df2[\"mc_E_leading\"], df2[\"mc_E_sub\"] = np.array(mc_E_leading), np.array(mc_E_sub)\n",
    "    df2[\"mc_E_asymmetry\"] = np.array(mc_E_asymmetry)\n",
    "    df2[\"mc_cos_opening_angle\"] = np.array(mc_cos_opening_angle)\n",
    "    df2[\"mc_opening_angle\"] = np.array(mc_opening_angle)\n",
    "   \n",
    "    return df2\n",
    "\n",
    "def Make_angle_wrt(df, vector, entries=[]):\n",
    "    \"\"\"\n",
    "    Vector should be a unit vector, for the desired direction. \n",
    "    \"\"\"\n",
    "    if isinstance(entries,list): \n",
    "        Num_evs = len(df)\n",
    "        entries_it = np.arange(0, Num_evs,1)\n",
    "    else: entries_it = entries\n",
    "    # Num_evs = len(df)\n",
    "    \n",
    "    polar_angle = []\n",
    "    # for i in range(Num_evs):\n",
    "    for i in entries_it:\n",
    "        direction = vector[0]*df[\"mc_px_sum\"][i] + vector[1]*df[\"mc_py_sum\"][i] + vector[2]*df[\"mc_pz_sum\"][i]\n",
    "        p_sum = np.sqrt(df[\"mc_px_sum\"][i]+df[\"mc_py_sum\"][i]+df[\"mc_pz_sum\"][i])\n",
    "        polar_angle.append(np.arccos(direction/p_sum))\n",
    "        \n",
    "    df2 = df.copy()\n",
    "    df2[\"mc_polar_angle\"] = np.array(polar_angle)\n",
    "    \n",
    "    return df2\n",
    "\n",
    "def Make_single_new_variables(df, rest_mass, entries=[]):\n",
    "    if isinstance(entries,list): \n",
    "        Num_evs = len(df)\n",
    "        entries_it = np.arange(0, Num_evs,1)\n",
    "    else: entries_it = entries\n",
    "    \n",
    "    mc_p_magnitude = []\n",
    "    mc_E_kinetic = []\n",
    "    for i in entries_it:\n",
    "        mc_p = np.sqrt(df['mc_px'][i]**2+df['mc_py'][i]**2+df['mc_pz'][i]**2)\n",
    "        mc_E = df['mc_E'][i] - rest_mass\n",
    "        \n",
    "        mc_p_magnitude.append(mc_p)\n",
    "        mc_E_kinetic.append(mc_E)\n",
    "        \n",
    "    df2 = df.copy()\n",
    "    df2[\"mc_p_magnitude\"] = mc_p_magnitude\n",
    "    df2[\"mc_E_kinetic\"] = mc_E_kinetic\n",
    "    \n",
    "    return df2\n",
    "\n",
    "def Make_single_angle(df, vector, entries=[]):\n",
    "    \"\"\"\n",
    "    Vector should be a unit vector, for the desired direction. \n",
    "    \"\"\"\n",
    "    if isinstance(entries,list): \n",
    "        Num_evs = len(df)\n",
    "        entries_it = np.arange(0, Num_evs,1)\n",
    "    else: entries_it = entries\n",
    "    # Num_evs = len(df)\n",
    "    \n",
    "    polar_angle = []\n",
    "    # for i in range(Num_evs):\n",
    "    for i in entries_it:\n",
    "        direction = vector[0]*df[\"mc_px\"][i] + vector[1]*df[\"mc_py\"][i] + vector[2]*df[\"mc_pz\"][i]\n",
    "        p_sum = np.sqrt(df[\"mc_px\"][i]+df[\"mc_py\"][i]+df[\"mc_pz\"][i])\n",
    "        polar_angle.append(np.arccos(direction/p_sum))\n",
    "        \n",
    "    df2 = df.copy()\n",
    "    df2[\"mc_polar_angle_single\"] = np.array(polar_angle)\n",
    "    \n",
    "    return df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085d8d21-525a-4dd1-ac50-d41b69e9cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for HNL_mass in signal_samples_dict:\n",
    "    # signal_samples_dict[HNL_mass]=Make_new_variables(signal_samples_dict[HNL_mass], filtered_index_dict[HNL_mass])\n",
    "    signal_samples_dict[HNL_mass]=Make_new_variables(signal_samples_dict[HNL_mass], signal_samples_dict[HNL_mass].index)\n",
    "    print(f\"Done {HNL_mass}MeV\")\n",
    "print(\"Done\")\n",
    "    \n",
    "# direction = [0, 0, 1]\n",
    "direction = av_HNL_direction\n",
    "\n",
    "for HNL_mass in signal_samples_dict:\n",
    "    signal_samples_dict[HNL_mass]=Make_angle_wrt(signal_samples_dict[HNL_mass], direction, [])\n",
    "    # if load_pi0_signal == True:\n",
    "    #     pi0_dict[HNL_mass]=Make_single_angle(pi0_dict[HNL_mass], direction, filtered_index_dict[HNL_mass])\n",
    "    print(f\"Done {HNL_mass}MeV\")\n",
    "# test_df = Make_new_variables(signal_samples_dict[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeef9c0c-9bb6-4af4-aa35-3857cc7b3acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_samples_dict[150].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fd6c8c-25f1-4c48-9624-68de5a4e12e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi0_dict[150].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f407455-d8ab-4f4e-b07c-0f4440c7106f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi0_mass = 0.135 #GeV\n",
    "direction = av_HNL_direction\n",
    "if load_pi0_signal == True:\n",
    "    for HNL_mass in pi0_dict:\n",
    "        pi0_dict[HNL_mass]=Make_single_new_variables(pi0_dict[HNL_mass], pi0_mass, entries=pi0_dict[HNL_mass].index)\n",
    "        pi0_dict[HNL_mass]=Make_single_angle(pi0_dict[HNL_mass], direction, entries=pi0_dict[HNL_mass].index)\n",
    "        print(f\"Done {HNL_mass}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271ebd0b-4d89-4bbb-ae99-a4c02141ae32",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4ca553-87da-48bd-a6cc-19ea3c30e03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_variable_signal(variable, HNL_samples_dict=[], xlabel=[], xlims=[0,0], bins=40, figsize=[10,10], dpi=100, xticks=[], \n",
    "                         density=True,legloc=\"best\",logy = False, cutline = None, savefig=False, filename=None, plot_entries=False,fraction=False):\n",
    "    \n",
    "    if(HNL_samples_dict==[]): raise Exception(\"Specify samples dict\") \n",
    "    if(xlabel==[]): xlabel=variable\n",
    "    \n",
    "    if logy == True:\n",
    "        logscale=\"log\"\n",
    "    elif logy == False:\n",
    "        logscale=\"linear\"\n",
    "    \n",
    "    fig,ax = plt.subplots(nrows=1, ncols=1, sharex=True, figsize=figsize,dpi=dpi)\n",
    "    \n",
    "    for HNL_mass in HNL_samples_dict:\n",
    "    \n",
    "        #var_HNL=HNL_samples_dict[HNL_mass][variable] #old way when specifying variable\n",
    "        var_HNL=HNL_samples_dict[HNL_mass]\n",
    "        Num_entries = len(var_HNL)\n",
    "       \n",
    "        if xlims[0] == 0 and xlims[1] == 0: xlims = [min(var_HNL),max(var_HNL)]\n",
    "    \n",
    "        if(isinstance(bins, int)):\n",
    "            nbins=bins\n",
    "            bins=np.linspace(xlims[0],xlims[1],nbins+1)\n",
    "        else: nbins=len(bins)-1\n",
    "    \n",
    "    #plt.sca(ax[0])\n",
    "               \n",
    "        if plot_entries==True: label=[f\"{HNL_mass} MeV HNL: \" + str(Num_entries) + \" entries\"]\n",
    "        if plot_entries==False: label=[f\"{HNL_mass} MeV HNL\"]\n",
    "                   \n",
    "        if fraction == False:\n",
    "            plt.hist(var_HNL,\n",
    "    #               label=[f\"HNL ({mass} MeV) \\n $|U_{{\\mu4}}|^2=\"+sci_notation(sample_info[\"300\"][\"theta_u2\"]) +f\" (x{HNLplotscale})\"],\n",
    "                  label=label,\n",
    "                  range=xlims,bins=bins,\n",
    "                  stacked=False,density=density,\n",
    "                  histtype=\"step\",lw=3)\n",
    "        if fraction == True:\n",
    "            plt.hist(var_HNL,weights=np.ones(len(var_HNL)) / len(var_HNL),\n",
    "                     label=label,\n",
    "                  range=xlims,bins=bins,\n",
    "                  stacked=False,density=False,\n",
    "                  histtype=\"step\",lw=3)\n",
    "    \n",
    "    if(isinstance(cutline, (int,float))):\n",
    "        plt.axvline(x=cutline, lw=3, color='green', linestyle = 'dashed')\n",
    "    \n",
    "    if(logy == True):\n",
    "        plt.yscale(\"log\")\n",
    "    else:\n",
    "        plt.yscale(\"linear\")\n",
    "        \n",
    "    if(density == True):\n",
    "        plt.ylabel(\"Fraction of total events\")\n",
    "    \n",
    "    plt.legend(loc=legloc,frameon=False)\n",
    "    \n",
    "    plt.xlabel(xlabel)\n",
    "    plt.xlim(xlims)\n",
    "    if xticks != []:\n",
    "        plt.xticks(xticks)\n",
    "    # plt.tight_layout(rect=[0, 0, 1, 0.92])\n",
    "    plt.tight_layout()\n",
    "    plt.yscale(logscale)\n",
    "    if filename == None:\n",
    "        Name = variable + \"_\" + Run + \"_\" + logscale\n",
    "    else:\n",
    "        Name = filename\n",
    "    if savefig == True:\n",
    "        plt.savefig(\"plots/Truth_studies/Signal_plots/\" + Name + \".png\")\n",
    "        plt.savefig(\"plots/Truth_studies/Signal_plots/\" + Name + \".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17645472-141b-42d9-86a3-1be7c5f4b82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_variable(df,variable,debug=True): #The df should NOT be flattened. Will return a series which can be plotted. \n",
    "    first_entry = df.index[0]\n",
    "    if isinstance(df[variable][first_entry], (np.ndarray)):\n",
    "        if(debug):print(\"This variable has an array of entries per event.\")\n",
    "        Num_events = len(df[variable])\n",
    "        if(debug):print(\"The total number of events is \" + str(Num_events))\n",
    "        copy_column = df[variable].copy()\n",
    "        exploded = copy_column.explode(variable)\n",
    "        Num_nans = exploded.isna().sum()\n",
    "        if(debug):print(\"The number of events with empty arrays is \" + str(Num_nans))\n",
    "        if(debug):print(\"Fraction of non-empty arrays is \" + str(1-(Num_nans/Num_events)))\n",
    "        Nans_removed = exploded.dropna()\n",
    "        Num_entries = len(Nans_removed)\n",
    "        if(debug):print(\"The total number of entries is \" + str(Num_entries))\n",
    "        \n",
    "        return Nans_removed, Num_entries\n",
    "    if isinstance(df[variable][first_entry], (int,float,np.int32,np.float32,np.uint32,np.nan)):\n",
    "        if(debug):print(\"This variable has one entry per event.\")\n",
    "        Num_events = len(df[variable])\n",
    "        if(debug):print(\"The total number of events is \" + str(Num_events))\n",
    "        copy_column = df[variable].copy()\n",
    "        Num_nans = copy_column.isna().sum()\n",
    "        if Num_nans != 0:\n",
    "            if(debug):print(\"There are \" + str(Num_nans) + \" Nan values, removing now\")\n",
    "            copy_column.dropna()\n",
    "        Num_entries = len(copy_column)\n",
    "        return copy_column, Num_entries\n",
    "    else: print(\"Not sure what type this variable is!\")\n",
    "    \n",
    "def remove_non_reco_vals(df,debug=True): #Feed in the output of the check_variable\n",
    "    #value = -1e15\n",
    "    value = -9999\n",
    "    first_entry = df.index[0]\n",
    "    if(debug):print(\"Total number of entries is \" + str(len(df)))\n",
    "    if(debug):print(\"Number of very negative values is \" + str(len(df.loc[df < value])))\n",
    "\n",
    "    if(len(df.loc[df < value]) > 0):\n",
    "        new_df = df.drop(df.loc[df < value].index) #Removes values entirely\n",
    "        if(debug):print(\"New number of entries is \" + str(len(new_df)))\n",
    "            # if(len(df.loc[df == -1.0]) > 0):\n",
    "            #     df.loc[(df == -1.0), variable] = new_value #Sets the new value\n",
    "            # if(len(df.loc[df == np.nan]) > 0):\n",
    "            #     df.loc[(df == np.nan), variable] = new_value #Sets the new value\n",
    "            # if(len(df.loc[df == np.inf]) > 0):\n",
    "            #     df.loc[(df == np.inf), variable] = new_value #Sets the new value\n",
    "    else: new_df = df.copy()\n",
    "    return new_df, len(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb054721-63e9-4c6e-8838-af5a6de493f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_names_dict = {'mc_px_sum':\"Sum of x-momenta [GeV]\", 'mc_py_sum':\"Sum of y-momenta [GeV]\", 'mc_pz_sum':\"Sum of z-momenta [GeV]\",\n",
    "                       'mc_p_magnitude':\"Magnitude of lepton momenta [GeV]\", 'mc_E_leading':\"Leading lepton energy [GeV]\",\n",
    "                       'mc_E':\"Energy [GeV]\", 'mc_px':\"Momentum in x-direction [GeV]\", 'mc_py':\"Momentum in y-direction [GeV]\",\n",
    "                       'mc_pz':\"Momentum in z-direction [GeV]\", 'mc_p_magnitude':\"Momentum [GeV]\", 'mc_E_kinetic':\"Kinetic energy [GeV]\",\n",
    "       'mc_E_sub':\"Sub-leading lepton energy [GeV]\", 'mc_E_asymmetry':\"Energy asymmetry\", 'mc_cos_opening_angle':\"cosine(opening angle)\",\n",
    "       'mc_opening_angle':\"Opening angle [radians]\", 'mc_polar_angle':\"Angle w.r.t parent HNL [radians]\",\n",
    "                       \"mc_polar_angle_single\":\"Angle w.r.t parent HNL [radians]\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eecce91-6b78-45b3-a58c-28d1eff077df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot_only_lepton = False #Final state is e+e-\n",
    "Plot_only_pi0 = True #Final state is pi0\n",
    "\n",
    "if Plot_only_lepton == True: sample_dict = signal_samples_dict\n",
    "elif Plot_only_pi0 == True: sample_dict = pi0_dict\n",
    "elif signal_like == True: sample_dict = signal_like_dict\n",
    "\n",
    "print_vals = input(\"Do you want to print all the variables in the sample? y/n \")\n",
    "if print_vals == \"y\":\n",
    "    var_list = []\n",
    "    for var in sample_dict[150].keys():\n",
    "        var_list.append(var)\n",
    "    print(var_list)\n",
    "else:\n",
    "    print(\"Not printing variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a34b280-da2c-4cab-919a-0a862887a9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'mc_p_magnitude'\n",
    "plot_dict = {}\n",
    "Num_entries_dict = {}\n",
    "debug = False\n",
    "\n",
    "plot_all_masses = False\n",
    "if plot_all_masses == True: plot_samples = sample_dict.keys()\n",
    "if plot_all_masses == False: plot_samples = [150, 180, 200, 240, 245]\n",
    "\n",
    "for sample in plot_samples:\n",
    "    print(f\"Mass is {sample} MeV\")\n",
    "    plot_dict[sample], Num_entries_dict[sample] = check_variable(sample_dict[sample],var,debug=debug)\n",
    "    plot_dict[sample], Num_entries_dict[sample] = remove_non_reco_vals(plot_dict[sample],debug=debug)\n",
    "    \n",
    "print()\n",
    "var_2 = 'mc_polar_angle_single'\n",
    "plot_dict_2 = {}\n",
    "Num_entries_dict_2 = {}\n",
    "\n",
    "for sample in plot_samples:\n",
    "    print(f\"Mass is {sample} MeV\")\n",
    "    plot_dict_2[sample], Num_entries_dict_2[sample] = check_variable(sample_dict[sample],var_2,debug=debug)\n",
    "    plot_dict_2[sample], Num_entries_dict_2[sample] = remove_non_reco_vals(plot_dict_2[sample],debug=debug)\n",
    "    \n",
    "# plot_dict[150].head()\n",
    "# Particle.from_pdgid(11)\n",
    "print()\n",
    "var_3 = 'mc_E_kinetic'\n",
    "plot_dict_3 = {}\n",
    "Num_entries_dict_3 = {}\n",
    "if load_pi0_signal == True:\n",
    "    for sample in pi0_dict:\n",
    "        print(f\"Mass is {sample} MeV\")\n",
    "        plot_dict_3[sample], Num_entries_dict_3[sample] = check_variable(pi0_dict[sample],var_3,debug=debug)\n",
    "        plot_dict_3[sample], Num_entries_dict_3[sample] = remove_non_reco_vals(plot_dict_3[sample],debug=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e1d26f-0989-41b8-a776-263f828b286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_pi0_signal == True:\n",
    "    Plot_variable_signal(var_3, HNL_samples_dict=plot_dict_3, xlabel=variable_names_dict[var_3], xlims=[0,2.0], bins=50, \n",
    "                     figsize=[8,8], dpi=100, xticks=[], density=True,legloc=\"best\",logy = False,\n",
    "                     cutline = None, savefig=True, filename = f\"pi0_{var_3}_{Run}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3e9b5d-9fd9-4ff1-ae20-5a2c61e2c73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mc_E Includes rest mass I believe. \n",
    "x_ticks = [0,0.05,0.1, 0.15, 0.2]\n",
    "Plot_variable_signal(var, HNL_samples_dict=plot_dict, xlabel=variable_names_dict[var], xlims=[0,0.2], bins=50, \n",
    "                     figsize=[8,8], dpi=100, xticks=x_ticks, density=True,legloc=\"best\",logy = False,\n",
    "                     cutline = None, savefig=True, filename = f\"pi0_{var}_{Run}\")\n",
    "# plt.xticks([0,0.05,0.1, 0.15, 0.2])\n",
    "# plt.ylim([0,10])\n",
    "# max_y, bin_edges = np.histogram(plot_dict[150], density=True, bins=40)\n",
    "# maxium = max(max_y)\n",
    "# max_x = max(bin_edges)\n",
    "# min_x = min(bin_edges)\n",
    "# print(maxium)\n",
    "# print(max_x)\n",
    "# print(min_x)\n",
    "# print(\"Max minus min is \" + str(max_x - min_x))\n",
    "# plt.ylim(0, maxium*1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dae51ea-6fab-4c6e-8ead-2632ec807dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot_variable_signal(var_2, HNL_samples_dict=plot_dict_2, xlabel=variable_names_dict[var_2], xlims=[0,3.2], bins=50, \n",
    "                     figsize=[8,8], dpi=100, xticks=[], density=True,legloc=\"upper left\",logy = False,\n",
    "                     cutline = None, savefig=True, filename = f\"pi0_{var_2}_{Run}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fee241-3cb7-4343-ae2c-301b82ca6fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dict[220].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd140a42-fdc2-4876-8ab5-8e55d9abf589",
   "metadata": {},
   "source": [
    "## 2D histogram of reco showers and tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e688a60e-603d-469a-8a85-e6842e9f0143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_fraction_recod(HNL_samples_dict=signal_samples_dict, variable='n_pfps'): #This should be fed with a dict of unflattened dataframes\n",
    "    frac_pfps_dict = {}\n",
    "    for HNL_mass in HNL_samples_dict:\n",
    "        Placeholder_list = []\n",
    "        Num_events = len(HNL_samples_dict[HNL_mass][variable])\n",
    "        for i in range(max(HNL_samples_dict[HNL_mass][variable])):\n",
    "            selection = HNL_samples_dict[HNL_mass].loc[(HNL_samples_dict[HNL_mass][variable] == i)]\n",
    "            Num_multiplicity = len(selection)\n",
    "            Placeholder_list.append(Num_multiplicity/Num_events)\n",
    "        frac_pfps_dict[HNL_mass] = Placeholder_list\n",
    "    return frac_pfps_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8807573f-2acf-431d-abf5-024c1b46b821",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_pfps_dict = Make_fraction_recod(HNL_samples_dict=sample_dict, variable='n_pfps')\n",
    "\n",
    "print(frac_pfps_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2715cbb8-bf25-43e9-abe7-51a1e29a46aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "HNL_mass = 150\n",
    "selection = sample_dict[HNL_mass].loc[(sample_dict[HNL_mass]['n_pfps'] == 2)]\n",
    "\n",
    "print(len(selection))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b6c4fb-75dd-4d57-9494-3687abb72a02",
   "metadata": {},
   "source": [
    "# End of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b317d8-d568-46bf-ba87-a40278b63177",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
