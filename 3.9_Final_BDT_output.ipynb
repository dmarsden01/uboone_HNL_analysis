{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe0cab0-578b-42ea-86af-07342852e08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading libraries\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import uproot3\n",
    "import uproot\n",
    "import math\n",
    "import pickle\n",
    "import csv\n",
    "from importlib import reload\n",
    "\n",
    "import Utilities.Constants as Constants\n",
    "import Utilities.Functions as Functions\n",
    "import Utilities.Plotter as PT\n",
    "from Utilities.ipython_exit import exit\n",
    "\n",
    "print(\"Successful!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29cd13c",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "This notebook is for plotting the BDT output score distributions, with the full uncertainties included. <br>\n",
    "The BDT output score .root files are loaded. The main choice is whether to plot the e+e- scores (Load\\_lepton\\_hists set to True) or the $\\pi^0$ scores (Load\\_pi0\\_hists set to True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6939111e-d766-4112-ab60-1fd7c65239ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Params_pyhf = {\"Stats_only\":False,\n",
    "               \"Use_flat_sys\":False,\n",
    "               \"Use_part_only\":False,\n",
    "               \"Num_bins_for_calc\":4,\n",
    "               \"Use_toys\":False,\n",
    "               \"Num_toys\":100,\n",
    "               \"Load_lepton_hists\":True,\n",
    "               \"Load_pi0_hists\":False,\n",
    "               \"Flat_bkg_overlay_frac\":0.3,\n",
    "               \"Flat_bkg_dirt_frac\":0.75,\n",
    "               \"Flat_bkg_EXT_frac\":0.0,\n",
    "               \"Flat_sig_detvar\":0.2, #This is very conservative, could be fed in per mass point from signal detvar script\n",
    "               \"Signal_flux_error\":0.3, #This comes from the KDAR flux uncertainty.\n",
    "               \"Overlay_detvar_frac\":0.3,\n",
    "               \"Load_lepton_dirac\":False,\n",
    "               \"Load_pi0_dirac\":False,\n",
    "               \"Load_single_r1_file\":False}\n",
    "\n",
    "Functions.pyhf_params(Params_pyhf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6695044e-f564-4ef5-8566-84a83162de29",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Params_pyhf[\"Load_lepton_hists\"] == True: \n",
    "    name_type=\"ee\"\n",
    "    HNL_masses = Constants.HNL_mass_samples\n",
    "if Params_pyhf[\"Load_pi0_hists\"] == True: \n",
    "    name_type=\"pi0\"\n",
    "    HNL_masses = Constants.HNL_mass_pi0_samples\n",
    "if Params_pyhf[\"Load_lepton_dirac\"] == True:\n",
    "    name_type=\"ee_dirac\"\n",
    "    HNL_masses = Constants.HNL_ee_dirac_mass_samples\n",
    "if Params_pyhf[\"Load_pi0_dirac\"] == True:\n",
    "    name_type=\"pi0_dirac\"\n",
    "    HNL_masses = Constants.HNL_pi0_dirac_mass_samples\n",
    "    \n",
    "BDT_name = \"_full_Finished_10\"\n",
    "\n",
    "filename = name_type+BDT_name\n",
    "\n",
    "hist_dict_run1, hist_dict_run3, theta_dict = Functions.New_Load_pyhf_files(f\"{filename}.root\",\n",
    "                                                                           Params_pyhf, HNL_masses = HNL_masses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b173fc-745a-42e8-b9f8-8b3b6e8c2792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_uncertainty_dicts(hist_dict, Params):\n",
    "    \"\"\"\n",
    "    Given a dict of uproot files will return the total signal uncertainty, bkg uncertainty and bin dicts.\n",
    "    \"\"\"\n",
    "    overlay_dict, dirt_dict, EXT_dict = {}, {}, {}\n",
    "    signal_dict = {}\n",
    "    bins_dict = {}\n",
    "    bins_cent_dict = {}\n",
    "    tot_uncertainty_dict = {}\n",
    "    sig_sys_err = {}\n",
    "    data = {}\n",
    "    \n",
    "    for HNL_mass in hist_dict:\n",
    "        overlay_dict[HNL_mass] = hist_dict[HNL_mass]['bkg_overlay'].to_numpy()[0]\n",
    "        dirt_dict[HNL_mass] = hist_dict[HNL_mass]['bkg_dirt'].to_numpy()[0]\n",
    "        EXT_dict[HNL_mass] = hist_dict[HNL_mass]['bkg_EXT'].to_numpy()[0]\n",
    "        signal_dict[HNL_mass] = hist_dict[HNL_mass]['signal'].to_numpy()[0]\n",
    "\n",
    "        tot_uncertainty = [hist_dict[HNL_mass]['ppfx_uncertainty_frac'].to_numpy()[0]*hist_dict[HNL_mass]['bkg_overlay'].to_numpy()[0], #overlay ppfx error\n",
    "                           hist_dict[HNL_mass]['Genie_uncertainty_frac'].to_numpy()[0]*hist_dict[HNL_mass]['bkg_overlay'].to_numpy()[0], #overlay genie error\n",
    "                           hist_dict[HNL_mass]['Reinteraction_uncertainty_frac'].to_numpy()[0]*hist_dict[HNL_mass]['bkg_overlay'].to_numpy()[0], #overlay reinteraction error\n",
    "                           hist_dict[HNL_mass]['overlay_DetVar_uncertainty_frac'].to_numpy()[0]*hist_dict[HNL_mass]['bkg_overlay'].to_numpy()[0], #overlay detector variation error\n",
    "                           hist_dict[HNL_mass]['bkg_dirt'].to_numpy()[0]*Params[\"Flat_bkg_dirt_frac\"], #dirt flat systematic error\n",
    "                           hist_dict[HNL_mass]['bkg_overlay'].errors(), #stat error\n",
    "                           hist_dict[HNL_mass]['bkg_dirt'].errors(), #stat error\n",
    "                           hist_dict[HNL_mass]['bkg_EXT'].errors()] #stat error\n",
    "\n",
    "        tot_sig_unc = [hist_dict[HNL_mass]['signal'].errors(),\n",
    "                       # hist_dict[HNL_mass][\"signal_DetVar_uncertainty\"].values(),\n",
    "                       # hist_dict[HNL_mass]['overlay_DetVar_uncertainty_frac'].to_numpy()[0]*hist_dict[HNL_mass]['signal'].to_numpy()[0], #WRONG!\n",
    "                       hist_dict[HNL_mass]['signal_DetVar_uncertainty_frac'].to_numpy()[0]*hist_dict[HNL_mass]['signal'].to_numpy()[0], #WRONG!\n",
    "                       hist_dict[HNL_mass]['signal'].values()*Params[\"Signal_flux_error\"]]\n",
    "\n",
    "        sig_sys_err[HNL_mass] = Functions.add_all_errors(tot_sig_unc)\n",
    "\n",
    "        tot_uncertainty_dict[HNL_mass] = Functions.add_all_errors(tot_uncertainty)\n",
    "\n",
    "        bins_dict[HNL_mass] = hist_dict[HNL_mass]['bkg_overlay'].to_numpy()[1] #A tuple of bin edges\n",
    "        bins_cent_dict[HNL_mass]=(bins_dict[HNL_mass][:-1]+bins_dict[HNL_mass][1:])/2\n",
    "\n",
    "        data[HNL_mass] = hist_dict[HNL_mass]['data'].values()\n",
    "\n",
    "    bkgs_dict = {'overlay':overlay_dict, 'dirtoverlay':dirt_dict, 'beamoff':EXT_dict}\n",
    "    \n",
    "    return signal_dict, bkgs_dict, data, sig_sys_err, tot_uncertainty_dict, bins_dict, bins_cent_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2187acf-f6ed-4374-80e0-f85ca5fb6170",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_dict_r1, bkgs_dict_r1, data_r1, sig_sys_err_r1, tot_uncertainty_dict_r1, bins_dict_r1, bins_cent_dict_r1 = Get_uncertainty_dicts(hist_dict_run1, \n",
    "                                                                                                                                        Params_pyhf)\n",
    "signal_dict_r3, bkgs_dict_r3, data_r3, sig_sys_err_r3, tot_uncertainty_dict_r3, bins_dict_r3, bins_cent_dict_r3 = Get_uncertainty_dicts(hist_dict_run3, \n",
    "                                                                                                                                        Params_pyhf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2fc94c-d134-405b-90e6-fcebbe60445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_overflow_bin(bins_dict, bins_cents_dict):\n",
    "    \"\"\"\n",
    "    For making the final \"overflow\" bin the same size as the previous bins, i.e one integer in width.\n",
    "    \"\"\"\n",
    "    bins_overflow, bins_cent_overflow = {}, {}\n",
    "    for HNL_mass in bins_dict:\n",
    "        overflow_bin = bins_cents_dict[HNL_mass][-2]+1 #Just adding one to the penultimate bin centre val. \n",
    "        bins_cent_overflow[HNL_mass] = bins_cents_dict[HNL_mass].copy()\n",
    "        bins_cent_overflow[HNL_mass][-1] = overflow_bin\n",
    "        bins_overflow[HNL_mass] = bins_dict[HNL_mass].copy()\n",
    "        bins_overflow[HNL_mass][-1] = bins_dict[HNL_mass][-2]+1 #Just adding one to the penultimate bin end val. \n",
    "    return bins_overflow, bins_cent_overflow\n",
    "\n",
    "bins_overflow_r1, bins_cents_overflow_r1 = make_overflow_bin(bins_dict_r1, bins_cent_dict_r1)\n",
    "bins_overflow_r3, bins_cents_overflow_r3 = make_overflow_bin(bins_dict_r3, bins_cent_dict_r3)\n",
    "\n",
    "def make_xlims_dict(bins_dict, lower = None):\n",
    "    \"\"\"\n",
    "    Making a dict of xlims for plotting several mass points at once.\n",
    "    Also returns a dict of xticks for the purpose of indicating the overflow.\n",
    "    \"\"\"\n",
    "    xlims_adjusted, xticks_adjusted = {}, {}\n",
    "    for HNL_mass in bins_dict:\n",
    "        if isinstance(lower,(int, float)): lower_val = lower\n",
    "        else: lower_val = bins_dict[HNL_mass][0]\n",
    "        xlims_adjusted[HNL_mass] = [lower_val,bins_dict[HNL_mass][-1]]\n",
    "        ticks = np.arange(bins_dict[HNL_mass][0], bins_dict[HNL_mass][-1], 1)\n",
    "        ticks_strings = []\n",
    "        for val in ticks:\n",
    "            ticks_strings.append(str(int(val)))\n",
    "        ticks_strings[-1] = str(ticks_strings[-1])+\"+\"\n",
    "        xticks_adjusted[HNL_mass] = ticks_strings\n",
    "        \n",
    "    return xlims_adjusted, xticks_adjusted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95023d1-464b-47f7-96e4-e1f6ca032f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_BDT_output_systematics(signal={}, tot_uncertainty_dict={}, sig_unc={}, bkgs={}, bins_cent_dict={}, bins_dict={}, colours={}, ALPHA=1.0, xlims=[0,5.0],\n",
    "                                figsize=[12,8], density=False, legloc=\"upper right\",legsize=22,\n",
    "                                logy=False, savefig=False, save_str=\"\", Run=\"_\", HNL_scale=1.0,scale_up=[], thetas=[], order=[],\n",
    "                                sig_sys=False,HNL_scale_label=False):\n",
    "    \"\"\"\n",
    "    This should take the histograms which have already been binned and scaled and plot the total uncertainties on bkg.\n",
    "    Therefore it will display what is being fed into the limit setting software.\n",
    "    \"\"\"\n",
    "    if(isinstance(HNL_scale, float)): print(\"Scaling by a single number for all\")\n",
    "    if(isinstance(HNL_scale, dict)): print(\"Scaling each mass point individually\")\n",
    "    if(signal=={}): raise Exception(\"Specify HNL sample masses\")\n",
    "    if(bkgs=={}): raise Exception(\"Specify background samples\")\n",
    "    if(bins_cent_dict=={}): raise Exception(\"Specify bin centres\")\n",
    "    if(bins_dict=={}): raise Exception(\"Specify bins\")\n",
    "    if(colours=={}): colours = {'overlay':Constants.sample_colours['overlay'],\n",
    "                                'dirtoverlay':Constants.sample_colours['dirtoverlay'],\n",
    "                                'beamoff':Constants.sample_colours['beamoff'],\n",
    "                                'signal':Constants.sample_colours['signal']}\n",
    "    if(order==[]): order = [\"beamoff\",\"overlay\",\"dirtoverlay\"] #From bottom to top in stack\n",
    "    if(thetas==[]): print(\"Haven't entered thetas, can't calculate scalings\") \n",
    "    \n",
    "    if logy == True:\n",
    "        logscale=\"log\"\n",
    "    elif logy == False:\n",
    "        logscale=\"linear\"\n",
    "    \n",
    "    for HNL_mass in signal.keys():\n",
    "        plt.figure(figsize=figsize,facecolor='white')\n",
    "        if(isinstance(HNL_scale, dict)):\n",
    "            HNL_scaling=HNL_scale[HNL_mass]\n",
    "        else: HNL_scaling = HNL_scale\n",
    "        print(\"HNL scale is \" + str(HNL_scaling))\n",
    "        \n",
    "        bins_cents=[bins_cent_dict[HNL_mass], bins_cent_dict[HNL_mass], bins_cent_dict[HNL_mass]]\n",
    "        \n",
    "        if HNL_scale_label==False: HNL_label = f\"{HNL_mass} MeV HNL\"\n",
    "        if HNL_scale_label==True: \n",
    "            theta = thetas[HNL_mass]\n",
    "            theta_2 = theta**2\n",
    "            new_theta_2 = np.sqrt(scale_up[HNL_mass])*theta_2\n",
    "            theta_2_label = PT.sci_notation(new_theta_2, decimal_digits=0)\n",
    "            HNL_label = f\"{HNL_mass} MeV HNL \\n\" + r\"$|U_{\\mu4}|^2$ = \" + theta_2_label\n",
    "        \n",
    "        labels_sample = {'overlay':fr\"In-Cryo $\\nu$\",\n",
    "                         'dirtoverlay':fr\"Out-Cryo $\\nu$\",\n",
    "                         'beamoff':f\"Beam-Off\",\n",
    "                         'signal':HNL_label}\n",
    "                         #'signal':f\"{HNL_mass} MeV HNL\"}\n",
    "\n",
    "        bkg_scores, bkg_colors, labels = [], [], []\n",
    "        for sample in order:\n",
    "            bkg_scores.append(bkgs[sample][HNL_mass])\n",
    "            bkg_colors.append(colours[sample])\n",
    "            labels.append(labels_sample[sample])\n",
    "        \n",
    "        hist_placeholder = np.histogram(bins_cents, weights=bkg_scores, range=xlims)[0] #Just for calculating ylims\n",
    "        \n",
    "        hist_full_placeholder = np.histogram(bins_cents, weights=bkg_scores, bins=bins_dict[HNL_mass])[0] #For making the error bars\n",
    "        numbins = len(np.where( bins_cent_dict[HNL_mass] > xlims[0] )[0])+1 #Getting the number of bins that will be plotted with the given xlims range\n",
    "               \n",
    "        plot=plt.hist(bins_cents,\n",
    "                      label=labels,\n",
    "                      bins=bins_dict[HNL_mass],\n",
    "                      histtype=\"stepfilled\",\n",
    "                      stacked=True,linewidth=2,edgecolor=\"black\",\n",
    "                      weights=bkg_scores, color=bkg_colors, alpha=ALPHA)\n",
    "        \n",
    "        tot_uncrt = tot_uncertainty_dict[HNL_mass]\n",
    "        upvals_placeholder = hist_full_placeholder+tot_uncrt\n",
    "        lowvals_placeholder = hist_full_placeholder-tot_uncrt\n",
    "        upvals = np.append(upvals_placeholder, [0])\n",
    "        lowvals = np.append(lowvals_placeholder, [0])\n",
    "        \n",
    "        maxy = max(upvals[-numbins:])\n",
    "        \n",
    "        plt.fill_between(bins_dict[HNL_mass], lowvals, upvals, step=\"post\",color=\"grey\",alpha=0.3,zorder=2)\n",
    "\n",
    "        plt.hist(bins_cent_dict[HNL_mass],\n",
    "                 weights=signal[HNL_mass]*HNL_scaling,\n",
    "                 bins=bins_dict[HNL_mass],\n",
    "                 lw=4, edgecolor=colours['signal'], label=labels_sample[\"signal\"], histtype=\"step\")\n",
    "        \n",
    "        sig_placeholder = np.histogram(bins_cent_dict[HNL_mass], weights=signal[HNL_mass]*HNL_scaling, bins=bins_dict[HNL_mass])[0] #For making the error bars\n",
    "        sig_down_placeholder = sig_placeholder-sig_unc[HNL_mass]*HNL_scaling\n",
    "        sig_up_placeholder = sig_placeholder+sig_unc[HNL_mass]*HNL_scaling\n",
    "        sig_down = np.append(sig_down_placeholder, [0])\n",
    "        sig_up = np.append(sig_up_placeholder, [0])\n",
    "        \n",
    "        if sig_sys == True:\n",
    "            plt.rcParams.update({'hatch.color': colours['signal']})\n",
    "            plt.fill_between(bins_dict[HNL_mass], sig_down, sig_up, step=\"post\",hatch='//',alpha=0,zorder=2,lw=2)\n",
    "        \n",
    "        ylims = [0,maxy*1.1]\n",
    "        plt.legend(loc=legloc,frameon=True, fontsize = legsize)\n",
    "        \n",
    "        plt.xlim(xlims)\n",
    "        if logy==False:\n",
    "            plt.ylim(ylims)\n",
    "        \n",
    "        plt.xlabel('BDT score', fontsize=30)\n",
    "        plt.ylabel('Events', fontsize=30)\n",
    "        plt.yscale(logscale)\n",
    "        plt.tight_layout()\n",
    "        if savefig == True:\n",
    "            plt.savefig(\"plots/BDT_output/Final_histograms/BDT_output_\" + Run + \"_\" + str(HNL_mass) + \"MeV_\" + logscale + save_str + \".pdf\")\n",
    "            plt.savefig(\"plots/BDT_output/Final_histograms/BDT_output_\" + Run + \"_\" + str(HNL_mass) + \"MeV_\" + logscale + save_str + \".png\")\n",
    "        plt.show()\n",
    "        \n",
    "def Plot_BDT_output_systematics_data(signal={}, tot_uncertainty_dict={}, sig_unc={}, bkgs={}, data={}, bins_cent_dict={}, bins_dict={},\n",
    "                                     colours={}, ALPHA=1.0, xlims=[], xticks=[], upper_y=[],\n",
    "                                     figsize=[12,10], density=False, legloc=\"upper right\",legsize=22,\n",
    "                                     logy=False, savefig=False, save_str=\"\", Run=\"_\", HNL_scale=1.0,scale_up=[], thetas=[], order=[], \n",
    "                                     sig_sys=False, HNL_scale_label=False, stacked=False, title_name=None, textpos=None, textsize=None,\n",
    "                                     plot_text=None):\n",
    "    \"\"\"\n",
    "    This should take the histograms which have already been binned and scaled and plot the total uncertainties on bkg.\n",
    "    Therefore it will display what is being fed into the limit setting software. INCLUDING the data.\n",
    "    \"\"\"\n",
    "    if(isinstance(HNL_scale, float)): print(\"Scaling by a single number for all\")\n",
    "    if(isinstance(HNL_scale, dict)): print(\"Scaling each mass point individually\")\n",
    "    if(signal=={}): raise Exception(\"Specify HNL sample masses\")\n",
    "    if(bkgs=={}): raise Exception(\"Specify background samples\")\n",
    "    if(data=={}): raise Exception(\"Specify data sample\")\n",
    "    if(bins_cent_dict=={}): raise Exception(\"Specify bin centres\")\n",
    "    if(bins_dict=={}): raise Exception(\"Specify bins\")\n",
    "    if(colours=={}): colours = {'overlay':Constants.sample_colours['overlay'],\n",
    "                                'dirtoverlay':Constants.sample_colours['dirtoverlay'],\n",
    "                                'beamoff':Constants.sample_colours['beamoff'],\n",
    "                                'signal':Constants.sample_colours['signal']}\n",
    "    if(order==[]): order = [\"beamoff\",\"overlay\",\"dirtoverlay\"] #From bottom to top in stack\n",
    "    if(thetas==[]): print(\"Haven't entered thetas, can't calculate scalings\") \n",
    "    \n",
    "    if logy == True:\n",
    "        logscale=\"log\"\n",
    "    elif logy == False:\n",
    "        logscale=\"linear\"\n",
    "    \n",
    "    for HNL_mass in signal.keys():\n",
    "        \n",
    "        fig,ax = plt.subplots(nrows=2, ncols=1, sharex=True, gridspec_kw={'height_ratios': [3, 1]}, figsize=figsize,dpi=100)\n",
    "        \n",
    "        if xlims==[]: xlims_plot=[bins_dict[HNL_mass][0],bins_dict[HNL_mass][-1]]\n",
    "        elif(isinstance(xlims, dict)): xlims_plot = xlims[HNL_mass]\n",
    "        else: xlims_plot=xlims\n",
    "        \n",
    "        #----primary plot----#\n",
    "        plt.sca(ax[0])\n",
    "        \n",
    "        if isinstance(title_name, str): plt.title(title_name, fontsize=24)\n",
    "        \n",
    "        if(isinstance(HNL_scale, dict)):\n",
    "            HNL_scaling=HNL_scale[HNL_mass]\n",
    "        else: HNL_scaling = HNL_scale\n",
    "        print(\"HNL scale is \" + str(HNL_scaling))\n",
    "        \n",
    "        bins_cents=[bins_cent_dict[HNL_mass], bins_cent_dict[HNL_mass], bins_cent_dict[HNL_mass]]\n",
    "        \n",
    "        if HNL_scale_label==False: HNL_label = f\"{HNL_mass} MeV HNL\"\n",
    "        if HNL_scale_label==True: \n",
    "            theta = thetas[HNL_mass]\n",
    "            theta_2 = theta**2\n",
    "            new_theta_2 = np.sqrt(scale_up[HNL_mass])*theta_2\n",
    "            theta_2_label = PT.sci_notation(new_theta_2, decimal_digits=0)\n",
    "            HNL_label = f\"{HNL_mass} MeV HNL \\n\" + r\"$|U_{\\mu4}|^2$ = \" + theta_2_label\n",
    "        \n",
    "        labels_sample = {'overlay':fr\"In-Cryo $\\nu$\",\n",
    "                         'dirtoverlay':fr\"Out-Cryo $\\nu$\",\n",
    "                         'beamoff':f\"Beam-Off\",\n",
    "                         'signal':HNL_label}\n",
    "                         #'signal':f\"{HNL_mass} MeV HNL\"}\n",
    "\n",
    "        bkg_scores, bkg_colors, labels = [], [], []\n",
    "        for sample in order:\n",
    "            bkg_scores.append(bkgs[sample][HNL_mass])\n",
    "            bkg_colors.append(colours[sample])\n",
    "            labels.append(labels_sample[sample])\n",
    "        \n",
    "        hist_placeholder = np.histogram(bins_cents, weights=bkg_scores, range=xlims_plot)[0] #Just for calculating ylims\n",
    "        \n",
    "        hist_full_placeholder = np.histogram(bins_cents, weights=bkg_scores, bins=bins_dict[HNL_mass])[0] #For making the error bars\n",
    "        numbins = len(np.where( bins_cent_dict[HNL_mass] > xlims_plot[0] )[0])+1 #Getting the number of bins that will be plotted with the given xlims range\n",
    "        \n",
    "        tot_uncrt = tot_uncertainty_dict[HNL_mass]\n",
    "        upvals_placeholder = hist_full_placeholder+tot_uncrt\n",
    "        lowvals_placeholder = hist_full_placeholder-tot_uncrt\n",
    "        upvals = np.append(upvals_placeholder, [0])\n",
    "        lowvals = np.append(lowvals_placeholder, [0])\n",
    "        \n",
    "        maxy = max(upvals[-numbins:])\n",
    "        \n",
    "        plot=plt.hist(bins_cents,\n",
    "                      label=labels,\n",
    "                      bins=bins_dict[HNL_mass],\n",
    "                      histtype=\"stepfilled\",\n",
    "                      stacked=True,linewidth=2,edgecolor=\"black\",\n",
    "                      weights=bkg_scores, color=bkg_colors, alpha=ALPHA)\n",
    "            \n",
    "        plt.fill_between(bins_dict[HNL_mass], lowvals, upvals, step=\"post\",color=\"grey\",alpha=0.3,zorder=2)\n",
    "        \n",
    "        sig_placeholder = np.histogram(bins_cent_dict[HNL_mass], weights=signal[HNL_mass]*HNL_scaling, bins=bins_dict[HNL_mass])[0] #For making the error bars\n",
    "        sig_down_placeholder = sig_placeholder-sig_unc[HNL_mass]*HNL_scaling\n",
    "        sig_up_placeholder = sig_placeholder+sig_unc[HNL_mass]*HNL_scaling\n",
    "        sig_down = np.append(sig_down_placeholder, [0])\n",
    "        sig_up = np.append(sig_up_placeholder, [0])\n",
    "\n",
    "        if stacked==False:\n",
    "       \n",
    "            plt.hist(bins_cent_dict[HNL_mass],\n",
    "                     weights=signal[HNL_mass]*HNL_scaling,\n",
    "                     bins=bins_dict[HNL_mass],\n",
    "                     lw=4, edgecolor=colours['signal'], label=labels_sample[\"signal\"], histtype=\"step\")\n",
    "            \n",
    "        if stacked==True:\n",
    "            sig_stacked = hist_full_placeholder+sig_placeholder\n",
    "            plt.hist(bins_cent_dict[HNL_mass],\n",
    "                     weights=sig_stacked,\n",
    "                     bins=bins_dict[HNL_mass],\n",
    "                     lw=4, edgecolor=colours['signal'], label=labels_sample[\"signal\"], histtype=\"step\")\n",
    "        \n",
    "        if sig_sys == True:\n",
    "            plt.rcParams.update({'hatch.color': colours['signal']})\n",
    "            plt.fill_between(bins_dict[HNL_mass], sig_down, sig_up, step=\"post\",hatch='//',alpha=0,zorder=2,lw=2)\n",
    "        \n",
    "        ylims = [0,maxy*1.1]\n",
    "        \n",
    "        plt.xlim(xlims_plot)\n",
    "        if logy==False:\n",
    "            plt.ylim(ylims)\n",
    "        \n",
    "        dat_val=data[HNL_mass]\n",
    "        \n",
    "        x,y=np.histogram(bins_cent_dict[HNL_mass],weights=dat_val,bins=bins_dict[HNL_mass],density=density)\n",
    "        x1,y=np.histogram(bins_cent_dict[HNL_mass],weights=dat_val,bins=bins_dict[HNL_mass])\n",
    "        bin_center = [(y[i] + y[i+1])/2. for i in range(len(y)-1)]\n",
    "        dat_placeholder=x\n",
    "        dat_err=np.sqrt(x1)*np.nan_to_num(x/x1)\n",
    "        \n",
    "        if Run==\"run1\":Run_label = \"Run 1\"\n",
    "        if Run==\"run3\":Run_label = \"Run 3\"\n",
    "        data_label = f\"{Run_label} NuMI Data\"\n",
    "        # data_label = f\"Data\"\n",
    "        \n",
    "        plt.errorbar(bin_center, dat_placeholder, yerr=dat_err,fmt='.',color='black',lw=5,capsize=5,elinewidth=3,label=data_label) #Plotting data\n",
    "        \n",
    "        # if plot_text != None:\n",
    "        #     plt.text(textpos[0],textpos[1], plot_text, fontsize=textsize)\n",
    "        \n",
    "        plt.ylabel('Events', fontsize=30)\n",
    "        plt.yscale(logscale)\n",
    "        plt.legend(loc=legloc,frameon=True, fontsize = legsize)\n",
    "        \n",
    "        if plot_text != None:\n",
    "            plt.legend(loc=legloc, frameon=True, prop={'size': legsize}, title=plot_text, title_fontsize=legsize)\n",
    "        \n",
    "        #----sub-plot----# \n",
    "        plt.sca(ax[1])\n",
    "        \n",
    "        fracer_data=np.nan_to_num(np.sqrt(x1)/x1)\n",
    "        x_err=fracer_data*x\n",
    "        fracer_mc=np.nan_to_num(tot_uncrt/plot[0][2])\n",
    "\n",
    "        rat_err_data=x_err*(1/plot[0][2])\n",
    "\n",
    "        rat_err_mc=fracer_mc\n",
    "\n",
    "        rat_err_mc=np.nan_to_num(rat_err_mc) #other wise the next doesnt plot pro[erly]\n",
    "\n",
    "        upvals= np.append(1+(rat_err_mc),1+(rat_err_mc)[-1]) #hate this but need to repeat last value to get bar on last bin to work, saw it here https://matplotlib.org/stable/gallery/lines_bars_and_markers/filled_step.html\n",
    "        lowvals=np.append(1-(rat_err_mc),1-(rat_err_mc)[-1])\n",
    "\n",
    "        plt.fill_between(y, lowvals, upvals,step=\"post\",color=\"grey\",alpha=0.3,zorder=2)\n",
    "\n",
    "        rat=np.nan_to_num(x/plot[0][2])\n",
    "        rat[x==0]=1 #dont think this is a good way to deal with this\n",
    "\n",
    "        plt.errorbar(bin_center,rat,yerr=fracer_data,fmt='.',color='black',lw=3,capsize=3,elinewidth=1,label=\"data\")\n",
    "        plt.ylabel(\"Data/MC\")\n",
    "        plt.axhline(1,ls='-',color='black')\n",
    "        \n",
    "        ylim = max(abs(np.nan_to_num(rat)))*1.1\n",
    "        ylim_min = min(abs(np.nan_to_num(rat)))*0.9\n",
    "        if (1.0+(1.0-ylim_min))>ylim: Use_ylim = False#Which is further from 1.0\n",
    "        else: Use_ylim = True #i.e the max is further from 1.0 than the min.\n",
    "        ylim_low = 1-(ylim-1.0)\n",
    "        ylim_high = 1+(1.0-ylim_min)\n",
    "        if (ylim>1.5) or (ylim_min<0.5):\n",
    "            if(Use_ylim):plt.ylim(ylim_low,ylim)\n",
    "            else:plt.ylim(ylim_min,ylim_high)\n",
    "        else: plt.ylim(0.5,1.5)\n",
    "        \n",
    "        if isinstance(xticks,dict):\n",
    "            plt.xticks(ticks=np.arange(bins_dict[HNL_mass][0], bins_dict[HNL_mass][-1], 1), labels=xticks[HNL_mass])\n",
    "\n",
    "        if upper_y!=[]:\n",
    "            plt.ylim(1-upper_y, 1+upper_y)\n",
    "            \n",
    "        plt.xlim(xlims_plot)\n",
    "\n",
    "        plt.xlabel(f'BDT Score '+r'($m_{\\mathrm{HNL}}=$'+f'{HNL_mass} MeV)', fontsize=28)\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.92])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if savefig == True:\n",
    "            plt.savefig(\"plots/BDT_output/Final_histograms/BDT_output_\" + Run + \"_\" + str(HNL_mass) + \"MeV_\" + logscale + save_str + \".pdf\")\n",
    "            plt.savefig(\"plots/BDT_output/Final_histograms/BDT_output_\" + Run + \"_\" + str(HNL_mass) + \"MeV_\" + logscale + save_str + \".png\")\n",
    "        plt.show()\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639ccb46-a86b-4cd2-aeca-e44d98698fc9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74793236-fd36-459c-82d1-127a8c38b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "#theta_squared limits\n",
    "print(\"Please check these are the correct .csv limit files\")\n",
    "uboone_ee_current = Functions.Pandafy_new('limit_files/My_limits/Full_sys_4_bins_expected_20_April.csv')\n",
    "uboone_pi0_reduced = Functions.Pandafy_new('limit_files/My_limits/Full_sys_4_bins_pi0_expected_20_April.csv')\n",
    "\n",
    "if Params_pyhf[\"Load_lepton_hists\"] == True: limit_thetas = uboone_ee_current.set_index('Mass')['Value'].to_dict()\n",
    "if Params_pyhf[\"Load_pi0_hists\"] == True: limit_thetas = uboone_pi0_reduced.set_index('Mass')['Value'].to_dict()\n",
    "if Params_pyhf[\"Load_lepton_dirac\"] == True: limit_thetas = uboone_ee_current.set_index('Mass')['Value'].to_dict()\n",
    "if Params_pyhf[\"Load_pi0_dirac\"] == True: limit_thetas = uboone_pi0_reduced.set_index('Mass')['Value'].to_dict()\n",
    "\n",
    "print(\"Theta squared limits are: \")\n",
    "print(limit_thetas)\n",
    "\n",
    "theta_scaling, hist_scaling = {}, {}\n",
    "limit_theta_power_1 = {}\n",
    "for HNL_mass in theta_dict:\n",
    "    theta_scaling[HNL_mass] = limit_thetas[HNL_mass]/(theta_dict[HNL_mass]**2)\n",
    "    hist_scaling[HNL_mass] = theta_scaling[HNL_mass]**(2)\n",
    "    limit_theta_power_1[HNL_mass] = limit_thetas[HNL_mass]**(1/2)\n",
    "\n",
    "print(\"Scalings for theta squared values are: \")\n",
    "print(theta_scaling)\n",
    "print(hist_scaling)\n",
    "print(limit_theta_power_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee881fd-d9bd-400a-a3b5-274d431c32ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hist_scaling)\n",
    "visibility_scaling = 100.0\n",
    "new_hist_scaling = {}\n",
    "for HNL_mass in theta_dict:\n",
    "    new_hist_scaling[HNL_mass] = hist_scaling[HNL_mass]*visibility_scaling\n",
    "print(new_hist_scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1428e1-70b0-455a-ab0e-81dd5e50986a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Run=\"run1\"\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "Lo_score = -5.0\n",
    "\n",
    "adjusted_xlims_r1, xticks_r1 = make_xlims_dict(bins_overflow_r1, lower = -5)\n",
    "adjusted_xlims_r3, xticks_r3 = make_xlims_dict(bins_overflow_r3, lower = -5)\n",
    "\n",
    "if Params_pyhf[\"Load_lepton_hists\"]==True: decay_type = \"ee\"\n",
    "if Params_pyhf[\"Load_pi0_hists\"]==True: decay_type = \"pi0\"\n",
    "if Params_pyhf[\"Load_lepton_dirac\"]==True: decay_type = \"ee_dirac\"\n",
    "if Params_pyhf[\"Load_pi0_dirac\"]==True: decay_type = \"pi0_dirac\"\n",
    "\n",
    "savestr = f\"_{decay_type}{BDT_name}_recoloured_stacked\"\n",
    "\n",
    "sample_colours_test = {'overlay':'#0254cf',\n",
    "                  'dirtoverlay':'cornflowerblue',\n",
    "                  'beamoff':'limegreen',\n",
    "                  'signal':'red',\n",
    "                  'signal_pi0':'gold'}\n",
    "\n",
    "if Params_pyhf[\"Load_pi0_hists\"]==True: sample_colours_test['signal']='gold'\n",
    "\n",
    "# titlename = r\"MicroBooNE Data\" \"\\n\" r\"$2.00\\times10^{20}$ POT\"\n",
    "titlename = None\n",
    "\n",
    "Plot_BDT_output_systematics_data(signal_dict_r1, tot_uncertainty_dict_r1, sig_sys_err_r1, bkgs_dict_r1, data_r1, bins_cents_overflow_r1, bins_overflow_r1, \n",
    "                                 xlims=adjusted_xlims_r1, xticks=xticks_r1, upper_y=0.75, legloc=\"upper right\", colours = sample_colours_test,\n",
    "                                 legsize=22, logy=False, savefig=True, save_str=savestr, Run=Run, HNL_scale=new_hist_scaling,\n",
    "                                 scale_up=new_hist_scaling, thetas=theta_dict, sig_sys=False, HNL_scale_label=True, stacked=True,\n",
    "                                 title_name=None, textpos=None, plot_text=titlename, textsize=18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414cf4a6-7725-4eab-a9ce-89b41e2660dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d808ca81-2397-404f-b518-acfce5162afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Run=\"run3\"\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "\n",
    "savestr = f\"_{decay_type}{BDT_name}_recoloured_stacked\"\n",
    "\n",
    "# titlename = r\"MicroBooNE Data\" \"\\n\" r\"$5.01\\times10^{20}$ POT\"\n",
    "titlename = None\n",
    "\n",
    "Plot_BDT_output_systematics_data(signal_dict_r3, tot_uncertainty_dict_r3, sig_sys_err_r3, bkgs_dict_r3, data_r3, bins_cents_overflow_r3, bins_overflow_r3, \n",
    "                                 xlims=adjusted_xlims_r3, xticks=xticks_r3, upper_y=0.75, legloc=\"upper right\", colours = sample_colours_test,\n",
    "                                 legsize=22, logy=False, savefig=True, save_str=savestr, Run=Run, HNL_scale=new_hist_scaling,\n",
    "                                 scale_up=new_hist_scaling, thetas=theta_dict, sig_sys=False, HNL_scale_label=True, stacked=True,\n",
    "                                 title_name=None, textpos=None, plot_text=titlename, textsize=19)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdf7943-ac9b-4a9b-aea0-62e6b9ac3baa",
   "metadata": {},
   "source": [
    "## Comparing Dirac and Majorana signal distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13327774-dcbe-4b56-8a7d-1ac28ca87ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Params_dirac = {\"Stats_only\":False,\n",
    "               \"Use_flat_sys\":False,\n",
    "               \"Use_part_only\":False,\n",
    "               \"Num_bins_for_calc\":4,\n",
    "               \"Use_toys\":False,\n",
    "               \"Num_toys\":100,\n",
    "               \"Load_lepton_hists\":False,\n",
    "               \"Load_pi0_hists\":False,\n",
    "               \"Flat_bkg_overlay_frac\":0.3,\n",
    "               \"Flat_bkg_dirt_frac\":0.75,\n",
    "               \"Flat_bkg_EXT_frac\":0.0,\n",
    "               \"Flat_sig_detvar\":0.2, #This is very conservative, could be fed in per mass point from signal detvar script\n",
    "               \"Signal_flux_error\":0.3, #This comes from the KDAR flux uncertainty.\n",
    "               \"Overlay_detvar_frac\":0.3,\n",
    "               \"Load_lepton_dirac\":False,\n",
    "               \"Load_pi0_dirac\":True,\n",
    "               \"Load_single_r1_file\":False}\n",
    "\n",
    "Functions.pyhf_params(Params_dirac)\n",
    "\n",
    "if Params_dirac[\"Load_lepton_hists\"] == True: \n",
    "    name_type=\"ee\"\n",
    "    HNL_masses_dirac = Constants.HNL_mass_samples\n",
    "if Params_dirac[\"Load_pi0_hists\"] == True: \n",
    "    name_type=\"pi0\"\n",
    "    HNL_masses_dirac = Constants.HNL_mass_pi0_samples\n",
    "if Params_dirac[\"Load_lepton_dirac\"] == True:\n",
    "    name_type=\"ee_dirac\"\n",
    "    HNL_masses_dirac = Constants.HNL_ee_dirac_mass_samples\n",
    "if Params_dirac[\"Load_pi0_dirac\"] == True:\n",
    "    name_type=\"pi0_dirac\"\n",
    "    HNL_masses_dirac = Constants.HNL_pi0_dirac_mass_samples\n",
    "    \n",
    "BDT_name = \"_full_Finished_10\"\n",
    "\n",
    "filename = name_type+BDT_name\n",
    "print(filename)\n",
    "\n",
    "hist_dict_run1_dirac, hist_dict_run3_dirac, theta_dict_dirac = Functions.New_Load_pyhf_files(f\"{filename}.root\",\n",
    "                                                                                             Params_dirac, HNL_masses = HNL_masses_dirac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1037fe69-76e3-4de5-95f4-179a940b5d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_dict_r1_dirac, bkgs_dict_r1_dirac, data_r1_dirac, sig_sys_err_r1_dirac, tot_uncertainty_dict_r1_dirac, bins_dict_r1_dirac, bins_cent_dict_r1_dirac = Get_uncertainty_dicts(hist_dict_run1_dirac, \n",
    "                                                                                                                                                            Params_dirac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653a955c-638b-4afa-be8c-6c5f896d1bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Dirac_factor = 2.0\n",
    "\n",
    "Run = \"run1\"\n",
    "\n",
    "# adjusted_xlims_r1, xticks_r1\n",
    "\n",
    "savefig = input(\"Do you want to save the BDT score plots? y/n \")\n",
    "\n",
    "for HNL_mass in HNL_masses_dirac:\n",
    "    plt.figure(figsize=[10,8])\n",
    "    xlims_plot = adjusted_xlims_r1[HNL_mass]\n",
    "\n",
    "    weights_Dirac = signal_dict_r1_dirac[HNL_mass]*Dirac_factor\n",
    "    # dirac_placeholder = np.histogram(bins_cents_overflow_r1[HNL_mass], weights=signal_dict_r1_dirac[HNL_mass], bins=bins_overflow_r1[HNL_mass])[0]\n",
    "    dirac_placeholder = np.histogram(bins_cent_dict_r1[HNL_mass], bins=bins_dict_r1[HNL_mass], weights=signal_dict_r1_dirac[HNL_mass])[0]\n",
    "    majorana_placeholder = np.histogram(bins_cent_dict_r1[HNL_mass], bins=bins_dict_r1[HNL_mass], weights=signal_dict_r1[HNL_mass])[0]\n",
    "    plt.hist(bins_cents_overflow_r1[HNL_mass], weights=dirac_placeholder*Dirac_factor, bins=bins_overflow_r1[HNL_mass], \n",
    "             label = f\"{HNL_mass} MeV Dirac \" + r\"$\\times~2$\", histtype=\"step\", lw=3) #Tried dashed linestyle but looked weird\n",
    "    plt.hist(bins_cents_overflow_r1[HNL_mass], weights=majorana_placeholder, bins=bins_overflow_r1[HNL_mass], \n",
    "             label = f\"{HNL_mass} MeV Majorana\", histtype=\"step\", lw=3)\n",
    "    \n",
    "    plt.ylabel('Events', fontsize=28)\n",
    "    \n",
    "    plt.xlabel(f'BDT Score '+r'($m_{\\mathrm{HNL}}=$'+f'{HNL_mass} MeV)', fontsize=28)\n",
    "    plt.xticks(ticks=np.arange(bins_overflow_r1[HNL_mass][0], bins_overflow_r1[HNL_mass][-1], 1), labels=xticks_r1[HNL_mass])\n",
    "    plt.xlim(xlims_plot)\n",
    "    \n",
    "    # plt.legend(fontsize=20)\n",
    "    \n",
    "    if decay_type == \"ee\": text1 = r'$N\\rightarrow \\nu e^{+}e^{-}$'\n",
    "    if decay_type == \"pi0\": text1 = r'$N\\rightarrow \\nu \\pi^{0}$'   \n",
    "    \n",
    "    plt.legend(loc=\"best\",frameon=True, fontsize=20, title=text1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if savefig == \"y\":\n",
    "        plt.savefig(f\"plots/BDT_output/Dirac_vs_Majorana_scores/Dirac_vs_Majorana_BDT_output_{decay_type}_\" + Run + \"_\" + str(HNL_mass) + \"MeV.pdf\")\n",
    "        plt.savefig(f\"plots/BDT_output/Dirac_vs_Majorana_scores/Dirac_vs_Majorana_BDT_output_{decay_type}_\" + Run + \"_\" + str(HNL_mass) + \"MeV.png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef581fd-a3fd-4478-868a-06faa32358cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "HNL_mass = 150\n",
    "\n",
    "dirac_placeholder = np.histogram(bins_cents_overflow_r1[HNL_mass], weights=signal_dict_r1_dirac[HNL_mass], bins=bins_overflow_r1[HNL_mass])[0]\n",
    "majorana_placeholder = np.histogram(bins_cents_overflow_r1[HNL_mass], weights=signal_dict_r1[HNL_mass], bins=bins_overflow_r1[HNL_mass])[0]\n",
    "\n",
    "print(dirac_placeholder)\n",
    "print(majorana_placeholder)\n",
    "\n",
    "print(\"Ratios of bin heights:\")\n",
    "\n",
    "for i, val in enumerate(dirac_placeholder):\n",
    "    ratio = dirac_placeholder[i]/majorana_placeholder[i]\n",
    "    print(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a072bf2-93ee-463a-b274-6f31f7dd0b99",
   "metadata": {},
   "source": [
    "## End of code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
