{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe0cab0-578b-42ea-86af-07342852e08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading libraries\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import uproot3\n",
    "import uproot\n",
    "import math\n",
    "import pickle\n",
    "import csv\n",
    "from importlib import reload\n",
    "\n",
    "import Utilities.Constants as Constants\n",
    "import Utilities.Functions as Functions\n",
    "import Utilities.Plotter as PT\n",
    "from Utilities.ipython_exit import exit\n",
    "\n",
    "print(\"Successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6939111e-d766-4112-ab60-1fd7c65239ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Params_pyhf = {\"Stats_only\":False,\n",
    "               \"Use_flat_sys\":False,\n",
    "               \"Use_part_only\":True,\n",
    "               \"Num_bins_for_calc\":4,\n",
    "               \"Use_toys\":False,\n",
    "               \"Num_toys\":100,\n",
    "               \"Load_lepton_hists\":True,\n",
    "               \"Load_pi0_hists\":False,\n",
    "               \"Flat_bkg_overlay_frac\":0.5,\n",
    "               \"Flat_bkg_dirt_frac\":1.0,\n",
    "               \"Flat_bkg_EXT_frac\":0.0,\n",
    "               \"Flat_sig_detvar\":0.2, #This is very conservative, could be fed in per mass point from signal detvar script\n",
    "               \"Signal_flux_error\":0.3, #This comes from the KDAR flux uncertainty.\n",
    "               \"Overlay_detvar_frac\":0.5}\n",
    "\n",
    "Functions.pyhf_params(Params_pyhf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb78650-72a3-4fa1-ad92-465a31cba48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading My BDT histograms\n",
    "# loc_hists = 'bdt_output/'\n",
    "loc_hists = 'Uncertainties/'\n",
    "\n",
    "hist_dict_run1 = {}\n",
    "hist_dict_run3 = {}\n",
    "theta_dict = {}\n",
    "\n",
    "#Loading in the .root files\n",
    "if Params_pyhf[\"Load_lepton_hists\"] == True:\n",
    "    for HNL_mass in Constants.HNL_mass_samples:\n",
    "        hist_dict_run1[HNL_mass] = uproot.open(loc_hists+f'run1_{HNL_mass}MeV_FINAL_3.root')\n",
    "        hist_dict_run3[HNL_mass] = uproot.open(loc_hists+f'run3_{HNL_mass}MeV_FINAL_3.root')\n",
    "        theta_dict[HNL_mass] = hist_dict_run1[HNL_mass][\"theta\"].values()[0] #assuming scaled theta is the same for all runs, only 1 value saved\n",
    "    \n",
    "if Params_pyhf[\"Load_pi0_hists\"] == True:\n",
    "    pi0_dict_run1, pi0_dict_run3 = {}, {}\n",
    "    for HNL_mass in Constants.HNL_mass_pi0_samples:\n",
    "        hist_dict_run1[HNL_mass] = uproot.open(loc_hists+f'pi0/run1_{HNL_mass}MeV_FINAL_3.root')\n",
    "        hist_dict_run3[HNL_mass] = uproot.open(loc_hists+f'pi0/run3_{HNL_mass}MeV_FINAL_3.root')\n",
    "        theta_dict[HNL_mass] = hist_dict_run1[HNL_mass][\"theta\"].values()[0]\n",
    "\n",
    "#list_of_dicts = [hist_dict_run1, hist_dict_run3] #Add run2 when available, not using yet\n",
    "\n",
    "#Constants\n",
    "\n",
    "theta_dict[HNL_mass] = hist_dict_run1[HNL_mass][\"theta\"].values()[0]\n",
    "theta_squared = Constants.theta_mu_4*Constants.theta_mu_4\n",
    "\n",
    "print(theta_dict)\n",
    "\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5dfbff-1aeb-4021-8799-2beb8842e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run1\n",
    "overlay_dict_r1, dirt_dict_r1, EXT_dict_r1 = {}, {}, {}\n",
    "signal_dict_r1 = {}\n",
    "bins_dict_r1 = {}\n",
    "bins_cent_dict_r1 = {}\n",
    "tot_uncertainty_dict_r1 = {}\n",
    "sig_sys_err_r1 = {}\n",
    "#Run3\n",
    "overlay_dict_r3, dirt_dict_r3, EXT_dict_r3 = {}, {}, {}\n",
    "signal_dict_r3 = {}\n",
    "bins_dict_r3 = {}\n",
    "bins_cent_dict_r3 = {}\n",
    "tot_uncertainty_dict_r3 = {}\n",
    "sig_sys_err_r3 = {}\n",
    "# xlims = [0,5.0]\n",
    "data_r1, data_r3 = {}, {}\n",
    "\n",
    "for HNL_mass in hist_dict_run1:\n",
    "#     print(HNL_mass)\n",
    "# for HNL_mass in [220]:\n",
    "    overlay_dict_r1[HNL_mass] = hist_dict_run1[HNL_mass]['bkg_overlay'].to_numpy()[0]\n",
    "    dirt_dict_r1[HNL_mass] = hist_dict_run1[HNL_mass]['bkg_dirt'].to_numpy()[0]\n",
    "    EXT_dict_r1[HNL_mass] = hist_dict_run1[HNL_mass]['bkg_EXT'].to_numpy()[0]\n",
    "    signal_dict_r1[HNL_mass] = hist_dict_run1[HNL_mass]['signal'].to_numpy()[0]\n",
    "    \n",
    "    overlay_dict_r3[HNL_mass] = hist_dict_run3[HNL_mass]['bkg_overlay'].to_numpy()[0]\n",
    "    dirt_dict_r3[HNL_mass] = hist_dict_run3[HNL_mass]['bkg_dirt'].to_numpy()[0]\n",
    "    EXT_dict_r3[HNL_mass] = hist_dict_run3[HNL_mass]['bkg_EXT'].to_numpy()[0]\n",
    "    signal_dict_r3[HNL_mass] = hist_dict_run3[HNL_mass]['signal'].to_numpy()[0]\n",
    "    \n",
    "    tot_uncertainty_r1 = [hist_dict_run1[HNL_mass]['ppfx_uncertainty'].to_numpy()[0], #overlay ppfx error\n",
    "                          hist_dict_run1[HNL_mass]['Genie_uncertainty'].to_numpy()[0], #overlay genie error\n",
    "                          hist_dict_run1[HNL_mass]['Reinteraction_uncertainty'].to_numpy()[0], #overlay reinteraction error\n",
    "                          hist_dict_run1[HNL_mass]['overlay_DetVar_uncertainty'].to_numpy()[0], #overlay detector variation error\n",
    "                          hist_dict_run1[HNL_mass]['bkg_dirt'].to_numpy()[0]*Params_pyhf[\"Flat_bkg_dirt_frac\"], #dirt flat systematic error\n",
    "                          hist_dict_run1[HNL_mass]['bkg_overlay'].errors(), #stat error\n",
    "                          hist_dict_run1[HNL_mass]['bkg_dirt'].errors(), #stat error\n",
    "                          hist_dict_run1[HNL_mass]['bkg_EXT'].errors()] #stat error\n",
    "    \n",
    "    tot_uncertainty_r3 = [hist_dict_run3[HNL_mass]['ppfx_uncertainty'].to_numpy()[0], #overlay ppfx error\n",
    "                          hist_dict_run3[HNL_mass]['Genie_uncertainty'].to_numpy()[0], #overlay genie error\n",
    "                          hist_dict_run3[HNL_mass]['Reinteraction_uncertainty'].to_numpy()[0], #overlay reinteraction error\n",
    "                          hist_dict_run3[HNL_mass]['overlay_DetVar_uncertainty'].to_numpy()[0], #overlay detector variation error\n",
    "                          hist_dict_run3[HNL_mass]['bkg_dirt'].to_numpy()[0]*Params_pyhf[\"Flat_bkg_dirt_frac\"], #dirt flat systematic error\n",
    "                          hist_dict_run3[HNL_mass]['bkg_overlay'].errors(), #stat error\n",
    "                          hist_dict_run3[HNL_mass]['bkg_dirt'].errors(), #stat error\n",
    "                          hist_dict_run3[HNL_mass]['bkg_EXT'].errors()] #stat error\n",
    "    \n",
    "    tot_sig_unc_r1 = [hist_dict_run1[HNL_mass]['signal'].errors(),\n",
    "                      hist_dict_run1[HNL_mass][\"signal_DetVar_uncertainty\"].values(),\n",
    "                      hist_dict_run1[HNL_mass]['signal'].values()*Params_pyhf[\"Signal_flux_error\"]]\n",
    "    tot_sig_unc_r3 = [hist_dict_run3[HNL_mass]['signal'].errors(),\n",
    "                      hist_dict_run3[HNL_mass][\"signal_DetVar_uncertainty\"].values(),\n",
    "                      hist_dict_run3[HNL_mass]['signal'].values()*Params_pyhf[\"Signal_flux_error\"]]\n",
    "    \n",
    "    sig_sys_err_r1[HNL_mass] = Functions.add_all_errors(tot_sig_unc_r1)\n",
    "    sig_sys_err_r3[HNL_mass] = Functions.add_all_errors(tot_sig_unc_r3)\n",
    "    \n",
    "    tot_uncertainty_dict_r1[HNL_mass] = Functions.add_all_errors(tot_uncertainty_r1)\n",
    "    tot_uncertainty_dict_r3[HNL_mass] = Functions.add_all_errors(tot_uncertainty_r3)\n",
    "    \n",
    "    bins_dict_r1[HNL_mass] = hist_dict_run1[HNL_mass]['bkg_overlay'].to_numpy()[1] #A tuple of bin edges\n",
    "    bins_cent_dict_r1[HNL_mass]=(bins_dict_r1[HNL_mass][:-1]+bins_dict_r1[HNL_mass][1:])/2\n",
    "    \n",
    "    bins_dict_r3[HNL_mass] = hist_dict_run3[HNL_mass]['bkg_overlay'].to_numpy()[1] #A tuple of bin edges\n",
    "    bins_cent_dict_r3[HNL_mass]=(bins_dict_r3[HNL_mass][:-1]+bins_dict_r3[HNL_mass][1:])/2\n",
    "    # maxy_dict[HNL_mass] = max(plt.hist(bins_cent_dict[HNL_mass], weights=overlay_dict[HNL_mass], range = xlims))*1.2\n",
    "    \n",
    "    data_r1[HNL_mass] = hist_dict_run1[HNL_mass]['data'].values()\n",
    "    data_r3[HNL_mass] = hist_dict_run3[HNL_mass]['data'].values()\n",
    "    \n",
    "bkgs_r1 = {'overlay':overlay_dict_r1, 'dirtoverlay':dirt_dict_r1, 'beamoff':EXT_dict_r1}\n",
    "bkgs_r3 = {'overlay':overlay_dict_r3, 'dirtoverlay':dirt_dict_r3, 'beamoff':EXT_dict_r3}\n",
    "\n",
    "# print(overlay_dict_r1[HNL_mass])\n",
    "# print(tot_uncertainty_dict_r1[HNL_mass])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95023d1-464b-47f7-96e4-e1f6ca032f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_BDT_output_systematics(signal={}, tot_uncertainty_dict={}, sig_unc={}, bkgs={}, bins_cent_dict={}, bins_dict={}, colours={}, ALPHA=1.0, xlims=[0,5.0],\n",
    "                                figsize=[12,8], density=False, legloc=\"upper right\",legsize=22,\n",
    "                                logy=False, savefig=False, save_str=\"\", Run=\"_\", HNL_scale=1.0,scale_up=[], thetas=[], order=[], sig_sys=False,HNL_scale_label=False):\n",
    "    \"\"\"\n",
    "    This should take the histograms which have already been binned and scaled and plot the total uncertainties on bkg.\n",
    "    Therefore it will display what is being fed into the limit setting software.\n",
    "    \"\"\"\n",
    "    if(isinstance(HNL_scale, float)): print(\"Scaling by a single number for all\")\n",
    "    if(isinstance(HNL_scale, dict)): print(\"Scaling each mass point individually\")\n",
    "    if(signal=={}): raise Exception(\"Specify HNL sample masses\")\n",
    "    if(bkgs=={}): raise Exception(\"Specify background samples\")\n",
    "    if(bins_cent_dict=={}): raise Exception(\"Specify bin centres\")\n",
    "    if(bins_dict=={}): raise Exception(\"Specify bins\")\n",
    "    if(colours=={}): colours = {'overlay':Constants.sample_colours['overlay'],\n",
    "                                'dirtoverlay':Constants.sample_colours['dirtoverlay'],\n",
    "                                'beamoff':Constants.sample_colours['beamoff'],\n",
    "                                'signal':Constants.sample_colours['signal']}\n",
    "    if(order==[]): order = [\"beamoff\",\"overlay\",\"dirtoverlay\"] #From bottom to top in stack\n",
    "    if(thetas==[]): print(\"Haven't entered thetas, can't calculate scalings\") \n",
    "    \n",
    "    if logy == True:\n",
    "        logscale=\"log\"\n",
    "    elif logy == False:\n",
    "        logscale=\"linear\"\n",
    "    \n",
    "    for HNL_mass in signal.keys():\n",
    "        plt.figure(figsize=figsize,facecolor='white')\n",
    "        if(isinstance(HNL_scale, dict)):\n",
    "            HNL_scaling=HNL_scale[HNL_mass]\n",
    "        else: HNL_scaling = HNL_scale\n",
    "        print(\"HNL scale is \" + str(HNL_scaling))\n",
    "        \n",
    "        bins_cents=[bins_cent_dict[HNL_mass], bins_cent_dict[HNL_mass], bins_cent_dict[HNL_mass]]\n",
    "        \n",
    "        if HNL_scale_label==False: HNL_label = f\"{HNL_mass} MeV HNL\"\n",
    "        if HNL_scale_label==True: \n",
    "            theta = thetas[HNL_mass]\n",
    "            theta_2 = theta**2\n",
    "            new_theta_2 = np.sqrt(scale_up[HNL_mass])*theta_2\n",
    "            theta_2_label = PT.sci_notation(new_theta_2, decimal_digits=0)\n",
    "            HNL_label = f\"{HNL_mass} MeV HNL \\n\" + r\"$|U_{\\mu4}|^2$ = \" + theta_2_label\n",
    "        \n",
    "        labels_sample = {'overlay':fr\"In-Cryo $\\nu$\",\n",
    "                         'dirtoverlay':fr\"Out-Cryo $\\nu$\",\n",
    "                         'beamoff':f\"Beam-Off\",\n",
    "                         'signal':HNL_label}\n",
    "                         #'signal':f\"{HNL_mass} MeV HNL\"}\n",
    "\n",
    "        bkg_scores, bkg_colors, labels = [], [], []\n",
    "        for sample in order:\n",
    "            bkg_scores.append(bkgs[sample][HNL_mass])\n",
    "            bkg_colors.append(colours[sample])\n",
    "            labels.append(labels_sample[sample])\n",
    "        \n",
    "        hist_placeholder = np.histogram(bins_cents, weights=bkg_scores, range=xlims)[0] #Just for calculating ylims\n",
    "        \n",
    "        hist_full_placeholder = np.histogram(bins_cents, weights=bkg_scores, bins=bins_dict[HNL_mass])[0] #For making the error bars\n",
    "        numbins = len(np.where( bins_cent_dict[HNL_mass] > xlims[0] )[0])+1 #Getting the number of bins that will be plotted with the given xlims range\n",
    "               \n",
    "        plot=plt.hist(bins_cents,\n",
    "                      label=labels,\n",
    "                      bins=bins_dict[HNL_mass],\n",
    "                      histtype=\"stepfilled\",\n",
    "                      stacked=True,linewidth=2,edgecolor=\"black\",\n",
    "                      weights=bkg_scores, color=bkg_colors, alpha=ALPHA)\n",
    "        \n",
    "        tot_uncrt = tot_uncertainty_dict[HNL_mass]\n",
    "        upvals_placeholder = hist_full_placeholder+tot_uncrt\n",
    "        lowvals_placeholder = hist_full_placeholder-tot_uncrt\n",
    "        upvals = np.append(upvals_placeholder, [0])\n",
    "        lowvals = np.append(lowvals_placeholder, [0])\n",
    "        \n",
    "        maxy = max(upvals[-numbins:])\n",
    "        \n",
    "        plt.fill_between(bins_dict[HNL_mass], lowvals, upvals, step=\"post\",color=\"grey\",alpha=0.3,zorder=2)\n",
    "\n",
    "        plt.hist(bins_cent_dict[HNL_mass],\n",
    "                 weights=signal[HNL_mass]*HNL_scaling,\n",
    "                 bins=bins_dict[HNL_mass],\n",
    "                 lw=4, edgecolor=colours['signal'], label=labels_sample[\"signal\"], histtype=\"step\")\n",
    "        \n",
    "        sig_placeholder = np.histogram(bins_cent_dict[HNL_mass], weights=signal[HNL_mass]*HNL_scaling, bins=bins_dict[HNL_mass])[0] #For making the error bars\n",
    "        sig_down_placeholder = sig_placeholder-sig_unc[HNL_mass]*HNL_scaling\n",
    "        sig_up_placeholder = sig_placeholder+sig_unc[HNL_mass]*HNL_scaling\n",
    "        sig_down = np.append(sig_down_placeholder, [0])\n",
    "        sig_up = np.append(sig_up_placeholder, [0])\n",
    "        \n",
    "        if sig_sys == True:\n",
    "            plt.rcParams.update({'hatch.color': colours['signal']})\n",
    "            plt.fill_between(bins_dict[HNL_mass], sig_down, sig_up, step=\"post\",hatch='//',alpha=0,zorder=2,lw=2)\n",
    "        \n",
    "        ylims = [0,maxy*1.1]\n",
    "        plt.legend(loc=legloc,frameon=True, fontsize = legsize)\n",
    "        \n",
    "        plt.xlim(xlims)\n",
    "        if logy==False:\n",
    "            plt.ylim(ylims)\n",
    "        \n",
    "        plt.xlabel('BDT score', fontsize=30)\n",
    "        plt.ylabel('Events', fontsize=30)\n",
    "        plt.yscale(logscale)\n",
    "        plt.tight_layout()\n",
    "        if savefig == True:\n",
    "            plt.savefig(\"plots/BDT_output/Final_histograms/BDT_output_\" + Run + \"_\" + str(HNL_mass) + \"MeV_\" + logscale + save_str + \".pdf\")\n",
    "            plt.savefig(\"plots/BDT_output/Final_histograms/BDT_output_\" + Run + \"_\" + str(HNL_mass) + \"MeV_\" + logscale + save_str + \".png\")\n",
    "        plt.show()\n",
    "        \n",
    "def Plot_BDT_output_systematics_data(signal={}, tot_uncertainty_dict={}, sig_unc={}, bkgs={}, data={}, bins_cent_dict={}, bins_dict={}, colours={}, ALPHA=1.0, xlims=[],\n",
    "                                figsize=[12,10], density=False, legloc=\"upper right\",legsize=22,\n",
    "                                logy=False, savefig=False, save_str=\"\", Run=\"_\", HNL_scale=1.0,scale_up=[], thetas=[], order=[], sig_sys=False,HNL_scale_label=False):\n",
    "    \"\"\"\n",
    "    This should take the histograms which have already been binned and scaled and plot the total uncertainties on bkg.\n",
    "    Therefore it will display what is being fed into the limit setting software. INCLUDING the data.\n",
    "    \"\"\"\n",
    "    if(isinstance(HNL_scale, float)): print(\"Scaling by a single number for all\")\n",
    "    if(isinstance(HNL_scale, dict)): print(\"Scaling each mass point individually\")\n",
    "    if(signal=={}): raise Exception(\"Specify HNL sample masses\")\n",
    "    if(bkgs=={}): raise Exception(\"Specify background samples\")\n",
    "    if(data=={}): raise Exception(\"Specify data sample\")\n",
    "    if(bins_cent_dict=={}): raise Exception(\"Specify bin centres\")\n",
    "    if(bins_dict=={}): raise Exception(\"Specify bins\")\n",
    "    if(colours=={}): colours = {'overlay':Constants.sample_colours['overlay'],\n",
    "                                'dirtoverlay':Constants.sample_colours['dirtoverlay'],\n",
    "                                'beamoff':Constants.sample_colours['beamoff'],\n",
    "                                'signal':Constants.sample_colours['signal']}\n",
    "    if(order==[]): order = [\"beamoff\",\"overlay\",\"dirtoverlay\"] #From bottom to top in stack\n",
    "    if(thetas==[]): print(\"Haven't entered thetas, can't calculate scalings\") \n",
    "    \n",
    "    if logy == True:\n",
    "        logscale=\"log\"\n",
    "    elif logy == False:\n",
    "        logscale=\"linear\"\n",
    "    \n",
    "    for HNL_mass in signal.keys():\n",
    "        \n",
    "        fig,ax = plt.subplots(nrows=2, ncols=1, sharex=True, gridspec_kw={'height_ratios': [3, 1]}, figsize=figsize,dpi=100)\n",
    "        \n",
    "        if xlims==[]: xlims=[bins_dict[HNL_mass][0],bins_dict[HNL_mass][-1]]\n",
    "        \n",
    "        #----primary plot----#\n",
    "        plt.sca(ax[0])\n",
    "        \n",
    "        if(isinstance(HNL_scale, dict)):\n",
    "            HNL_scaling=HNL_scale[HNL_mass]\n",
    "        else: HNL_scaling = HNL_scale\n",
    "        print(\"HNL scale is \" + str(HNL_scaling))\n",
    "        \n",
    "        bins_cents=[bins_cent_dict[HNL_mass], bins_cent_dict[HNL_mass], bins_cent_dict[HNL_mass]]\n",
    "        \n",
    "        if HNL_scale_label==False: HNL_label = f\"{HNL_mass} MeV HNL\"\n",
    "        if HNL_scale_label==True: \n",
    "            theta = thetas[HNL_mass]\n",
    "            theta_2 = theta**2\n",
    "            new_theta_2 = np.sqrt(scale_up[HNL_mass])*theta_2\n",
    "            theta_2_label = PT.sci_notation(new_theta_2, decimal_digits=0)\n",
    "            HNL_label = f\"{HNL_mass} MeV HNL \\n\" + r\"$|U_{\\mu4}|^2$ = \" + theta_2_label\n",
    "        \n",
    "        labels_sample = {'overlay':fr\"In-Cryo $\\nu$\",\n",
    "                         'dirtoverlay':fr\"Out-Cryo $\\nu$\",\n",
    "                         'beamoff':f\"Beam-Off\",\n",
    "                         'signal':HNL_label}\n",
    "                         #'signal':f\"{HNL_mass} MeV HNL\"}\n",
    "\n",
    "        bkg_scores, bkg_colors, labels = [], [], []\n",
    "        for sample in order:\n",
    "            bkg_scores.append(bkgs[sample][HNL_mass])\n",
    "            bkg_colors.append(colours[sample])\n",
    "            labels.append(labels_sample[sample])\n",
    "        \n",
    "        hist_placeholder = np.histogram(bins_cents, weights=bkg_scores, range=xlims)[0] #Just for calculating ylims\n",
    "        \n",
    "        hist_full_placeholder = np.histogram(bins_cents, weights=bkg_scores, bins=bins_dict[HNL_mass])[0] #For making the error bars\n",
    "        numbins = len(np.where( bins_cent_dict[HNL_mass] > xlims[0] )[0])+1 #Getting the number of bins that will be plotted with the given xlims range\n",
    "               \n",
    "        plot=plt.hist(bins_cents,\n",
    "                      label=labels,\n",
    "                      bins=bins_dict[HNL_mass],\n",
    "                      histtype=\"stepfilled\",\n",
    "                      stacked=True,linewidth=2,edgecolor=\"black\",\n",
    "                      weights=bkg_scores, color=bkg_colors, alpha=ALPHA)\n",
    "        \n",
    "        tot_uncrt = tot_uncertainty_dict[HNL_mass]\n",
    "        upvals_placeholder = hist_full_placeholder+tot_uncrt\n",
    "        lowvals_placeholder = hist_full_placeholder-tot_uncrt\n",
    "        upvals = np.append(upvals_placeholder, [0])\n",
    "        lowvals = np.append(lowvals_placeholder, [0])\n",
    "        \n",
    "        maxy = max(upvals[-numbins:])\n",
    "        \n",
    "        plt.fill_between(bins_dict[HNL_mass], lowvals, upvals, step=\"post\",color=\"grey\",alpha=0.3,zorder=2)\n",
    "\n",
    "        plt.hist(bins_cent_dict[HNL_mass],\n",
    "                 weights=signal[HNL_mass]*HNL_scaling,\n",
    "                 bins=bins_dict[HNL_mass],\n",
    "                 lw=4, edgecolor=colours['signal'], label=labels_sample[\"signal\"], histtype=\"step\")\n",
    "        \n",
    "        sig_placeholder = np.histogram(bins_cent_dict[HNL_mass], weights=signal[HNL_mass]*HNL_scaling, bins=bins_dict[HNL_mass])[0] #For making the error bars\n",
    "        sig_down_placeholder = sig_placeholder-sig_unc[HNL_mass]*HNL_scaling\n",
    "        sig_up_placeholder = sig_placeholder+sig_unc[HNL_mass]*HNL_scaling\n",
    "        sig_down = np.append(sig_down_placeholder, [0])\n",
    "        sig_up = np.append(sig_up_placeholder, [0])\n",
    "        \n",
    "        if sig_sys == True:\n",
    "            plt.rcParams.update({'hatch.color': colours['signal']})\n",
    "            plt.fill_between(bins_dict[HNL_mass], sig_down, sig_up, step=\"post\",hatch='//',alpha=0,zorder=2,lw=2)\n",
    "        \n",
    "        ylims = [0,maxy*1.1]\n",
    "        \n",
    "        plt.xlim(xlims)\n",
    "        if logy==False:\n",
    "            plt.ylim(ylims)\n",
    "        \n",
    "        dat_val=data[HNL_mass]\n",
    "        \n",
    "        x,y=np.histogram(bins_cent_dict[HNL_mass],weights=dat_val,bins=bins_dict[HNL_mass],density=density)\n",
    "        x1,y=np.histogram(bins_cent_dict[HNL_mass],weights=dat_val,bins=bins_dict[HNL_mass])\n",
    "        bin_center = [(y[i] + y[i+1])/2. for i in range(len(y)-1)]\n",
    "        dat_placeholder=x\n",
    "        dat_err=np.sqrt(x1)*np.nan_to_num(x/x1)\n",
    "        \n",
    "        if Run==\"run1\":Run_label = \"Run 1\"\n",
    "        if Run==\"run3\":Run_label = \"Run 3\"\n",
    "        data_label = f\"NuMI Data {Run_label}\"\n",
    "        \n",
    "        plt.errorbar(bin_center,dat_placeholder,yerr=dat_err,fmt='.',color='black',lw=5,capsize=5,elinewidth=3,label=data_label) #Plotting data\n",
    "        \n",
    "        plt.ylabel('Events', fontsize=30)\n",
    "        plt.yscale(logscale)\n",
    "        plt.legend(loc=legloc,frameon=True, fontsize = legsize)\n",
    "        \n",
    "        #----sub-plot----# \n",
    "        plt.sca(ax[1])\n",
    "        \n",
    "        fracer_data=np.nan_to_num(np.sqrt(x1)/x1)\n",
    "        x_err=fracer_data*x\n",
    "        fracer_mc=np.nan_to_num(tot_uncrt/plot[0][2])\n",
    "\n",
    "        rat_err_data=x_err*(1/plot[0][2])\n",
    "\n",
    "        rat_err_mc=fracer_mc\n",
    "\n",
    "        rat_err_mc=np.nan_to_num(rat_err_mc) #other wise the next doesnt plot pro[erly]\n",
    "\n",
    "        upvals= np.append(1+(rat_err_mc),1+(rat_err_mc)[-1]) #hate this but need to repeat last value to get bar on last bin to work, saw it here https://matplotlib.org/stable/gallery/lines_bars_and_markers/filled_step.html\n",
    "        lowvals=np.append(1-(rat_err_mc),1-(rat_err_mc)[-1])\n",
    "\n",
    "        plt.fill_between(y, lowvals, upvals,step=\"post\",color=\"grey\",alpha=0.3,zorder=2)\n",
    "\n",
    "        rat=np.nan_to_num(x/plot[0][2])\n",
    "        rat[x==0]=1 #dont think this is a good way to deal with this\n",
    "\n",
    "        plt.errorbar(bin_center,rat,yerr=fracer_data,fmt='.',color='black',lw=3,capsize=3,elinewidth=1,label=\"data\")\n",
    "        plt.ylabel(\"Data/MC\")\n",
    "        plt.axhline(1,ls='-',color='black')\n",
    "        # plt.axhline(1.1,ls='--',color='grey')\n",
    "        # plt.axhline(0.9,ls='--',color='grey')\n",
    "        ylim = max(abs(np.nan_to_num(rat)))*1.1\n",
    "        ylim_min = min(abs(np.nan_to_num(rat)))*0.9\n",
    "        if (1.0+(1.0-ylim_min))>ylim: Use_ylim = False#Which is further from 1.0\n",
    "        else: Use_ylim = True #i.e the max is further from 1.0 than the min.\n",
    "        ylim_low = 1-(ylim-1.0)\n",
    "        ylim_high = 1+(1.0-ylim_min)\n",
    "        if (ylim>1.5) or (ylim_min<0.5):\n",
    "            if(Use_ylim):plt.ylim(ylim_low,ylim)\n",
    "            else:plt.ylim(ylim_min,ylim_high)\n",
    "        else: plt.ylim(0.5,1.5)\n",
    "        # plt.ylim(0.5,1.5)\n",
    "        # plt.ylim(0.9,1.1)\n",
    "        plt.xlim(xlims)\n",
    "\n",
    "        plt.xlabel('BDT score', fontsize=30)\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.92])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        if savefig == True:\n",
    "            plt.savefig(\"plots/BDT_output/Final_histograms/BDT_output_\" + Run + \"_\" + str(HNL_mass) + \"MeV_\" + logscale + save_str + \".pdf\")\n",
    "            plt.savefig(\"plots/BDT_output/Final_histograms/BDT_output_\" + Run + \"_\" + str(HNL_mass) + \"MeV_\" + logscale + save_str + \".png\")\n",
    "        plt.show()\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639ccb46-a86b-4cd2-aeca-e44d98698fc9",
   "metadata": {},
   "source": [
    "## Run1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74793236-fd36-459c-82d1-127a8c38b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "#theta_squared limits\n",
    "print(\"Please check these are the correct .csv limit files\")\n",
    "uboone_ee_current = Functions.Pandafy_new('limit_files/My_limits/Full_sys_4_bins_expected_20_April.csv')\n",
    "uboone_pi0_reduced = Functions.Pandafy_new('limit_files/My_limits/Full_sys_4_bins_pi0_expected_20_April.csv')\n",
    "\n",
    "if Params_pyhf[\"Load_lepton_hists\"] == True: limit_thetas = uboone_ee_current.set_index('Mass')['Value'].to_dict()\n",
    "if Params_pyhf[\"Load_pi0_hists\"] == True: limit_thetas = uboone_pi0_reduced.set_index('Mass')['Value'].to_dict()\n",
    "\n",
    "print(\"Theta squared limits are: \")\n",
    "print(limit_thetas)\n",
    "\n",
    "theta_scaling, hist_scaling = {}, {}\n",
    "limit_theta_power_1 = {}\n",
    "for HNL_mass in theta_dict:\n",
    "    theta_scaling[HNL_mass] = limit_thetas[HNL_mass]/(theta_dict[HNL_mass]**2)\n",
    "    hist_scaling[HNL_mass] = theta_scaling[HNL_mass]**(2)\n",
    "    limit_theta_power_1[HNL_mass] = limit_thetas[HNL_mass]**(1/2)\n",
    "\n",
    "print(\"Scalings for theta squared values are: \")\n",
    "print(theta_scaling)\n",
    "print(hist_scaling)\n",
    "print(limit_theta_power_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee881fd-d9bd-400a-a3b5-274d431c32ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hist_scaling)\n",
    "visibility_scaling = 20.0\n",
    "new_hist_scaling = {}\n",
    "for HNL_mass in theta_dict:\n",
    "    new_hist_scaling[HNL_mass] = hist_scaling[HNL_mass]*visibility_scaling\n",
    "print(new_hist_scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1428e1-70b0-455a-ab0e-81dd5e50986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Run=\"run1\"\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "XLIMS=[0,bins_dict_r1[150][-1]]\n",
    "if Params_pyhf[\"Load_lepton_hists\"]==True: decay_type = \"ee\"\n",
    "if Params_pyhf[\"Load_pi0_hists\"]==True: decay_type = \"pi0\"\n",
    "\n",
    "savestr = f\"_{decay_type}_data\"\n",
    "# Plot_BDT_output_systematics(signal_dict_r1, tot_uncertainty_dict_r1, sig_sys_err_r1, bkgs_r1, bins_cent_dict_r1, bins_dict_r1, \n",
    "#                             xlims=[0,8.0], legloc=\"upper right\",\n",
    "#                             legsize=22, logy=False, savefig=False, save_str=\"\", Run=Run, HNL_scale=hist_scaling,\n",
    "#                             scale_up=hist_scaling, thetas=theta_dict, sig_sys=False,HNL_scale_label=True)\n",
    "\n",
    "Plot_BDT_output_systematics_data(signal_dict_r1, tot_uncertainty_dict_r1, sig_sys_err_r1, bkgs_r1, data_r1, bins_cent_dict_r1, bins_dict_r1, \n",
    "                                 xlims=XLIMS, legloc=\"upper right\",\n",
    "                                 legsize=22, logy=False, savefig=True, save_str=savestr, Run=Run, HNL_scale=new_hist_scaling,\n",
    "                                 scale_up=new_hist_scaling, thetas=theta_dict, sig_sys=False, HNL_scale_label=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f23100-26e6-41a6-b569-6bfe289c835b",
   "metadata": {},
   "source": [
    "## Run3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d808ca81-2397-404f-b518-acfce5162afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Run=\"run3\"\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "XLIMS=[0,bins_dict_r3[150][-1]]\n",
    "savestr = f\"_{decay_type}_data\"\n",
    "# Plot_BDT_output_systematics(signal_dict_r3, tot_uncertainty_dict_r3, sig_sys_err_r3, bkgs_r3, bins_cent_dict_r3, bins_dict_r3, xlims=[0,8.0], legloc=\"upper right\",\n",
    "#                                 logy=False, savefig=False, save_str=\"\", Run=Run, HNL_scale=1.0, sig_sys=False)\n",
    "\n",
    "Plot_BDT_output_systematics_data(signal_dict_r3, tot_uncertainty_dict_r3, sig_sys_err_r3, bkgs_r3, data_r3, bins_cent_dict_r3, bins_dict_r3, \n",
    "                            xlims=XLIMS, legloc=\"upper right\",\n",
    "                            legsize=22, logy=False, savefig=True, save_str=savestr, Run=Run, HNL_scale=new_hist_scaling,\n",
    "                            scale_up=new_hist_scaling, thetas=theta_dict, sig_sys=False,HNL_scale_label=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c2e45e-7b0c-45cc-a21a-65bfd2fafdc3",
   "metadata": {},
   "source": [
    "## Loading in Uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466c18c5-63d4-4237-96ec-e8ac7a64789c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate_total_uncertainty(Params, hist_dict, bkg_reweight_err_dict=None, bkg_detvar_dict=None, sig_detvar_dict=None): #Takes the dictionary of all root files\n",
    "    BKG_ERR_dict, SIGNAL_ERR_dict = {}, {}\n",
    "    for HNL_mass in hist_dict:\n",
    "        bkg_stat_err_list = [hist_dict[HNL_mass]['bkg_overlay'].errors(), \n",
    "                             hist_dict[HNL_mass]['bkg_EXT'].errors(), \n",
    "                             hist_dict[HNL_mass]['bkg_dirt'].errors()]\n",
    "        sig_stat_err = hist_dict[HNL_mass]['signal'].errors()\n",
    "        if Params[\"Stats_only\"] == True:\n",
    "        #As default the errors saved in the files are stat errors, this will change once I properly calculate them\n",
    "            bkg_err_list = bkg_stat_err_list\n",
    "            sig_err = sig_stat_err\n",
    "        elif Params[\"Use_flat_sys_bkg\"] == True:\n",
    "            zero_bins = []\n",
    "            for i,val in enumerate(hist_dict[HNL_mass]['bkg_overlay'].values()):\n",
    "                if val == 0:\n",
    "                    zero_bins.append(i)\n",
    "                    print(f\"{HNL_mass} last bin 0, setting error to 2.0\")\n",
    "            if len(zero_bins) != 0:\n",
    "                bkg_sys_err_list = [hist_dict[HNL_mass]['bkg_overlay'].values()*Params[\"Flat_overlay_bkg_frac\"] + np.ones_like(hist_dict[HNL_mass]['bkg_overlay'].values())*2.0, #This is horrible need to rewrite \n",
    "                                    np.zeros_like(hist_dict[HNL_mass]['bkg_EXT'].errors()), #No systematic error on the EXT sample\n",
    "                                    hist_dict[HNL_mass]['bkg_dirt'].values()*Params[\"Flat_dirt_bkg_frac\"]]\n",
    "            else:    \n",
    "                bkg_sys_err_list = [hist_dict[HNL_mass]['bkg_overlay'].values()*Params[\"Flat_overlay_bkg_frac\"], \n",
    "                                    np.zeros_like(hist_dict[HNL_mass]['bkg_EXT'].errors()), #No systematic error on the EXT sample\n",
    "                                    hist_dict[HNL_mass]['bkg_dirt'].values()*Params[\"Flat_dirt_bkg_frac\"]]\n",
    "            bkg_err_list = [Functions.add_all_errors([bkg_stat_err_list[0],bkg_sys_err_list[0]]), #adding the sys and stat error in quadrature for each bkg type\n",
    "                            Functions.add_all_errors([bkg_stat_err_list[1],bkg_sys_err_list[1]]),\n",
    "                            Functions.add_all_errors([bkg_stat_err_list[2],bkg_sys_err_list[2]])]\n",
    "        elif Params[\"Use_flat_sys_bkg\"] == False:\n",
    "            ppfx_unc = hist_dict[HNL_mass][\"ppfx_uncertainty\"].values()\n",
    "            genie_unc = hist_dict[HNL_mass][\"Genie_uncertainty\"].values()\n",
    "            reint_unc = hist_dict[HNL_mass][\"Reinteraction_uncertainty\"].values()\n",
    "            # detvar_unc = bkg_detvar_dict[HNL_mass][\"Total_DetVar_uncertainty\"].values() #Don't know what this looks like yet, as I haven't made\n",
    "            detvar_unc = hist_dict[HNL_mass]['bkg_overlay'].values()*Params[\"Overlay_detvar_frac\"] #Just setting as flat. Too much variation in samples\n",
    "            tot_overlay_sys = Functions.add_all_errors([ppfx_unc, genie_unc, reint_unc, detvar_unc])\n",
    "            bkg_sys_err_list = [tot_overlay_sys, \n",
    "                                np.zeros_like(hist_dict[HNL_mass]['bkg_EXT'].errors()), #No systematic error on the EXT sample\n",
    "                                hist_dict[HNL_mass]['bkg_dirt'].values()*Params[\"Flat_dirt_bkg_frac\"]] #Don't have reweight or DetVar samples for dirt\n",
    "            bkg_err_list = [Functions.add_all_errors([bkg_stat_err_list[0],bkg_sys_err_list[0]]), #adding the sys and stat error in quadrature for each bkg type\n",
    "                            Functions.add_all_errors([bkg_stat_err_list[1],bkg_sys_err_list[1]]),\n",
    "                            Functions.add_all_errors([bkg_stat_err_list[2],bkg_sys_err_list[2]])]\n",
    "        if (Params[\"Stats_only\"] == False) and (Params[\"Use_flat_sys_signal\"] == True):\n",
    "            zero_bins = []\n",
    "            for i,val in enumerate(hist_dict[HNL_mass]['signal'].values()):\n",
    "                if val == 0:\n",
    "                    zero_bins.append(i)\n",
    "                    print(f\"{HNL_mass} signal last bin 0, setting error to 2.0\")\n",
    "            if len(zero_bins) != 0:\n",
    "                sig_sys_err = hist_dict[HNL_mass]['signal'].values()*Params[\"Flat_sig_frac\"]+2.0\n",
    "            else:\n",
    "                sig_sys_err = hist_dict[HNL_mass]['signal'].values()*Params[\"Flat_sig_frac\"]\n",
    "            sig_err = Functions.add_all_errors([sig_stat_err,sig_sys_err])\n",
    "        if (Params[\"Stats_only\"] == False) and (Params[\"Use_flat_sys_signal\"] == False):\n",
    "            sig_detvar_err = sig_detvar_dict[HNL_mass][\"Total_DetVar_uncertainty\"].values()\n",
    "            sig_flux_err = hist_dict[HNL_mass]['signal'].values()*Params[\"Flat_overlay_bkg_frac\"]\n",
    "            sig_err = Functions.add_all_errors([sig_stat_err,sig_detvar_err,sig_flux_err]) #Adding stat, detvar and flux errors in quadrature\n",
    "        total_bkg_err = Functions.add_all_errors(bkg_err_list) #Now adding the errors of overlay, EXT and dirt in quadrature\n",
    "        BKG_ERR_dict[HNL_mass] = total_bkg_err\n",
    "        SIGNAL_ERR_dict[HNL_mass] = sig_err\n",
    "    return BKG_ERR_dict, SIGNAL_ERR_dict\n",
    "    \n",
    "def Add_bkg_hists_make_signal(hist_dict):\n",
    "    BKG_dict, SIGNAL_dict = {}, {}\n",
    "    for HNL_mass in hist_dict:\n",
    "        bkg_hists = [hist_dict[HNL_mass]['bkg_EXT'], hist_dict[HNL_mass]['bkg_overlay'], hist_dict[HNL_mass]['bkg_dirt']]\n",
    "        \n",
    "        total_bkg = Functions.add_hists_vals(bkg_hists)\n",
    "        BKG_dict[HNL_mass] = total_bkg\n",
    "        SIGNAL_dict[HNL_mass] = hist_dict[HNL_mass]['signal'].values()\n",
    " \n",
    "    return BKG_dict, SIGNAL_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a072bf2-93ee-463a-b274-6f31f7dd0b99",
   "metadata": {},
   "source": [
    "## End of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513a4fdd-4afb-4c4e-b13b-7873ce2318a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
