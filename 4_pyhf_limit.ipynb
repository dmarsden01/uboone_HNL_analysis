{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffe0cab0-578b-42ea-86af-07342852e08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful!\n"
     ]
    }
   ],
   "source": [
    "#Loading libraries\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyhf\n",
    "from pyhf.contrib.viz import brazil\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import uproot3\n",
    "import uproot\n",
    "import math\n",
    "import awkward as ak\n",
    "import pickle\n",
    "\n",
    "import csv\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "import Utilities.Constants as Constants\n",
    "import Utilities.Functions as Functions\n",
    "\n",
    "print(\"Successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6939111e-d766-4112-ab60-1fd7c65239ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using FLAT systematic uncertainty on background\n",
      "With 50.0% on overlay, and 100.0% on dirt.\n",
      "Using FLAT systematic uncertainty on signal\n",
      "With 50.0% on all signal\n"
     ]
    }
   ],
   "source": [
    "Params_pyhf = {\"Use_flat_sys_bkg\":True,\n",
    "               \"Use_flat_sys_signal\":True,\n",
    "               \"Stats_only\":False,\n",
    "               \"Use_second_half_only\":True,\n",
    "               \"Load_logit_hists\":True,\n",
    "               \"Use_toys\":False,\n",
    "               \"Num_toys\":100,\n",
    "               \"Load_lepton_hists\":False,\n",
    "               \"Load_pi0_hists\":True,\n",
    "               \"Flat_overlay_bkg_frac\":0.5,\n",
    "               \"Flat_dirt_bkg_frac\":1.0,\n",
    "               \"Flat_sig_frac\":0.5,\n",
    "               \"Signal_flux_error\":0.3}\n",
    "\n",
    "Functions.pyhf_params(Params_pyhf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edb78650-72a3-4fa1-ad92-465a31cba48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "#Loading My BDT histograms\n",
    "loc_hists = 'bdt_output/'\n",
    "\n",
    "hist_dict_run1 = {}\n",
    "hist_dict_run3 = {}\n",
    "\n",
    "#Loading in the .root files\n",
    "if Params_pyhf[\"Load_lepton_hists\"] == True:\n",
    "    for HNL_mass in Constants.HNL_mass_samples:\n",
    "    # for HNL_mass in [10]:\n",
    "        if Params_pyhf[\"Load_logit_hists\"] == False:\n",
    "            hist_dict_run1[HNL_mass] = uproot.open(loc_hists+f'run1_{HNL_mass}MeV_test2.root')\n",
    "            hist_dict_run3[HNL_mass] = uproot.open(loc_hists+f'run3_{HNL_mass}MeV_test2.root')\n",
    "        if Params_pyhf[\"Load_logit_hists\"] == True:\n",
    "            hist_dict_run1[HNL_mass] = uproot.open(loc_hists+f'run1_{HNL_mass}MeV_logit_top_20_merged.root')\n",
    "            hist_dict_run3[HNL_mass] = uproot.open(loc_hists+f'run3_{HNL_mass}MeV_logit_top_20_merged.root')\n",
    "    \n",
    "if Params_pyhf[\"Load_pi0_hists\"] == True:\n",
    "    pi0_dict_run1, pi0_dict_run3 = {}, {}\n",
    "    for HNL_mass in Constants.HNL_mass_pi0_samples:\n",
    "        if Params_pyhf[\"Load_logit_hists\"] == False:\n",
    "            hist_dict_run1[HNL_mass] = uproot.open(loc_hists+f'pi0/run1_{HNL_mass}MeV_test1.root') #run1_150MeV_logit_test1.root\n",
    "            # pi0_dict_run3[HNL_mass] = uproot.open(loc_hists+f'pi0/run3_{HNL_mass}MeV_test2.root')\n",
    "        if Params_pyhf[\"Load_logit_hists\"] == True:\n",
    "            hist_dict_run1[HNL_mass] = uproot.open(loc_hists+f'pi0/run1_{HNL_mass}MeV_logit_test1.root')\n",
    "            # pi0_dict_run3[HNL_mass] = uproot.open(loc_hists+f'pi0/run3_{HNL_mass}MeV_logit_test5.root')\n",
    "\n",
    "#list_of_dicts = [hist_dict_run1, hist_dict_run3] #Add run2 when available, not using yet\n",
    "\n",
    "#Constants\n",
    "theta_squared = Constants.theta_mu_4*Constants.theta_mu_4\n",
    "\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67f13771-c136-43f0-b489-70a01787d4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([150, 180, 200, 220, 240, 245])\n"
     ]
    }
   ],
   "source": [
    "print(hist_dict_run1.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c2e45e-7b0c-45cc-a21a-65bfd2fafdc3",
   "metadata": {},
   "source": [
    "## Loading in Uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4a24f4e-b7fb-4be2-bf2f-0895823c373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (Params_pyhf[\"Stats_only\"] == False) and (Params_pyhf[\"Use_flat_sys_bkg\"] == False):\n",
    "    err_dict_run1, err_dict_run3 = {}, {}\n",
    "    for HNL_mass in Constants.HNL_mass_samples:\n",
    "        err_dict_run1[HNL_mass] = uproot.open(loc_hists+f'Uncertainties/run1_Test_2_{HNL_mass}MeV.root')\n",
    "        err_dict_run3[HNL_mass] = uproot.open(loc_hists+f'Uncertainties/run3_Test_2_{HNL_mass}MeV.root')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "466c18c5-63d4-4237-96ec-e8ac7a64789c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate_total_uncertainty(Params, hist_dict, bkg_reweight_err_dict=None, bkg_detvar_dict=None, sig_detvar_dict=None): #Takes the dictionary of all root files\n",
    "    BKG_ERR_dict, SIGNAL_ERR_dict = {}, {}\n",
    "    for HNL_mass in hist_dict:\n",
    "        bkg_stat_err_list = [hist_dict[HNL_mass]['bkg_overlay'].errors(), \n",
    "                             hist_dict[HNL_mass]['bkg_EXT'].errors(), \n",
    "                             hist_dict[HNL_mass]['bkg_dirt'].errors()]\n",
    "        sig_stat_err = hist_dict[HNL_mass]['signal'].errors()\n",
    "        if Params[\"Stats_only\"] == True:\n",
    "        #As default the errors saved in the files are stat errors, this will change once I properly calculate them\n",
    "            bkg_err_list = bkg_stat_err_list\n",
    "            sig_err = sig_stat_err\n",
    "        elif Params[\"Use_flat_sys_bkg\"] == True:\n",
    "            zero_bins = []\n",
    "            for i,val in enumerate(hist_dict[HNL_mass]['bkg_overlay'].values()):\n",
    "                if val == 0:\n",
    "                    zero_bins.append(i)\n",
    "                    print(f\"{HNL_mass} last bin 0, setting error to 2.0\")\n",
    "            if len(zero_bins) != 0:\n",
    "                bkg_sys_err_list = [hist_dict[HNL_mass]['bkg_overlay'].values()*Params[\"Flat_overlay_bkg_frac\"] + np.ones_like(hist_dict[HNL_mass]['bkg_overlay'].values())*2.0, #This is horrible need to rewrite \n",
    "                                    np.zeros_like(hist_dict[HNL_mass]['bkg_EXT'].errors()), #No systematic error on the EXT sample\n",
    "                                    hist_dict[HNL_mass]['bkg_dirt'].values()*Params[\"Flat_dirt_bkg_frac\"]]\n",
    "            else:    \n",
    "                bkg_sys_err_list = [hist_dict[HNL_mass]['bkg_overlay'].values()*Params[\"Flat_overlay_bkg_frac\"], \n",
    "                                    np.zeros_like(hist_dict[HNL_mass]['bkg_EXT'].errors()), #No systematic error on the EXT sample\n",
    "                                    hist_dict[HNL_mass]['bkg_dirt'].values()*Params[\"Flat_dirt_bkg_frac\"]]\n",
    "            bkg_err_list = [Functions.add_all_errors([bkg_stat_err_list[0],bkg_sys_err_list[0]]), #adding the sys and stat error in quadrature for each bkg type\n",
    "                            Functions.add_all_errors([bkg_stat_err_list[1],bkg_sys_err_list[1]]),\n",
    "                            Functions.add_all_errors([bkg_stat_err_list[2],bkg_sys_err_list[2]])]\n",
    "        elif Params[\"Use_flat_sys_bkg\"] == False:\n",
    "            ppfx_unc = bkg_reweight_err_dict[HNL_mass][\"ppfx_uncertainty\"].values()\n",
    "            genie_unc = bkg_reweight_err_dict[HNL_mass][\"Genie_uncertainty\"].values()\n",
    "            reint_unc = bkg_reweight_err_dict[HNL_mass][\"Reinteraction_uncertainty\"].values()\n",
    "            detvar_unc = bkg_detvar_dict[HNL_mass][\"Total_DetVar_uncertainty\"].values() #Don't know what this looks like yet, as I haven't made\n",
    "            tot_overlay_sys = Functions.add_all_errors([ppfx_unc, genie_unc, reint_unc, detvar_unc])\n",
    "            bkg_sys_err_list = [tot_overlay_sys, \n",
    "                                0, #No systematic error on the EXT sample\n",
    "                                hist_dict[HNL_mass]['bkg_dirt'].values()*Params[\"Flat_dirt_bkg_frac\"]] #Don't have reweight or DetVar samples for dirt\n",
    "            bkg_err_list = [Functions.add_all_errors([bkg_stat_err_list[0],bkg_sys_err_list[0]]), #adding the sys and stat error in quadrature for each bkg type\n",
    "                            Functions.add_all_errors([bkg_stat_err_list[1],bkg_sys_err_list[1]]),\n",
    "                            Functions.add_all_errors([bkg_stat_err_list[2],bkg_sys_err_list[2]])]\n",
    "        if (Params[\"Stats_only\"] == False) and (Params[\"Use_flat_sys_signal\"] == True):\n",
    "            zero_bins = []\n",
    "            for i,val in enumerate(hist_dict[HNL_mass]['signal'].values()):\n",
    "                if val == 0:\n",
    "                    zero_bins.append(i)\n",
    "                    print(f\"{HNL_mass} signal last bin 0, setting error to 2.0\")\n",
    "            if len(zero_bins) != 0:\n",
    "                sig_sys_err = hist_dict[HNL_mass]['signal'].values()*Params[\"Flat_sig_frac\"]+2.0\n",
    "            else:\n",
    "                sig_sys_err = hist_dict[HNL_mass]['signal'].values()*Params[\"Flat_sig_frac\"]\n",
    "            sig_err = Functions.add_all_errors([sig_stat_err,sig_sys_err])\n",
    "        if (Params[\"Stats_only\"] == False) and (Params[\"Use_flat_sys_signal\"] == False):\n",
    "            sig_detvar_err = sig_detvar_dict[HNL_mass][\"Total_DetVar_uncertainty\"].values()\n",
    "            sig_flux_err = hist_dict[HNL_mass]['signal'].values()*Params[\"Flat_overlay_bkg_frac\"]\n",
    "            sig_err = Functions.add_all_errors([sig_stat_err,sig_detvar_err,sig_flux_err]) #Adding stat, detvar and flux errors in quadrature\n",
    "        total_bkg_err = Functions.add_all_errors(bkg_err_list) #Now adding the errors of overlay, EXT and dirt in quadrature\n",
    "        BKG_ERR_dict[HNL_mass] = total_bkg_err\n",
    "        SIGNAL_ERR_dict[HNL_mass] = sig_err\n",
    "    return BKG_ERR_dict, SIGNAL_ERR_dict\n",
    "    \n",
    "def Add_bkg_hists_make_signal(hist_dict):\n",
    "    BKG_dict, SIGNAL_dict = {}, {}\n",
    "    for HNL_mass in hist_dict:\n",
    "        bkg_hists = [hist_dict[HNL_mass]['bkg_EXT'], hist_dict[HNL_mass]['bkg_overlay'], hist_dict[HNL_mass]['bkg_dirt']]\n",
    "        \n",
    "        total_bkg = Functions.add_hists_vals(bkg_hists)\n",
    "        BKG_dict[HNL_mass] = total_bkg\n",
    "        SIGNAL_dict[HNL_mass] = hist_dict[HNL_mass]['signal'].values()\n",
    " \n",
    "    return BKG_dict, SIGNAL_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d595061-c00a-43c5-845f-16e9d176918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_dict(Total_dict):\n",
    "    model_dict = {}\n",
    "    \n",
    "    for HNL_mass in Total_dict:\n",
    "        model_dict[HNL_mass] = pyhf.Model(\n",
    "        {\n",
    "      \"channels\": [\n",
    "        {\n",
    "          \"name\": \"singlechannel\",\n",
    "          \"samples\": [\n",
    "            {\n",
    "              \"name\": \"signal\",\n",
    "              \"data\": Total_dict[HNL_mass][\"SIGNAL_dict\"],\n",
    "              \"modifiers\": [\n",
    "                {\n",
    "                  \"name\": \"mu\",\n",
    "                  \"type\": \"normfactor\",\n",
    "                  \"data\": None\n",
    "                },\n",
    "                {\n",
    "                  \"name\": \"uncorr_siguncrt\",\n",
    "                  \"type\": \"shapesys\",\n",
    "                  \"data\": Total_dict[HNL_mass][\"SIGNAL_ERR_dict\"]  \n",
    "                }\n",
    "              ]\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"background\",\n",
    "              \"data\": Total_dict[HNL_mass][\"BKG_dict\"],\n",
    "              \"modifiers\": [\n",
    "                {\n",
    "                  \"name\": \"uncorr_bkguncrt\",\n",
    "                  \"type\": \"shapesys\",\n",
    "                  \"data\": Total_dict[HNL_mass][\"BKG_ERR_dict\"]\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "    )\n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e370570b-20ae-4a1f-aeda-8a8b2e95ce0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([150, 180, 200, 220, 240, 245])\n"
     ]
    }
   ],
   "source": [
    "R1_BKG_ERR_dict, R1_SIGNAL_ERR_dict = Calculate_total_uncertainty(Params_pyhf, hist_dict_run1)\n",
    "R3_BKG_ERR_dict, R3_SIGNAL_ERR_dict = Calculate_total_uncertainty(Params_pyhf, hist_dict_run3)\n",
    "\n",
    "R1_BKG, R1_SIGNAL = Add_bkg_hists_make_signal(hist_dict_run1)\n",
    "R3_BKG, R3_SIGNAL = Add_bkg_hists_make_signal(hist_dict_run3)\n",
    "\n",
    "R1_output = Functions.Make_into_lists(Params_pyhf, R1_BKG, R1_SIGNAL, R1_BKG_ERR_dict, R1_SIGNAL_ERR_dict)\n",
    "R3_output = Functions.Make_into_lists(Params_pyhf, R3_BKG, R3_SIGNAL, R3_BKG_ERR_dict, R3_SIGNAL_ERR_dict)\n",
    "\n",
    "# list_input_dicts = [R1_output, R3_output]\n",
    "list_input_dicts = [R1_output, R1_output] #Used when I didn't have Run3\n",
    "\n",
    "Total_dict = Functions.Create_final_appended_runs_dict(list_input_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a0fd0bb-d3a4-4317-bf1c-66aa8b4191ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = create_model_dict(Total_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68fc82f-8497-4465-88d7-ea486bdb2f3e",
   "metadata": {},
   "source": [
    "## Testing single point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b9c533c-cc65-4f3c-8be0-dee7b236807a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected CLs(-1 σ): 0.4498\n",
      "Expected CLs( 0 σ): 0.5912\n",
      "Expected CLs( 1 σ): 0.7507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/jupyter/envs/ana/lib/python3.7/site-packages/pyhf/infer/calculators.py:369: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  teststat = (qmu - qmu_A) / (2 * self.sqrtqmuA_v)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper limit 10MeV (obs): μ = 5.6908\n",
      "Upper limit 10MeV (exp): μ = 5.6908\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HNL_mass = 10 #Mass point to test\n",
    "DATA_OBS_dict = {}\n",
    "obs_limit_dict = {}\n",
    "exp_limits_dict = {}\n",
    "init_pars = model_dict[HNL_mass].config.suggested_init()\n",
    "model_dict[HNL_mass].expected_actualdata(init_pars) #signal plus bkg\n",
    "\n",
    "bkg_pars = init_pars.copy()\n",
    "bkg_pars[model_dict[HNL_mass].config.poi_index] = 0\n",
    "model_dict[HNL_mass].expected_actualdata(bkg_pars) #bkg only\n",
    "\n",
    "DATA_OBS_dict[HNL_mass] = Total_dict[HNL_mass][\"BKG_dict\"]+model_dict[HNL_mass].config.auxdata\n",
    "\n",
    "model_dict[HNL_mass].logpdf(pars=bkg_pars, data=DATA_OBS_dict[HNL_mass])\n",
    "\n",
    "CLs_obs, CLs_exp = pyhf.infer.hypotest(\n",
    "            1.0,  # null hypothesis\n",
    "            DATA_OBS_dict[HNL_mass],\n",
    "            model_dict[HNL_mass],\n",
    "            test_stat=\"qtilde\",\n",
    "            return_expected_set=True,\n",
    "            calctype=\"asymptotics\",\n",
    "            )\n",
    "for expected_value, n_sigma in zip(CLs_exp, np.arange(-1, 2)):\n",
    "    print(f\"Expected CLs({n_sigma:2d} σ): {expected_value:.4f}\")\n",
    "    \n",
    "poi_values = np.linspace(0.001, 10, 50)\n",
    "obs_limit_single, exp_limits_single, (scan, results) = pyhf.infer.intervals.upperlimit(DATA_OBS_dict[HNL_mass], \n",
    "                                                                                       model_dict[HNL_mass], poi_values, \n",
    "                                                                                       level=0.1, return_results=True)\n",
    "print(f\"Upper limit {HNL_mass}MeV (obs): μ = {obs_limit_single:.4f}\")\n",
    "print(f\"Upper limit {HNL_mass}MeV (exp): μ = {exp_limits_single[2]:.4f}\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb30a6bc-7a6c-47b4-89df-7688667c8c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 10MeV limit is 0.0009542149778660387\n",
      "Observed 10MeV limit is 0.0009542149778660387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('bdt_output/new_theta_dict_2.pkl', 'rb') as handle:\n",
    "    new_theta_dict = pickle.load(handle)\n",
    "#print(new_theta_dict)\n",
    "scaled_thetas = new_theta_dict #Saved in 3.5_BDT_Result\n",
    "\n",
    "exp_limit = []\n",
    "obs_limit = []\n",
    "\n",
    "# for HNL_mass in Constants.HNL_mass_samples:\n",
    "for HNL_mass in [10]:\n",
    "    theta_squared = (scaled_thetas[HNL_mass])**2\n",
    "\n",
    "    EXP_LIMIT = np.sqrt(exp_limits_single[2])*theta_squared\n",
    "    LIMIT = np.sqrt(obs_limit_single)*theta_squared\n",
    "    print(f\"Expected {HNL_mass}MeV limit is \" + str(EXP_LIMIT))\n",
    "    print(f\"Observed {HNL_mass}MeV limit is \" + str(LIMIT)+ \"\\n\")\n",
    "    \n",
    "    exp_limit.append(EXP_LIMIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0d29e6-f7f4-4088-b9c5-0ccc2fd1f419",
   "metadata": {},
   "source": [
    "## Running through all points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15d15f43-88df-42fe-886b-d3b8ac4a02f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150, 180, 200, 220, 240, 245]\n"
     ]
    }
   ],
   "source": [
    "list_test = Constants.HNL_mass_pi0_samples\n",
    "print(list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93ace42d-de08-48dd-8c1a-ed51a6f79b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_OBS_dict = {}\n",
    "\n",
    "# for HNL_mass in Constants.HNL_mass_samples: #removing the 240MeV point\n",
    "for HNL_mass in list_test:\n",
    "    init_pars = model_dict[HNL_mass].config.suggested_init()\n",
    "    model_dict[HNL_mass].expected_actualdata(init_pars) #signal plus bkg\n",
    "\n",
    "    bkg_pars = init_pars.copy()\n",
    "    bkg_pars[model_dict[HNL_mass].config.poi_index] = 0\n",
    "    model_dict[HNL_mass].expected_actualdata(bkg_pars) #bkg only\n",
    "\n",
    "    DATA_OBS_dict[HNL_mass] = Total_dict[HNL_mass][\"BKG_dict\"]+model_dict[HNL_mass].config.auxdata\n",
    "\n",
    "    model_dict[HNL_mass].logpdf(pars=bkg_pars, data=DATA_OBS_dict[HNL_mass])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4234fa8-33c9-48dc-9eaa-674262afcba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/jupyter/envs/ana/lib/python3.7/site-packages/scipy/optimize/optimize.py:283: RuntimeWarning: Values in x were outside bounds during a minimize step, clipping to bounds\n",
      "  \"minimize step, clipping to bounds\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150MeV\n",
      "Expected CLs(-2 σ): 0.0000\n",
      "Expected CLs(-1 σ): 0.0000\n",
      "Expected CLs( 0 σ): 0.0000\n",
      "Expected CLs( 1 σ): 0.0000\n",
      "Expected CLs( 2 σ): 0.0000\n",
      "180MeV\n",
      "Expected CLs(-2 σ): 0.0000\n",
      "Expected CLs(-1 σ): 0.0000\n",
      "Expected CLs( 0 σ): 0.0000\n",
      "Expected CLs( 1 σ): 0.0000\n",
      "Expected CLs( 2 σ): 0.0000\n",
      "200MeV\n",
      "Expected CLs(-2 σ): 0.0038\n",
      "Expected CLs(-1 σ): 0.0184\n",
      "Expected CLs( 0 σ): 0.0790\n",
      "Expected CLs( 1 σ): 0.2671\n",
      "Expected CLs( 2 σ): 0.6101\n",
      "220MeV\n",
      "Expected CLs(-2 σ): 0.0000\n",
      "Expected CLs(-1 σ): 0.0000\n",
      "Expected CLs( 0 σ): 0.0004\n",
      "Expected CLs( 1 σ): 0.0065\n",
      "Expected CLs( 2 σ): 0.0629\n",
      "240MeV\n",
      "Expected CLs(-2 σ): 0.3103\n",
      "Expected CLs(-1 σ): 0.4598\n",
      "Expected CLs( 0 σ): 0.6497\n",
      "Expected CLs( 1 σ): 0.8408\n",
      "Expected CLs( 2 σ): 0.9608\n",
      "245MeV\n",
      "Expected CLs(-2 σ): 0.1410\n",
      "Expected CLs(-1 σ): 0.2660\n",
      "Expected CLs( 0 σ): 0.4680\n",
      "Expected CLs( 1 σ): 0.7227\n",
      "Expected CLs( 2 σ): 0.9196\n"
     ]
    }
   ],
   "source": [
    "# for HNL_mass in Constants.HNL_mass_samples:\n",
    "for HNL_mass in list_test:\n",
    "\n",
    "    if Params_pyhf[\"Use_toys\"] == False:\n",
    "        CLs_obs, CLs_exp = pyhf.infer.hypotest(\n",
    "            1.0,  # null hypothesis\n",
    "            DATA_OBS_dict[HNL_mass],\n",
    "            model_dict[HNL_mass],\n",
    "            test_stat=\"qtilde\",\n",
    "            return_expected_set=True,\n",
    "            calctype=\"asymptotics\",\n",
    "            )\n",
    "    if Params_pyhf[\"Use_toys\"] == True:\n",
    "        CLs_obs, CLs_exp = pyhf.infer.hypotest(\n",
    "            1.0,  # null hypothesis\n",
    "            DATA_OBS_dict[HNL_mass],\n",
    "            model_dict[HNL_mass],\n",
    "            test_stat=\"qtilde\",\n",
    "            return_expected_set=True,\n",
    "            calctype=\"toybased\",\n",
    "            ntoys=Params_pyhf[\"Num_toys\"],\n",
    "            track_progress=True,\n",
    "            )\n",
    "    \n",
    "    print(f\"{HNL_mass}MeV\")\n",
    "    for expected_value, n_sigma in zip(CLs_exp, np.arange(-2, 3)):\n",
    "        print(f\"Expected CLs({n_sigma:2d} σ): {expected_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2727ad3d-56ab-42bf-ae92-e24e5b50f592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If the output of the following is equal to the lowest or highest value of poi, the range needs to be extended\n",
      "Upper limit 150MeV (obs): μ = 0.0201\n",
      "Upper limit 150MeV (exp): μ = 0.0201\n",
      "\n",
      "Upper limit 180MeV (obs): μ = 0.0406\n",
      "Upper limit 180MeV (exp): μ = 0.0406\n",
      "\n",
      "Upper limit 200MeV (obs): μ = 0.9239\n",
      "Upper limit 200MeV (exp): μ = 0.9239\n",
      "\n",
      "Upper limit 220MeV (obs): μ = 0.3578\n",
      "Upper limit 220MeV (exp): μ = 0.3578\n",
      "\n",
      "Upper limit 240MeV (obs): μ = 2.0000\n",
      "Upper limit 240MeV (exp): μ = 2.0000\n",
      "\n",
      "Upper limit 245MeV (obs): μ = 2.0000\n",
      "Upper limit 245MeV (exp): μ = 2.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "obs_limit_dict = {}\n",
    "exp_limits_dict = {}\n",
    "print(\"If the output of the following is equal to the lowest or highest value of poi, the range needs to be extended\")\n",
    "\n",
    "# for HNL_mass in Constants.HNL_mass_samples:\n",
    "for HNL_mass in list_test:\n",
    "\n",
    "    poi_values = np.linspace(0.001, 2, 100)\n",
    "    obs_limit_dict[HNL_mass], exp_limits_dict[HNL_mass], (scan, results) = pyhf.infer.intervals.upperlimit(\n",
    "        DATA_OBS_dict[HNL_mass], model_dict[HNL_mass], poi_values, level=0.1, return_results=True\n",
    "    )\n",
    "    print(f\"Upper limit {HNL_mass}MeV (obs): μ = {obs_limit_dict[HNL_mass]:.4f}\")\n",
    "    print(f\"Upper limit {HNL_mass}MeV (exp): μ = {exp_limits_dict[HNL_mass][2]:.4f}\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f0dcf7f-0665-430c-8239-66452b8bf24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06\n",
      "Expected 150MeV limit is 1.4183768288927653e-07\n",
      "Observed 150MeV limit is 1.4183768288927653e-07\n",
      "\n",
      "2.5e-07\n",
      "Expected 180MeV limit is 5.0394222193883816e-08\n",
      "Observed 180MeV limit is 5.0394222193883816e-08\n",
      "\n",
      "4e-08\n",
      "Expected 200MeV limit is 3.844840776376411e-08\n",
      "Observed 200MeV limit is 3.844840776376411e-08\n",
      "\n",
      "4e-08\n",
      "Expected 220MeV limit is 2.3925669204464607e-08\n",
      "Observed 220MeV limit is 2.3925669204464607e-08\n",
      "\n",
      "1e-08\n",
      "Expected 240MeV limit is 1.4142135623730952e-08\n",
      "Observed 240MeV limit is 1.4142135623730952e-08\n",
      "\n",
      "1e-08\n",
      "Expected 245MeV limit is 1.4142135623730952e-08\n",
      "Observed 245MeV limit is 1.4142135623730952e-08\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if Params_pyhf[\"Load_pi0_hists\"] == False:\n",
    "    with open('bdt_output/new_theta_dict.pkl', 'rb') as handle:\n",
    "        new_theta_dict = pickle.load(handle)\n",
    "if Params_pyhf[\"Load_pi0_hists\"] == True:\n",
    "    with open('bdt_output/pi0/new_theta_dict_pi0.pkl', 'rb') as handle:\n",
    "        new_theta_dict = pickle.load(handle)\n",
    "#print(new_theta_dict)\n",
    "scaled_thetas = new_theta_dict #Saved in 3.5_BDT_Result\n",
    "\n",
    "exp_limit = []\n",
    "obs_limit = []\n",
    "\n",
    "# for HNL_mass in Constants.HNL_mass_samples:\n",
    "for HNL_mass in list_test:\n",
    "    theta_squared = (scaled_thetas[HNL_mass])**2\n",
    "    print(theta_squared)\n",
    "\n",
    "    EXP_LIMIT = np.sqrt(exp_limits_dict[HNL_mass][2])*theta_squared\n",
    "    LIMIT = np.sqrt(obs_limit_dict[HNL_mass])*theta_squared\n",
    "    # if HNL_mass in Constants.Old_generator_mass_points:\n",
    "    #     EXP_LIMIT = EXP_LIMIT*np.sqrt(1/Constants.Old_gen_HNL_scalings[HNL_mass])\n",
    "    #     LIMIT = LIMIT*np.sqrt(1/Constants.Old_gen_HNL_scalings[HNL_mass])\n",
    "    print(f\"Expected {HNL_mass}MeV limit is \" + str(EXP_LIMIT))\n",
    "    print(f\"Observed {HNL_mass}MeV limit is \" + str(LIMIT)+ \"\\n\")\n",
    "    \n",
    "    exp_limit.append(EXP_LIMIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8437737-0007-42bb-9cfa-bd8e2a45194e",
   "metadata": {},
   "source": [
    "## Saving limit as .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f20e73a7-2fee-4aad-9067-e3dd5d7d9f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150, 180, 200, 220, 240, 245]\n",
      "[1.4183768288927653e-07, 5.0394222193883816e-08, 3.844840776376411e-08, 2.3925669204464607e-08, 1.4142135623730952e-08, 1.4142135623730952e-08]\n"
     ]
    }
   ],
   "source": [
    "# masses = Constants.HNL_mass_samples\n",
    "masses = list_test\n",
    "\n",
    "if Params_pyhf[\"Stats_only\"] == True:\n",
    "    stats =  \"Stats_only\"\n",
    "else:\n",
    "    stats = \"Flat_sys\"\n",
    "    \n",
    "if Params_pyhf[\"Use_second_half_only\"] == True:\n",
    "    half_hist = \"havled\"\n",
    "else:\n",
    "    half_hist = \"full_hist\"\n",
    "\n",
    "print(masses)\n",
    "print(exp_limit)\n",
    "\n",
    "r = zip(masses, exp_limit)\n",
    "if Params_pyhf[\"Load_pi0_hists\"] == False:\n",
    "    with open(f'limit_files/{stats}_{half_hist}_expected_mu_top_20_logit_New_gen_70percent_signal.csv', \"w\") as s:\n",
    "        w = csv.writer(s)\n",
    "        for row in r:\n",
    "            w.writerow(row)\n",
    "            \n",
    "if Params_pyhf[\"Load_pi0_hists\"] == True:\n",
    "    with open(f'limit_files/{stats}_{half_hist}_expected_mu_all_vars_logit_New_run1.csv', \"w\") as s:\n",
    "        w = csv.writer(s)\n",
    "        for row in r:\n",
    "            w.writerow(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a259396-713f-4435-99e8-870067d7c520",
   "metadata": {},
   "source": [
    "## Finished code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1787c6f6-155b-472d-8587-627baeaa4e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def New_BR_limit(Old_theta_squared, HNL_mass):\n",
    "#     New_limit = Old_theta_squared*np.sqrt(1/Constants.Old_gen_HNL_scalings[HNL_mass])\n",
    "#     print(\"Old limit was \" + str(Old_theta_squared))\n",
    "#     print(\"New limit is \" + str(New_limit))\n",
    "#     return New_limit\n",
    "\n",
    "# Old_limits = {20:0.00015681119188699395,\n",
    "#               50:9.92373190724973e-06,\n",
    "#               100:9.84200063077575e-07,\n",
    "#               150:1.2830647341135436e-07,\n",
    "#               180:7.604092480424186e-08}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d15b7ad-a343-44ab-8045-dbd8ee626630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old limit was 0.00015681119188699395\n",
      "New limit is 4.473705399878215e-06\n",
      "Old limit was 9.92373190724973e-06\n",
      "New limit is 7.026375098105447e-07\n",
      "Old limit was 9.84200063077575e-07\n",
      "New limit is 1.3926575446624903e-07\n",
      "Old limit was 1.2830647341135436e-07\n",
      "New limit is 2.7234936977555177e-08\n",
      "Old limit was 7.604092480424186e-08\n",
      "New limit is 1.935262655698933e-08\n"
     ]
    }
   ],
   "source": [
    "# New_limits = []\n",
    "# for HNL_mass in list_test:\n",
    "#     New_limits.append(New_BR_limit(Old_limits[HNL_mass], HNL_mass))\n",
    "    \n",
    "# r = zip([20,50,100,150,180], New_limits)\n",
    "\n",
    "# with open(f'limit_files/New_BR_expected_mu.csv', \"w\") as s:\n",
    "#     w = csv.writer(s)\n",
    "#     for row in r:\n",
    "#         w.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6656fea3-8b53-45fc-8cc6-914f6b9f8575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New scaling is 0.028529248110697302\n",
      "New scaling is 0.07080375773727186\n",
      "New scaling is 0.14150146874688022\n",
      "New scaling is 0.21226471473687195\n",
      "New scaling is 0.2545027773769233\n",
      "New scaling is 0.28289193995533474\n"
     ]
    }
   ],
   "source": [
    "# for HNL_mass in Constants.HNL_mass_samples:\n",
    "#     new_scaling = np.sqrt(1/Constants.Old_gen_HNL_scalings[HNL_mass])\n",
    "#     print(\"New scaling is \" + str(new_scaling))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c44d35cf-1a71-42a7-ba8a-06a8fe0c30b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.050808497914834036, 0.05487945004360595, 0.06145440546673507, 0.06355764988787484, 0.07558287866005854, 0.08151675367339842, 0.09340516893421773, 0.1223239917030607, 0.16126455618691313, 0.3767107403439153, 0.039337891479048835, 0.03850081930059008, 0.04775438903415764, 0.052777319663197715, 0.057503899210725004, 0.06557695378140402, 0.0789857347150117, 0.09886097753972525, 0.14303558448522657, 0.36171050766471524]\n"
     ]
    }
   ],
   "source": [
    "print(Total_dict[20][\"SIGNAL_ERR_dict\"])\n",
    "\n",
    "#print(Total_dict[20][\"SIGNAL_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84d5fe72-6da3-4db9-af90-38ee337aec80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 20MeV signal is \n",
      "[1.2564858198165894, 0.4351254403591156, 0.44490355253219604, 0.4009020924568176, 0.474237859249115, 0.4546816349029541, 0.48890501260757446, 0.4009020924568176, 0.48401594161987305, 0.4693487882614136, 0.5280174016952515, 0.6160203218460083, 0.7724698781967163, 0.8262494206428528, 1.1684828996658325, 1.3591558933258057, 1.7845032215118408, 3.0605452060699463, 5.319286346435547, 29.026288986206055]\n",
      "Total 50MeV signal is \n",
      "[1.3828301429748535, 0.6708196997642517, 0.5531320571899414, 0.45309752225875854, 0.47075068950653076, 0.6237446665763855, 0.5237101316452026, 0.49428820610046387, 0.7414323091506958, 0.6590509414672852, 0.8591200113296509, 0.6237446665763855, 0.8885419368743896, 1.053304672241211, 1.3592926263809204, 1.7005867958068848, 2.3184471130371094, 3.6895084381103516, 6.060914993286133, 32.0228157043457]\n",
      "Total 100MeV signal is \n",
      "[0.25780484080314636, 0.11260440945625305, 0.1195187121629715, 0.11457992345094681, 0.12939628958702087, 0.12544526159763336, 0.10667786002159119, 0.11556768417358398, 0.13038405776023865, 0.13334733247756958, 0.16693109273910522, 0.18471074104309082, 0.20051486790180206, 0.20644141733646393, 0.2884253263473511, 0.3634949326515198, 0.47116056084632874, 0.6756264567375183, 1.1734564304351807, 3.965848207473755]\n",
      "Total 150MeV signal is \n",
      "[0.7105308175086975, 0.35084301233291626, 0.2977743148803711, 0.3184121549129486, 0.3744291067123413, 0.3714808523654938, 0.28598126769065857, 0.29482606053352356, 0.4127565026283264, 0.36853256821632385, 0.40685996413230896, 0.4569804072380066, 0.6456691026687622, 0.6515656113624573, 0.9345986247062683, 1.0967530012130737, 1.4741302728652954, 2.4205219745635986, 4.274978160858154, 13.567895889282227]\n",
      "Total 180MeV signal is \n",
      "[7.829308986663818, 4.132135391235352, 3.7593111991882324, 3.4486241340637207, 4.349616050720215, 3.8835859298706055, 4.287478923797607, 4.753509044647217, 4.629234313964844, 5.499157428741455, 7.052591800689697, 6.866179943084717, 9.072056770324707, 9.351675033569336, 12.986711502075195, 15.68968677520752, 19.014036178588867, 27.557924270629883, 44.64570236206055, 69.37638092041016]\n",
      "Total 200MeV signal is \n",
      "[0.4938566982746124, 0.27805376052856445, 0.29880404472351074, 0.29880404472351074, 0.32577940821647644, 0.32577940821647644, 0.3216293454170227, 0.4004804193973541, 0.45858120918273926, 0.41915568709373474, 0.5332822203636169, 0.5146069526672363, 0.6245834827423096, 0.7739855051040649, 0.8756618499755859, 1.076939582824707, 1.4504446983337402, 1.9671266078948975, 3.002565622329712, 3.695625066757202]\n",
      "\n",
      "Total bkg is \n",
      "[5178.9053   1110.9154    603.34033   366.86493   251.27592   204.7402\n",
      "  165.6885    133.132     101.55884    90.468346   84.81668    69.88953\n",
      "   60.47133    57.216183   51.164066   41.061756   36.759506   31.851618\n",
      "   24.122948    9.019966]\n",
      "\n",
      "Total bkg error is  \n",
      "[31.03173159 16.35098205 12.02819459  9.29807171  7.67518003  7.01779764\n",
      "  6.31080565  5.71978635  4.86349435  4.64304769  4.55996756  4.09128118\n",
      "  3.80061505  3.71157852  3.55899765  3.11977946  2.86001323  2.69805645\n",
      "  2.32750993  1.38787403]\n"
     ]
    }
   ],
   "source": [
    "TOTAL_SIGNAL_dict = {}\n",
    "TOTAL_SIGNAL_ERR_dict = {}\n",
    "TOTAL_BKG_dict = {}\n",
    "TOTAL_BKG_ERR_dict = {}\n",
    "TOTAL_DATA_dict = {}\n",
    "\n",
    "for HNL_mass in HNL_masses:\n",
    "    \n",
    "    r1_signal = hist_dict_run1[HNL_mass]['signal']\n",
    "    r1_EXT = hist_dict_run1[HNL_mass]['bkg_EXT']\n",
    "    r1_nu = hist_dict_run1[HNL_mass]['bkg_overlay']\n",
    "    r1_dirt = hist_dict_run1[HNL_mass]['bkg_dirt']\n",
    "    r1_data = hist_dict_run1[HNL_mass]['data']\n",
    "    \n",
    "    r3_signal = hist_dict_run3[HNL_mass]['signal']\n",
    "    r3_EXT = hist_dict_run3[HNL_mass]['bkg_EXT']\n",
    "    r3_nu = hist_dict_run3[HNL_mass]['bkg_overlay']\n",
    "    r3_dirt = hist_dict_run3[HNL_mass]['bkg_dirt']\n",
    "    r3_data = hist_dict_run3[HNL_mass]['data']\n",
    "    \n",
    "    r1_bkg_hists = [r1_EXT, r1_nu, r1_dirt]\n",
    "    r1_total_bkg = add_hists_vals(r1_bkg_hists)\n",
    "    \n",
    "    r3_bkg_hists = [r3_EXT, r3_nu, r3_dirt]\n",
    "    r3_total_bkg = add_hists_vals(r3_bkg_hists)\n",
    "    \n",
    "    if Params_pyhf[\"Stats_only\"] == True:\n",
    "        overlay_r1_err = get_stat_errors(r1_nu)\n",
    "        dirt_r1_err = get_stat_errors(r1_dirt)\n",
    "        \n",
    "        overlay_r3_err = get_stat_errors(r3_nu)\n",
    "        dirt_r3_err = get_stat_errors(r3_dirt)\n",
    "        \n",
    "        r1_sig_err = get_stat_errors(r1_signal)\n",
    "        r3_sig_err = get_stat_errors(r3_signal)\n",
    "        \n",
    "    elif Params_pyhf[\"Stats_only\"] == False:\n",
    "        overlay_r1_err = get_full_errors_nu_FLAT_INPUTS(r1_nu)\n",
    "        dirt_r1_err = get_full_errors_dirt(r1_dirt)\n",
    "      \n",
    "        overlay_r3_err = get_full_errors_nu_FLAT_INPUTS(r3_nu)\n",
    "        dirt_r3_err = get_full_errors_dirt(r3_dirt)\n",
    "        \n",
    "        r1_sig_err = get_full_errors_signal(r1_signal)\n",
    "        r3_sig_err = get_full_errors_signal(r3_signal)\n",
    "    \n",
    "    \n",
    "    r1_bkg_err_list = [overlay_r1_err, r1_EXT.errors(), dirt_r1_err]\n",
    "    r1_total_bkg_err = add_all_errors(r1_bkg_err_list)\n",
    "\n",
    "    r3_bkg_err_list = [overlay_r3_err, r3_EXT.errors(), dirt_r3_err]\n",
    "    r3_total_bkg_err = add_all_errors(r3_bkg_err_list)\n",
    "    \n",
    "    #Converting np.ndarrays to lists\n",
    "    SIGNAL_R1 = np.ndarray.tolist(r1_signal.values())\n",
    "    SIGNAL_ERR_R1 = np.ndarray.tolist(r1_sig_err)\n",
    "    BKG_R1 = np.ndarray.tolist(r1_total_bkg)\n",
    "    BKG_ERR_R1 = np.ndarray.tolist(r1_total_bkg_err)\n",
    "    DATA_R1 = np.ndarray.tolist(r1_data.values())\n",
    "    \n",
    "    SIGNAL_R3 = np.ndarray.tolist(r3_signal.values())\n",
    "    SIGNAL_ERR_R3 = np.ndarray.tolist(r3_sig_err)\n",
    "    BKG_R3 = np.ndarray.tolist(r3_total_bkg)\n",
    "    BKG_ERR_R3 = np.ndarray.tolist(r3_total_bkg_err)\n",
    "    DATA_R3 = np.ndarray.tolist(r3_data.values())\n",
    "    \n",
    "    list_of_lists = [SIGNAL_R1, SIGNAL_ERR_R1, BKG_R1, BKG_ERR_R1, DATA_R1, SIGNAL_R3, SIGNAL_ERR_R3, BKG_R3, BKG_ERR_R3, DATA_R3]\n",
    "    if Params_pyhf[\"Use_second_half_only\"] == True:\n",
    "        for n in range(len(list_of_lists)):\n",
    "            list_of_lists[n]=remove_first_half_hist(list_of_lists[n])\n",
    "    \n",
    "    TOTAL_SIGNAL_dict[HNL_mass] = append_r3_to_r1(list_of_lists[0], list_of_lists[5])\n",
    "    TOTAL_SIGNAL_ERR_dict[HNL_mass] = append_r3_to_r1(list_of_lists[1], list_of_lists[6])\n",
    "    TOTAL_BKG_dict[HNL_mass] = append_r3_to_r1(list_of_lists[2], list_of_lists[7])\n",
    "    TOTAL_BKG_ERR_dict[HNL_mass] = append_r3_to_r1(list_of_lists[3], list_of_lists[8])\n",
    "    TOTAL_DATA_dict[HNL_mass] = append_r3_to_r1(list_of_lists[4], list_of_lists[9])\n",
    "    \n",
    "    # print(f\"Total {HNL_mass}MeV signal is \")\n",
    "    # print(SIGNAL_R1)\n",
    "\n",
    "# print()\n",
    "# print(\"Total bkg is \")\n",
    "# print(r1_total_bkg)\n",
    "\n",
    "# print()\n",
    "# print(\"Total bkg error is  \")\n",
    "# print(r1_total_bkg_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4ce615d-8780-424f-9372-21a3c27a84e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "# for HNL_mass in HNL_masses:\n",
    "#     model_dict[HNL_mass] = pyhf.simplemodels.uncorrelated_background(signal=TOTAL_SIGNAL_dict[HNL_mass],\n",
    "#                                                                      bkg=TOTAL_BKG_dict[HNL_mass], \n",
    "#                                                                      bkg_uncertainty=TOTAL_BKG_ERR_dict[HNL_mass])\n",
    "    \n",
    "for HNL_mass in HNL_masses:\n",
    "    model_dict[HNL_mass] = pyhf.Model(\n",
    "        {\n",
    "  \"channels\": [\n",
    "    {\n",
    "      \"name\": \"singlechannel\",\n",
    "      \"samples\": [\n",
    "        {\n",
    "          \"name\": \"signal\",\n",
    "          \"data\": TOTAL_SIGNAL_dict[HNL_mass],\n",
    "          \"modifiers\": [\n",
    "            {\n",
    "              \"name\": \"mu\",\n",
    "              \"type\": \"normfactor\",\n",
    "              \"data\": None\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"uncorr_siguncrt\",\n",
    "              \"type\": \"shapesys\",\n",
    "              \"data\": TOTAL_SIGNAL_ERR_dict[HNL_mass]  \n",
    "            }\n",
    "          ]\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"background\",\n",
    "          \"data\": TOTAL_BKG_dict[HNL_mass],\n",
    "          \"modifiers\": [\n",
    "            {\n",
    "              \"name\": \"uncorr_bkguncrt\",\n",
    "              \"type\": \"shapesys\",\n",
    "              \"data\": TOTAL_BKG_ERR_dict[HNL_mass]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "614e2625-7dc1-486d-9d33-a3c051f0584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_full = pyhf.model.uncorrelated_background(signal=TOTAL_SIGNAL, signal_uncertainty=TOTAL_SIGNAL_ERR, bkg=TOTAL_BKG, bkg_uncertainty=TOTAL_BKG_ERR)\n",
    "# model_full\n",
    "# print(json.dumps(model.spec, indent=2))\n",
    "# model.config.param_set(\"uncorr_bkguncrt\").n_parameters\n",
    "#model.config.param_set(\"uncorr_siguncrt\").n_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0e3cf9e-299d-42f0-afca-e541978bb7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(json.dumps(model.spec, indent=2))\n",
    "DATA_OBS_dict = {}\n",
    "for HNL_mass in HNL_masses:\n",
    "    init_pars = model_dict[HNL_mass].config.suggested_init()\n",
    "    model_dict[HNL_mass].expected_actualdata(init_pars) #signal plus bkg\n",
    "\n",
    "    bkg_pars = init_pars.copy()\n",
    "    bkg_pars[model_dict[HNL_mass].config.poi_index] = 0\n",
    "    model_dict[HNL_mass].expected_actualdata(bkg_pars) #bkg only\n",
    "\n",
    "    DATA_OBS_dict[HNL_mass] = TOTAL_DATA_dict[HNL_mass]+model_dict[HNL_mass].config.auxdata\n",
    "\n",
    "    model_dict[HNL_mass].logpdf(pars=bkg_pars, data=DATA_OBS_dict[HNL_mass])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4a5f893-b271-4da1-bf61-f16bd3fb3e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20MeV\n",
      "Expected CLs(-2 σ): 0.0000\n",
      "Expected CLs(-1 σ): 0.0000\n",
      "Expected CLs( 0 σ): 0.0000\n",
      "Expected CLs( 1 σ): 0.0000\n",
      "Expected CLs( 2 σ): 0.0000\n",
      "50MeV\n",
      "Expected CLs(-2 σ): 0.0000\n",
      "Expected CLs(-1 σ): 0.0000\n",
      "Expected CLs( 0 σ): 0.0000\n",
      "Expected CLs( 1 σ): 0.0000\n",
      "Expected CLs( 2 σ): 0.0000\n",
      "100MeV\n",
      "Expected CLs(-2 σ): 0.0339\n",
      "Expected CLs(-1 σ): 0.0954\n",
      "Expected CLs( 0 σ): 0.2435\n",
      "Expected CLs( 1 σ): 0.5158\n",
      "Expected CLs( 2 σ): 0.8163\n",
      "150MeV\n",
      "Expected CLs(-2 σ): 0.0000\n",
      "Expected CLs(-1 σ): 0.0000\n",
      "Expected CLs( 0 σ): 0.0000\n",
      "Expected CLs( 1 σ): 0.0011\n",
      "Expected CLs( 2 σ): 0.0181\n",
      "180MeV\n",
      "Expected CLs(-2 σ): 0.0000\n",
      "Expected CLs(-1 σ): 0.0000\n",
      "Expected CLs( 0 σ): 0.0000\n",
      "Expected CLs( 1 σ): 0.0000\n",
      "Expected CLs( 2 σ): 0.0000\n",
      "200MeV\n",
      "Expected CLs(-2 σ): 0.0090\n",
      "Expected CLs(-1 σ): 0.0354\n",
      "Expected CLs( 0 σ): 0.1247\n",
      "Expected CLs( 1 σ): 0.3521\n",
      "Expected CLs( 2 σ): 0.6948\n"
     ]
    }
   ],
   "source": [
    "#pyhf.infer.mle.fit(data=DATA_OBS, pdf=model)\n",
    "for HNL_mass in HNL_masses:\n",
    "    CLs_obs, CLs_exp = pyhf.infer.hypotest(\n",
    "        1.0,  # null hypothesis\n",
    "        DATA_OBS_dict[HNL_mass],\n",
    "        model_dict[HNL_mass],\n",
    "        test_stat=\"qtilde\",\n",
    "        return_expected_set=True,\n",
    "        )\n",
    "    \n",
    "#print(f\"      Observed CLs: {CLs_obs:.4f}\")\n",
    "    print(f\"{HNL_mass}MeV\")\n",
    "    for expected_value, n_sigma in zip(CLs_exp, np.arange(-2, 3)):\n",
    "        print(f\"Expected CLs({n_sigma:2d} σ): {expected_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "433df84e-f04e-45cf-9a8f-84f7cf889b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If the output of the following is equal to the lowest or highest value of poi, the range needs to be extended\n",
      "Upper limit 20MeV (obs): μ = 0.1928\n",
      "Upper limit 20MeV (exp): μ = 0.1928\n",
      "\n",
      "Upper limit 50MeV (obs): μ = 0.1908\n",
      "Upper limit 50MeV (exp): μ = 0.1908\n",
      "\n",
      "Upper limit 100MeV (obs): μ = 1.4359\n",
      "Upper limit 100MeV (exp): μ = 1.4359\n",
      "\n",
      "Upper limit 150MeV (obs): μ = 0.3653\n",
      "Upper limit 150MeV (exp): μ = 0.3653\n",
      "\n",
      "Upper limit 180MeV (obs): μ = 0.0927\n",
      "Upper limit 180MeV (exp): μ = 0.0927\n",
      "\n",
      "Upper limit 200MeV (obs): μ = 1.0781\n",
      "Upper limit 200MeV (exp): μ = 1.0781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "obs_limit_dict = {}\n",
    "exp_limits_dict = {}\n",
    "print(\"If the output of the following is equal to the lowest or highest value of poi, the range needs to be extended\")\n",
    "\n",
    "for HNL_mass in HNL_masses:\n",
    "\n",
    "    poi_values = np.linspace(0.001, 10, 100)\n",
    "    obs_limit_dict[HNL_mass], exp_limits_dict[HNL_mass], (scan, results) = pyhf.infer.intervals.upperlimit(\n",
    "        DATA_OBS_dict[HNL_mass], model_dict[HNL_mass], poi_values, level=0.1, return_results=True\n",
    "    )\n",
    "    print(f\"Upper limit {HNL_mass}MeV (obs): μ = {obs_limit_dict[HNL_mass]:.4f}\")\n",
    "    print(f\"Upper limit {HNL_mass}MeV (exp): μ = {exp_limits_dict[HNL_mass][2]:.4f}\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69e5451d-aad4-4dfb-87e6-fd111ea3bef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{20: 0.02, 50: 0.005, 100: 0.001, 150: 0.0005, 180: 0.0005, 200: 0.0002}\n"
     ]
    }
   ],
   "source": [
    "with open('bdt_output/new_theta_dict.pkl', 'rb') as handle:\n",
    "    new_theta_dict = pickle.load(handle)\n",
    "print(new_theta_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99e89ee7-9741-419d-8dfa-faee7b318a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 20MeV limit is 0.00017565276611044875\n",
      "Observed 20MeV limit is 0.00017565277276562592\n",
      "\n",
      "Expected 50MeV limit is 1.0920525261344537e-05\n",
      "Observed 50MeV limit is 1.092052522652675e-05\n",
      "\n",
      "Expected 100MeV limit is 1.1983074147731274e-06\n",
      "Observed 100MeV limit is 1.1983073726571225e-06\n",
      "\n",
      "Expected 150MeV limit is 1.510942780087027e-07\n",
      "Observed 150MeV limit is 1.5109429153975143e-07\n",
      "\n",
      "Expected 180MeV limit is 7.609925062363602e-08\n",
      "Observed 180MeV limit is 7.609923365786958e-08\n",
      "\n",
      "Expected 200MeV limit is 4.153181878369165e-08\n",
      "Observed 200MeV limit is 4.153181909099249e-08\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Mass point\n",
    "with open('bdt_output/new_theta_dict.pkl', 'rb') as handle:\n",
    "    new_theta_dict = pickle.load(handle)\n",
    "#print(new_theta_dict)\n",
    "scaled_thetas = new_theta_dict #Saved in 3.5_BDT_Result\n",
    "\n",
    "exp_limit = []\n",
    "obs_limit = []\n",
    "\n",
    "for HNL_mass in HNL_masses:\n",
    "    theta_squared = (scaled_thetas[HNL_mass])**2\n",
    "\n",
    "    EXP_LIMIT = np.sqrt(exp_limits_dict[HNL_mass][2])*theta_squared\n",
    "    LIMIT = np.sqrt(obs_limit_dict[HNL_mass])*theta_squared\n",
    "    print(f\"Expected {HNL_mass}MeV limit is \" + str(EXP_LIMIT))\n",
    "    print(f\"Observed {HNL_mass}MeV limit is \" + str(LIMIT)+ \"\\n\")\n",
    "    \n",
    "    exp_limit.append(EXP_LIMIT)\n",
    "# print()\n",
    "# print(\"Owen's expected limit is \" + str(Owen_exp_limit))\n",
    "# print(\"Owen's observed limit is \" + str(Owen_obs_limit))\n",
    "\n",
    "# print()\n",
    "# perc_diff_exp = (1-(EXP_LIMIT/Owen_exp_limit))*100\n",
    "# perc_diff_obs = (1-(LIMIT/Owen_obs_limit))*100\n",
    "\n",
    "# print(\"pyhf expected limit is \" + str(perc_diff_exp) + \" different from Owen's limit.\")\n",
    "# print(\"pyhf observed limit is \" + str(perc_diff_obs) + \" different from Owen's limit.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69557119-e9c6-430c-a6b5-b6ddaea4613f",
   "metadata": {},
   "source": [
    "## Saving Limits as .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3197c589-b82b-4105-be66-ec902f4ffafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 50, 100, 150, 180, 200]\n",
      "[0.00017565276611044875, 1.0920525261344537e-05, 1.1983074147731274e-06, 1.510942780087027e-07, 7.609925062363602e-08, 4.153181878369165e-08]\n"
     ]
    }
   ],
   "source": [
    "masses = HNL_masses\n",
    "\n",
    "if Params_pyhf[\"Stats_only\"] == True:\n",
    "    stats =  \"Stats_only\"\n",
    "else:\n",
    "    stats = \"Owen_sys\"\n",
    "    \n",
    "if Params_pyhf[\"Use_second_half_only\"] == True:\n",
    "    half_hist = \"havled\"\n",
    "else:\n",
    "    half_hist = \"full_hist\"\n",
    "\n",
    "print(masses)\n",
    "print(exp_limit)\n",
    "\n",
    "r = zip(masses, exp_limit)\n",
    "\n",
    "with open(f'limit_files/{stats}_{half_hist}_expected_mu_COMBINED_highest_E.csv', \"w\") as s:\n",
    "    w = csv.writer(s)\n",
    "    for row in r:\n",
    "        w.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1405e88b-4862-4f4f-9aae-df0dc1924ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66cc7172-6236-477f-9d5c-1a50e81519ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"channels\": [\n",
      "    {\n",
      "      \"name\": \"singlechannel\",\n",
      "      \"samples\": [\n",
      "        {\n",
      "          \"name\": \"signal\",\n",
      "          \"data\": [\n",
      "            0.2123590111732483,\n",
      "            0.11062422394752502,\n",
      "            0.11753824353218079,\n",
      "            0.0948207676410675,\n",
      "            0.08494359999895096,\n",
      "            0.09975934773683548,\n",
      "            0.10074706375598907,\n",
      "            0.09778391569852829,\n",
      "            0.09778391569852829,\n",
      "            0.12050139158964157,\n",
      "            0.1333416998386383,\n",
      "            0.16099776327610016,\n",
      "            0.20445728302001953,\n",
      "            0.21927301585674286,\n",
      "            0.2508799433708191,\n",
      "            0.3121183514595032,\n",
      "            0.43360745906829834,\n",
      "            0.6222612857818604,\n",
      "            1.114143967628479,\n",
      "            4.416079521179199,\n",
      "            0.11143967509269714,\n",
      "            0.0829869881272316,\n",
      "            0.07113170623779297,\n",
      "            0.06243783235549927,\n",
      "            0.05137290060520172,\n",
      "            0.05611501261591911,\n",
      "            0.07192205637693405,\n",
      "            0.07350276410579681,\n",
      "            0.06797029823064804,\n",
      "            0.08377734571695328,\n",
      "            0.09326156973838806,\n",
      "            0.10985896736383438,\n",
      "            0.11460108309984207,\n",
      "            0.1477958858013153,\n",
      "            0.18178102374076843,\n",
      "            0.25449344515800476,\n",
      "            0.35486817359924316,\n",
      "            0.5406009554862976,\n",
      "            1.1349458694458008,\n",
      "            5.407590389251709\n",
      "          ],\n",
      "          \"modifiers\": [\n",
      "            {\n",
      "              \"name\": \"mu\",\n",
      "              \"type\": \"normfactor\",\n",
      "              \"data\": null\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"background\",\n",
      "          \"data\": [\n",
      "            4813.0419921875,\n",
      "            1084.7637939453125,\n",
      "            583.9191284179688,\n",
      "            408.3866882324219,\n",
      "            292.4494323730469,\n",
      "            216.58653259277344,\n",
      "            163.92173767089844,\n",
      "            168.064697265625,\n",
      "            130.50506591796875,\n",
      "            105.41650390625,\n",
      "            92.03352355957031,\n",
      "            73.40505981445312,\n",
      "            83.59547424316406,\n",
      "            78.19515228271484,\n",
      "            63.587196350097656,\n",
      "            54.04482650756836,\n",
      "            63.537628173828125,\n",
      "            56.97993087768555,\n",
      "            41.053070068359375,\n",
      "            26.990182876586914,\n",
      "            6222.9423828125,\n",
      "            1328.26611328125,\n",
      "            760.9569091796875,\n",
      "            562.6710205078125,\n",
      "            447.1845703125,\n",
      "            346.5769348144531,\n",
      "            290.2818603515625,\n",
      "            244.77734375,\n",
      "            225.49014282226562,\n",
      "            196.5823974609375,\n",
      "            175.8265380859375,\n",
      "            153.3267059326172,\n",
      "            154.1259307861328,\n",
      "            142.684326171875,\n",
      "            133.48500061035156,\n",
      "            118.56350708007812,\n",
      "            115.80341339111328,\n",
      "            122.71444702148438,\n",
      "            113.43251037597656,\n",
      "            62.4538459777832\n",
      "          ],\n",
      "          \"modifiers\": [\n",
      "            {\n",
      "              \"name\": \"uncorr_bkguncrt\",\n",
      "              \"type\": \"shapesys\",\n",
      "              \"data\": [\n",
      "                1481.253173828125,\n",
      "                162.64280700683594,\n",
      "                83.81015014648438,\n",
      "                59.9840202331543,\n",
      "                46.59243392944336,\n",
      "                35.241127014160156,\n",
      "                27.77196502685547,\n",
      "                24.55970001220703,\n",
      "                18.695737838745117,\n",
      "                17.6707706451416,\n",
      "                15.45075798034668,\n",
      "                12.776668548583984,\n",
      "                13.477092742919922,\n",
      "                11.36016845703125,\n",
      "                8.785843849182129,\n",
      "                8.902772903442383,\n",
      "                8.560722351074219,\n",
      "                8.49879264831543,\n",
      "                6.323156833648682,\n",
      "                5.41060733795166,\n",
      "                2432.649169921875,\n",
      "                299.70184326171875,\n",
      "                156.1425018310547,\n",
      "                106.06019592285156,\n",
      "                83.75310516357422,\n",
      "                62.723365783691406,\n",
      "                54.59048843383789,\n",
      "                45.86286544799805,\n",
      "                41.29096984863281,\n",
      "                32.37138748168945,\n",
      "                31.506181716918945,\n",
      "                26.538427352905273,\n",
      "                27.113197326660156,\n",
      "                26.818252563476562,\n",
      "                24.2493839263916,\n",
      "                20.97845458984375,\n",
      "                23.549537658691406,\n",
      "                24.74275016784668,\n",
      "                25.598798751831055,\n",
      "                12.846282958984375\n",
      "              ]\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "HNL_mass = 100\n",
    "print(json.dumps(model_dict[HNL_mass].spec, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01974e7f-3d17-4287-ba74-5328c603a38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict_full_sys = {}\n",
    "\n",
    "for HNL_mass in HNL_masses:\n",
    "    model_dict_full_sys[HNL_mass] = pyhf.Model(\n",
    "        {\n",
    "  \"channels\": [\n",
    "    {\n",
    "      \"name\": \"singlechannel\",\n",
    "      \"samples\": [\n",
    "        {\n",
    "          \"name\": \"signal\",\n",
    "          \"data\": TOTAL_SIGNAL_dict[HNL_mass],\n",
    "          \"modifiers\": [\n",
    "            {\n",
    "              \"name\": \"mu\",\n",
    "              \"type\": \"normfactor\",\n",
    "              \"data\": None\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"uncorr_siguncrt\",\n",
    "              \"type\": \"shapesys\",\n",
    "              \"data\": TOTAL_SIGNAL_ERR_dict[HNL_mass]  \n",
    "            }\n",
    "          ]\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"background\",\n",
    "          \"data\": TOTAL_BKG_dict[HNL_mass],\n",
    "          \"modifiers\": [\n",
    "            {\n",
    "              \"name\": \"uncorr_bkguncrt\",\n",
    "              \"type\": \"shapesys\",\n",
    "              \"data\": TOTAL_BKG_ERR_dict[HNL_mass]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9416cdf2-0f11-4ae6-ac1b-9260325f2396",
   "metadata": {},
   "source": [
    "# Adding in signal systematic uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "244d3408-b6f7-4cc9-bad2-86f8bb48220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Messing around with model\n",
    "\n",
    "full_model = pyhf.Model(\n",
    "    {\n",
    "  \"channels\": [\n",
    "    {\n",
    "      \"name\": \"singlechannel\",\n",
    "      \"samples\": [\n",
    "        {\n",
    "          \"name\": \"signal\",\n",
    "          \"data\": [\n",
    "            0.4354482889175415,\n",
    "            0.6531724333763123,\n",
    "            0.9367626905441284,\n",
    "            1.1947383880615234,\n",
    "            1.3539148569107056,\n",
    "            1.192908763885498,\n",
    "            0.6879351139068604,\n",
    "            0.2671237289905548,\n",
    "            0.8156560063362122,\n",
    "            1.649437665939331,\n",
    "            2.6418192386627197,\n",
    "            3.511852264404297,\n",
    "            3.4166924953460693,\n",
    "            2.6418192386627197,\n",
    "            1.114729881286621,\n",
    "            0.842844545841217\n",
    "          ],\n",
    "          \"modifiers\": [\n",
    "            {\n",
    "              \"name\": \"mu\",\n",
    "              \"type\": \"normfactor\",\n",
    "              \"data\": None\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"uncorr_siguncrt\",\n",
    "              \"type\": \"shapesys\",\n",
    "              \"data\": TOTAL_SIGNAL_ERR  \n",
    "            }\n",
    "          ]\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"background\",\n",
    "          \"data\": [\n",
    "            227.98190307617188,\n",
    "            185.65267944335938,\n",
    "            141.53671264648438,\n",
    "            83.10063171386719,\n",
    "            39.49835968017578,\n",
    "            20.065095901489258,\n",
    "            5.26054573059082,\n",
    "            0.7651026844978333,\n",
    "            385.53765869140625,\n",
    "            330.3393249511719,\n",
    "            241.39376831054688,\n",
    "            143.0430908203125,\n",
    "            55.337371826171875,\n",
    "            20.656126022338867,\n",
    "            7.634726524353027,\n",
    "            3.049088954925537\n",
    "          ],\n",
    "          \"modifiers\": [\n",
    "            {\n",
    "              \"name\": \"uncorr_bkguncrt\",\n",
    "              \"type\": \"shapesys\",\n",
    "              \"data\": [\n",
    "                34.158817291259766,\n",
    "                27.066844940185547,\n",
    "                22.60236358642578,\n",
    "                14.79345417022705,\n",
    "                6.955612659454346,\n",
    "                4.61644983291626,\n",
    "                1.6257153749465942,\n",
    "                0.48608535528182983,\n",
    "                73.31805419921875,\n",
    "                65.45207214355469,\n",
    "                51.50766372680664,\n",
    "                34.320030212402344,\n",
    "                10.886519432067871,\n",
    "                5.264797210693359,\n",
    "                2.1698012351989746,\n",
    "                1.1060731410980225\n",
    "              ]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6192c9b-f9ee-4407-be07-9f98aa29e8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-111.00315017])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(json.dumps(full_model.spec, indent=2))\n",
    "init_pars = full_model.config.suggested_init()\n",
    "full_model.expected_actualdata(init_pars) #signal plus bkg\n",
    "\n",
    "bkg_pars = init_pars.copy()\n",
    "bkg_pars[model.config.poi_index] = 0\n",
    "full_model.expected_actualdata(bkg_pars) #bkg only\n",
    "\n",
    "DATA_OBS = TOTAL_DATA+full_model.config.auxdata\n",
    "\n",
    "full_model.logpdf(pars=bkg_pars, data=DATA_OBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe01a2b1-3aa2-4348-9804-04c1f5937e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Observed CLs: 0.3368\n",
      "Expected CLs(-2 σ): 0.1098\n",
      "Expected CLs(-1 σ): 0.2229\n",
      "Expected CLs( 0 σ): 0.4195\n",
      "Expected CLs( 1 σ): 0.6851\n",
      "Expected CLs( 2 σ): 0.9041\n"
     ]
    }
   ],
   "source": [
    "CLs_obs, CLs_exp = pyhf.infer.hypotest(\n",
    "    1.0,  # null hypothesis\n",
    "    DATA_OBS,\n",
    "    full_model,\n",
    "    test_stat=\"qtilde\",\n",
    "    return_expected_set=True,\n",
    ")\n",
    "print(f\"      Observed CLs: {CLs_obs:.4f}\")\n",
    "for expected_value, n_sigma in zip(CLs_exp, np.arange(-2, 3)):\n",
    "    print(f\"Expected CLs({n_sigma:2d} σ): {expected_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6eddbe7e-3de0-4d2a-8729-49308c8ec4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper limit (obs): μ = 1.9852\n",
      "Upper limit (exp): μ = 2.2352\n"
     ]
    }
   ],
   "source": [
    "poi_values = np.linspace(0.1, 10, 50)\n",
    "obs_limit, exp_limits, (scan, results) = pyhf.infer.intervals.upperlimit(\n",
    "    DATA_OBS, full_model, poi_values, level=0.1, return_results=True\n",
    ")\n",
    "print(f\"Upper limit (obs): μ = {obs_limit:.4f}\")\n",
    "print(f\"Upper limit (exp): μ = {exp_limits[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7eb56c7e-87ee-4eb0-8390-0ef5904cddae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected limit is 1.495059542214373e-08\n",
      "Observed limit is 1.40898768497879e-08\n",
      "\n",
      "Owen's expected limit is 1.52039448e-08\n",
      "Owen's observed limit is 1.46164475e-08\n",
      "\n",
      "pyhf expected limit is 1.6663397637188937 different from Owen's limit.\n",
      "pyhf observed limit is 3.6025898236360154 different from Owen's limit.\n"
     ]
    }
   ],
   "source": [
    "#Mass point\n",
    "EXP_LIMIT = np.sqrt(exp_limits[2])*theta_squared\n",
    "LIMIT = np.sqrt(obs_limit)*theta_squared\n",
    "print(\"Expected limit is \" + str(EXP_LIMIT))\n",
    "print(\"Observed limit is \" + str(LIMIT))\n",
    "print()\n",
    "print(\"Owen's expected limit is \" + str(Owen_exp_limit))\n",
    "print(\"Owen's observed limit is \" + str(Owen_obs_limit))\n",
    "\n",
    "print()\n",
    "perc_diff_exp = (1-(EXP_LIMIT/Owen_exp_limit))*100\n",
    "perc_diff_obs = (1-(LIMIT/Owen_obs_limit))*100\n",
    "\n",
    "# perc_diff_exp = (1-(Owen_exp_limit/EXP_LIMIT))*100\n",
    "# perc_diff_obs = (1-(Owen_obs_limit/LIMIT))*100\n",
    "\n",
    "print(\"pyhf expected limit is \" + str(perc_diff_exp) + \"% different from Owen's limit.\")\n",
    "print(\"pyhf observed limit is \" + str(perc_diff_obs) + \"% different from Owen's limit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9608e383-7ca2-43da-99f1-4b5660318ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
