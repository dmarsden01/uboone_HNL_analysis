{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffe0cab0-578b-42ea-86af-07342852e08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful!\n"
     ]
    }
   ],
   "source": [
    "#Loading libraries\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyhf\n",
    "from pyhf.contrib.viz import brazil\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import uproot3\n",
    "import uproot\n",
    "import math\n",
    "import awkward as ak\n",
    "\n",
    "import csv\n",
    "\n",
    "import Utilities.Constants as Constants\n",
    "\n",
    "print(\"Successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edb78650-72a3-4fa1-ad92-465a31cba48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "#Loading My BDT histograms\n",
    "HNL_masses = Constants.HNL_mass_samples #in MeV\n",
    "\n",
    "loc_hists = 'bdt_output/'\n",
    "\n",
    "hist_dict_run1 = {}\n",
    "hist_dict_run3 = {}\n",
    "\n",
    "#Loading in the .root files\n",
    "for HNL_mass in HNL_masses:\n",
    "\n",
    "    hist_dict_run1[HNL_mass] = uproot.open(loc_hists+f'run1_{HNL_mass}MeV_test2.root')\n",
    "    hist_dict_run3[HNL_mass] = uproot.open(loc_hists+f'run3_{HNL_mass}MeV_test2.root')\n",
    "\n",
    "#Constants\n",
    "theta_squared = Constants.theta_mu_4*Constants.theta_mu_4\n",
    "\n",
    "stats_only = True\n",
    "\n",
    "use_second_half_score = True\n",
    "\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24b05319-1dec-483e-af65-314358534d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for adding histograms and errors together\n",
    "\n",
    "def add_hists_vals(hist_list):\n",
    "    Total_hist = np.zeros_like(hist_list[0].values())\n",
    "    for hist in hist_list:\n",
    "        Total_hist += hist.values()\n",
    "    return Total_hist\n",
    "\n",
    "def add_all_errors(err_list): #adds in quadrature\n",
    "    Total_hist = np.zeros_like(err_list[0])\n",
    "    for i in range(len(err_list[0])): #Looping over the bins\n",
    "        for errs in err_list: #Looping over the histograms\n",
    "            Total_hist[i] += errs[i]**2 #Adding error from each hist in quadrature\n",
    "        Total_hist[i] = np.sqrt(Total_hist[i])\n",
    "    return Total_hist\n",
    "\n",
    "def append_r3_to_r1(r1_list, r3_list): #Must be in a list form already\n",
    "    TOTAL = r1_list + r3_list\n",
    "    return TOTAL\n",
    "\n",
    "def get_full_errors_nu(hist, ppfx, gen):\n",
    "    Total_err = np.zeros_like(hist.values())\n",
    "    stat_err = hist.errors()\n",
    "    det_sys_err = 0.3*hist.values()  #30% flat det sys err\n",
    "    #det_sys_err = 0.7*hist.values()  #30% flat det sys err\n",
    "    ppfx_err = []\n",
    "    for i in range(len(ppfx.values())):\n",
    "        ppfx_err.append(hist.values()[i]*ppfx.values()[i])\n",
    "    gen_err = []\n",
    "    for j in range(len(gen.values())):\n",
    "        gen_err.append(hist.values()[j]*gen.values()[j])\n",
    "    for k in range(len(Total_err)):\n",
    "        Total_err[k] = np.sqrt(stat_err[k]**2 + det_sys_err[k]**2 + ppfx_err[k]**2 + gen_err[k]**2)\n",
    "    return Total_err\n",
    "\n",
    "def get_full_errors_nu_FLAT_INPUTS(hist):\n",
    "    Total_err = np.zeros_like(hist.values())\n",
    "    stat_err = hist.errors()\n",
    "    det_sys_err = 0.3*hist.values()  #30% flat det sys err\n",
    "    ppfx_err = 0.3*hist.values() #Took flat 30% ppfx\n",
    "    gen_err = 0.2*hist.values() #Took flat 20% ppfx\n",
    "    #det_sys_err = 0.7*hist.values()  #30% flat det sys err\n",
    "    for k in range(len(Total_err)):\n",
    "        Total_err[k] = np.sqrt(stat_err[k]**2 + det_sys_err[k]**2 + ppfx_err[k]**2 + gen_err[k]**2)\n",
    "    return Total_err\n",
    "\n",
    "def get_full_errors_signal(hist):\n",
    "    Total_err = np.zeros_like(hist.values())\n",
    "    stat_err = hist.errors()\n",
    "    det_sys_err = 0.15*hist.values() #15% flat det sys err\n",
    "    flux_err = 0.3*hist.values() #30% flat flux err\n",
    "    #flux_err = 0.7*hist.values() #30% flat flux err\n",
    "    for k in range(len(Total_err)):\n",
    "        Total_err[k] = np.sqrt(stat_err[k]**2 + det_sys_err[k]**2 + flux_err[k]**2)\n",
    "    return Total_err\n",
    "\n",
    "def get_full_errors_dirt(hist):\n",
    "    Total_err = np.zeros_like(hist.values())\n",
    "    stat_err = hist.errors()\n",
    "    dirt_unconstrained_err = 1.0*hist.values() #100% unconstrained err\n",
    "    for k in range(len(Total_err)):\n",
    "        Total_err[k] = np.sqrt(stat_err[k]**2 + dirt_unconstrained_err[k]**2)\n",
    "    return Total_err\n",
    "\n",
    "def get_stat_errors(hist): #This works because the .root files saved only have stat errors on them\n",
    "    Total_err = np.zeros_like(hist.values())\n",
    "    stat_err = hist.errors()\n",
    "    return stat_err\n",
    "\n",
    "def remove_first_half_hist(hist_list):\n",
    "    length = len(hist_list)\n",
    "    slice_at = int(np.floor(length/2))\n",
    "    sliced_hist = hist_list[slice_at:]\n",
    "    return sliced_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84d5fe72-6da3-4db9-af90-38ee337aec80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 20MeV signal is \n",
      "[1.2564858198165894, 0.4351254403591156, 0.44490355253219604, 0.4009020924568176, 0.474237859249115, 0.4546816349029541, 0.48890501260757446, 0.4009020924568176, 0.48401594161987305, 0.4693487882614136, 0.5280174016952515, 0.6160203218460083, 0.7724698781967163, 0.8262494206428528, 1.1684828996658325, 1.3591558933258057, 1.7845032215118408, 3.0605452060699463, 5.319286346435547, 29.026288986206055]\n",
      "Total 50MeV signal is \n",
      "[1.3828301429748535, 0.6708196997642517, 0.5531320571899414, 0.45309752225875854, 0.47075068950653076, 0.6237446665763855, 0.5237101316452026, 0.49428820610046387, 0.7414323091506958, 0.6590509414672852, 0.8591200113296509, 0.6237446665763855, 0.8885419368743896, 1.053304672241211, 1.3592926263809204, 1.7005867958068848, 2.3184471130371094, 3.6895084381103516, 6.060914993286133, 32.0228157043457]\n",
      "Total 100MeV signal is \n",
      "[0.25780484080314636, 0.11260440945625305, 0.1195187121629715, 0.11457992345094681, 0.12939628958702087, 0.12544526159763336, 0.10667786002159119, 0.11556768417358398, 0.13038405776023865, 0.13334733247756958, 0.16693109273910522, 0.18471074104309082, 0.20051486790180206, 0.20644141733646393, 0.2884253263473511, 0.3634949326515198, 0.47116056084632874, 0.6756264567375183, 1.1734564304351807, 3.965848207473755]\n",
      "Total 150MeV signal is \n",
      "[0.7105308175086975, 0.35084301233291626, 0.2977743148803711, 0.3184121549129486, 0.3744291067123413, 0.3714808523654938, 0.28598126769065857, 0.29482606053352356, 0.4127565026283264, 0.36853256821632385, 0.40685996413230896, 0.4569804072380066, 0.6456691026687622, 0.6515656113624573, 0.9345986247062683, 1.0967530012130737, 1.4741302728652954, 2.4205219745635986, 4.274978160858154, 13.567895889282227]\n",
      "Total 180MeV signal is \n",
      "[7.829308986663818, 4.132135391235352, 3.7593111991882324, 3.4486241340637207, 4.349616050720215, 3.8835859298706055, 4.287478923797607, 4.753509044647217, 4.629234313964844, 5.499157428741455, 7.052591800689697, 6.866179943084717, 9.072056770324707, 9.351675033569336, 12.986711502075195, 15.68968677520752, 19.014036178588867, 27.557924270629883, 44.64570236206055, 69.37638092041016]\n",
      "Total 200MeV signal is \n",
      "[0.4938566982746124, 0.27805376052856445, 0.29880404472351074, 0.29880404472351074, 0.32577940821647644, 0.32577940821647644, 0.3216293454170227, 0.4004804193973541, 0.45858120918273926, 0.41915568709373474, 0.5332822203636169, 0.5146069526672363, 0.6245834827423096, 0.7739855051040649, 0.8756618499755859, 1.076939582824707, 1.4504446983337402, 1.9671266078948975, 3.002565622329712, 3.695625066757202]\n",
      "\n",
      "Total bkg is \n",
      "[5178.9053   1110.9154    603.34033   366.86493   251.27592   204.7402\n",
      "  165.6885    133.132     101.55884    90.468346   84.81668    69.88953\n",
      "   60.47133    57.216183   51.164066   41.061756   36.759506   31.851618\n",
      "   24.122948    9.019966]\n",
      "\n",
      "Total bkg error is  \n",
      "[31.03173159 16.35098205 12.02819459  9.29807171  7.67518003  7.01779764\n",
      "  6.31080565  5.71978635  4.86349435  4.64304769  4.55996756  4.09128118\n",
      "  3.80061505  3.71157852  3.55899765  3.11977946  2.86001323  2.69805645\n",
      "  2.32750993  1.38787403]\n"
     ]
    }
   ],
   "source": [
    "TOTAL_SIGNAL_dict = {}\n",
    "TOTAL_SIGNAL_ERR_dict = {}\n",
    "TOTAL_BKG_dict = {}\n",
    "TOTAL_BKG_ERR_dict = {}\n",
    "TOTAL_DATA_dict = {}\n",
    "\n",
    "for HNL_mass in HNL_masses:\n",
    "    \n",
    "    r1_signal = hist_dict_run1[HNL_mass]['Signal']\n",
    "    r1_EXT = hist_dict_run1[HNL_mass]['bkg_EXT']\n",
    "    r1_nu = hist_dict_run1[HNL_mass]['bkg_overlay']\n",
    "    r1_dirt = hist_dict_run1[HNL_mass]['bkg_dirt']\n",
    "    r1_data = hist_dict_run1[HNL_mass]['Data']\n",
    "    \n",
    "    r3_signal = hist_dict_run3[HNL_mass]['Signal']\n",
    "    r3_EXT = hist_dict_run3[HNL_mass]['bkg_EXT']\n",
    "    r3_nu = hist_dict_run3[HNL_mass]['bkg_overlay']\n",
    "    r3_dirt = hist_dict_run3[HNL_mass]['bkg_dirt']\n",
    "    r3_data = hist_dict_run3[HNL_mass]['Data']\n",
    "    \n",
    "    r1_bkg_hists = [r1_EXT, r1_nu, r1_dirt]\n",
    "    r1_total_bkg = add_hists_vals(r1_bkg_hists)\n",
    "    \n",
    "    r3_bkg_hists = [r3_EXT, r3_nu, r3_dirt]\n",
    "    r3_total_bkg = add_hists_vals(r3_bkg_hists)\n",
    "    \n",
    "    if stats_only == True:\n",
    "        overlay_r1_err = get_stat_errors(r1_nu)\n",
    "        dirt_r1_err = get_stat_errors(r1_dirt)\n",
    "        \n",
    "        overlay_r3_err = get_stat_errors(r3_nu)\n",
    "        dirt_r3_err = get_stat_errors(r3_dirt)\n",
    "        \n",
    "        r1_sig_err = get_stat_errors(r1_signal)\n",
    "        r3_sig_err = get_stat_errors(r3_signal)\n",
    "        \n",
    "    elif stats_only == False:\n",
    "        overlay_r1_err = get_full_errors_nu_FLAT_INPUTS(r1_nu)\n",
    "        dirt_r1_err = get_full_errors_dirt(r1_dirt)\n",
    "      \n",
    "        overlay_r3_err = get_full_errors_nu_FLAT_INPUTS(r3_nu)\n",
    "        dirt_r3_err = get_full_errors_dirt(r3_dirt)\n",
    "        \n",
    "        r1_sig_err = get_full_errors_signal(r1_signal)\n",
    "        r3_sig_err = get_full_errors_signal(r3_signal)\n",
    "    \n",
    "    \n",
    "    r1_bkg_err_list = [overlay_r1_err, r1_EXT.errors(), dirt_r1_err]\n",
    "    r1_total_bkg_err = add_all_errors(r1_bkg_err_list)\n",
    "\n",
    "    r3_bkg_err_list = [overlay_r3_err, r3_EXT.errors(), dirt_r3_err]\n",
    "    r3_total_bkg_err = add_all_errors(r3_bkg_err_list)\n",
    "    \n",
    "    #Converting np.ndarrays to lists\n",
    "    SIGNAL_R1 = np.ndarray.tolist(r1_signal.values())\n",
    "    SIGNAL_ERR_R1 = np.ndarray.tolist(r1_sig_err)\n",
    "    BKG_R1 = np.ndarray.tolist(r1_total_bkg)\n",
    "    BKG_ERR_R1 = np.ndarray.tolist(r1_total_bkg_err)\n",
    "    DATA_R1 = np.ndarray.tolist(r1_data.values())\n",
    "    \n",
    "    SIGNAL_R3 = np.ndarray.tolist(r3_signal.values())\n",
    "    SIGNAL_ERR_R3 = np.ndarray.tolist(r3_sig_err)\n",
    "    BKG_R3 = np.ndarray.tolist(r3_total_bkg)\n",
    "    BKG_ERR_R3 = np.ndarray.tolist(r3_total_bkg_err)\n",
    "    DATA_R3 = np.ndarray.tolist(r3_data.values())\n",
    "    \n",
    "    list_of_lists = [SIGNAL_R1, SIGNAL_ERR_R1, BKG_R1, BKG_ERR_R1, DATA_R1, SIGNAL_R3, SIGNAL_ERR_R3, BKG_R3, BKG_ERR_R3, DATA_R3]\n",
    "    if use_second_half_score == True:\n",
    "        for n in range(len(list_of_lists)):\n",
    "            list_of_lists[n]=remove_first_half_hist(list_of_lists[n])\n",
    "    \n",
    "    TOTAL_SIGNAL_dict[HNL_mass] = append_r3_to_r1(list_of_lists[0], list_of_lists[5])\n",
    "    TOTAL_SIGNAL_ERR_dict[HNL_mass] = append_r3_to_r1(list_of_lists[1], list_of_lists[6])\n",
    "    TOTAL_BKG_dict[HNL_mass] = append_r3_to_r1(list_of_lists[2], list_of_lists[7])\n",
    "    TOTAL_BKG_ERR_dict[HNL_mass] = append_r3_to_r1(list_of_lists[3], list_of_lists[8])\n",
    "    TOTAL_DATA_dict[HNL_mass] = append_r3_to_r1(list_of_lists[4], list_of_lists[9])\n",
    "    \n",
    "    # print(f\"Total {HNL_mass}MeV signal is \")\n",
    "    # print(SIGNAL_R1)\n",
    "\n",
    "# print()\n",
    "# print(\"Total bkg is \")\n",
    "# print(r1_total_bkg)\n",
    "\n",
    "# print()\n",
    "# print(\"Total bkg error is  \")\n",
    "# print(r1_total_bkg_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4ce615d-8780-424f-9372-21a3c27a84e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "# for HNL_mass in HNL_masses:\n",
    "#     model_dict[HNL_mass] = pyhf.simplemodels.uncorrelated_background(signal=TOTAL_SIGNAL_dict[HNL_mass],\n",
    "#                                                                      bkg=TOTAL_BKG_dict[HNL_mass], \n",
    "#                                                                      bkg_uncertainty=TOTAL_BKG_ERR_dict[HNL_mass])\n",
    "    \n",
    "for HNL_mass in HNL_masses:\n",
    "    model_dict[HNL_mass] = pyhf.Model(\n",
    "        {\n",
    "  \"channels\": [\n",
    "    {\n",
    "      \"name\": \"singlechannel\",\n",
    "      \"samples\": [\n",
    "        {\n",
    "          \"name\": \"signal\",\n",
    "          \"data\": TOTAL_SIGNAL_dict[HNL_mass],\n",
    "          \"modifiers\": [\n",
    "            {\n",
    "              \"name\": \"mu\",\n",
    "              \"type\": \"normfactor\",\n",
    "              \"data\": None\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"uncorr_siguncrt\",\n",
    "              \"type\": \"shapesys\",\n",
    "              \"data\": TOTAL_SIGNAL_ERR_dict[HNL_mass]  \n",
    "            }\n",
    "          ]\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"background\",\n",
    "          \"data\": TOTAL_BKG_dict[HNL_mass],\n",
    "          \"modifiers\": [\n",
    "            {\n",
    "              \"name\": \"uncorr_bkguncrt\",\n",
    "              \"type\": \"shapesys\",\n",
    "              \"data\": TOTAL_BKG_ERR_dict[HNL_mass]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "614e2625-7dc1-486d-9d33-a3c051f0584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_full = pyhf.model.uncorrelated_background(signal=TOTAL_SIGNAL, signal_uncertainty=TOTAL_SIGNAL_ERR, bkg=TOTAL_BKG, bkg_uncertainty=TOTAL_BKG_ERR)\n",
    "# model_full\n",
    "# print(json.dumps(model.spec, indent=2))\n",
    "# model.config.param_set(\"uncorr_bkguncrt\").n_parameters\n",
    "#model.config.param_set(\"uncorr_siguncrt\").n_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0e3cf9e-299d-42f0-afca-e541978bb7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(json.dumps(model.spec, indent=2))\n",
    "DATA_OBS_dict = {}\n",
    "for HNL_mass in HNL_masses:\n",
    "    init_pars = model_dict[HNL_mass].config.suggested_init()\n",
    "    model_dict[HNL_mass].expected_actualdata(init_pars) #signal plus bkg\n",
    "\n",
    "    bkg_pars = init_pars.copy()\n",
    "    bkg_pars[model_dict[HNL_mass].config.poi_index] = 0\n",
    "    model_dict[HNL_mass].expected_actualdata(bkg_pars) #bkg only\n",
    "\n",
    "    DATA_OBS_dict[HNL_mass] = TOTAL_DATA_dict[HNL_mass]+model_dict[HNL_mass].config.auxdata\n",
    "\n",
    "    model_dict[HNL_mass].logpdf(pars=bkg_pars, data=DATA_OBS_dict[HNL_mass])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4a5f893-b271-4da1-bf61-f16bd3fb3e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20MeV\n",
      "Expected CLs(-2 σ): 0.0000\n",
      "Expected CLs(-1 σ): 0.0000\n",
      "Expected CLs( 0 σ): 0.0000\n",
      "Expected CLs( 1 σ): 0.0000\n",
      "Expected CLs( 2 σ): 0.0000\n",
      "50MeV\n",
      "Expected CLs(-2 σ): 0.0000\n",
      "Expected CLs(-1 σ): 0.0000\n",
      "Expected CLs( 0 σ): 0.0000\n",
      "Expected CLs( 1 σ): 0.0000\n",
      "Expected CLs( 2 σ): 0.0000\n",
      "100MeV\n",
      "Expected CLs(-2 σ): 0.0339\n",
      "Expected CLs(-1 σ): 0.0954\n",
      "Expected CLs( 0 σ): 0.2435\n",
      "Expected CLs( 1 σ): 0.5158\n",
      "Expected CLs( 2 σ): 0.8163\n",
      "150MeV\n",
      "Expected CLs(-2 σ): 0.0000\n",
      "Expected CLs(-1 σ): 0.0000\n",
      "Expected CLs( 0 σ): 0.0000\n",
      "Expected CLs( 1 σ): 0.0011\n",
      "Expected CLs( 2 σ): 0.0181\n",
      "180MeV\n",
      "Expected CLs(-2 σ): 0.0000\n",
      "Expected CLs(-1 σ): 0.0000\n",
      "Expected CLs( 0 σ): 0.0000\n",
      "Expected CLs( 1 σ): 0.0000\n",
      "Expected CLs( 2 σ): 0.0000\n",
      "200MeV\n",
      "Expected CLs(-2 σ): 0.0090\n",
      "Expected CLs(-1 σ): 0.0354\n",
      "Expected CLs( 0 σ): 0.1247\n",
      "Expected CLs( 1 σ): 0.3521\n",
      "Expected CLs( 2 σ): 0.6948\n"
     ]
    }
   ],
   "source": [
    "#pyhf.infer.mle.fit(data=DATA_OBS, pdf=model)\n",
    "for HNL_mass in HNL_masses:\n",
    "    CLs_obs, CLs_exp = pyhf.infer.hypotest(\n",
    "        1.0,  # null hypothesis\n",
    "        DATA_OBS_dict[HNL_mass],\n",
    "        model_dict[HNL_mass],\n",
    "        test_stat=\"qtilde\",\n",
    "        return_expected_set=True,\n",
    "        )\n",
    "    \n",
    "#print(f\"      Observed CLs: {CLs_obs:.4f}\")\n",
    "    print(f\"{HNL_mass}MeV\")\n",
    "    for expected_value, n_sigma in zip(CLs_exp, np.arange(-2, 3)):\n",
    "        print(f\"Expected CLs({n_sigma:2d} σ): {expected_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "433df84e-f04e-45cf-9a8f-84f7cf889b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If the output of the following is equal to the lowest or highest value of poi, the range needs to be extended\n",
      "Upper limit 20MeV (obs): μ = 0.1928\n",
      "Upper limit 20MeV (exp): μ = 0.1928\n",
      "\n",
      "Upper limit 50MeV (obs): μ = 0.1908\n",
      "Upper limit 50MeV (exp): μ = 0.1908\n",
      "\n",
      "Upper limit 100MeV (obs): μ = 1.4359\n",
      "Upper limit 100MeV (exp): μ = 1.4359\n",
      "\n",
      "Upper limit 150MeV (obs): μ = 0.3653\n",
      "Upper limit 150MeV (exp): μ = 0.3653\n",
      "\n",
      "Upper limit 180MeV (obs): μ = 0.0927\n",
      "Upper limit 180MeV (exp): μ = 0.0927\n",
      "\n",
      "Upper limit 200MeV (obs): μ = 1.0781\n",
      "Upper limit 200MeV (exp): μ = 1.0781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "obs_limit_dict = {}\n",
    "exp_limits_dict = {}\n",
    "print(\"If the output of the following is equal to the lowest or highest value of poi, the range needs to be extended\")\n",
    "\n",
    "for HNL_mass in HNL_masses:\n",
    "\n",
    "    poi_values = np.linspace(0.001, 10, 100)\n",
    "    obs_limit_dict[HNL_mass], exp_limits_dict[HNL_mass], (scan, results) = pyhf.infer.intervals.upperlimit(\n",
    "        DATA_OBS_dict[HNL_mass], model_dict[HNL_mass], poi_values, level=0.1, return_results=True\n",
    "    )\n",
    "    print(f\"Upper limit {HNL_mass}MeV (obs): μ = {obs_limit_dict[HNL_mass]:.4f}\")\n",
    "    print(f\"Upper limit {HNL_mass}MeV (exp): μ = {exp_limits_dict[HNL_mass][2]:.4f}\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99e89ee7-9741-419d-8dfa-faee7b318a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 20MeV limit is 0.00017565276611044875\n",
      "Observed 20MeV limit is 0.00017565277276562592\n",
      "\n",
      "Expected 50MeV limit is 1.0920525261344537e-05\n",
      "Observed 50MeV limit is 1.092052522652675e-05\n",
      "\n",
      "Expected 100MeV limit is 1.1983074147731274e-06\n",
      "Observed 100MeV limit is 1.1983073726571225e-06\n",
      "\n",
      "Expected 150MeV limit is 1.510942780087027e-07\n",
      "Observed 150MeV limit is 1.5109429153975143e-07\n",
      "\n",
      "Expected 180MeV limit is 7.609925062363602e-08\n",
      "Observed 180MeV limit is 7.609923365786958e-08\n",
      "\n",
      "Expected 200MeV limit is 4.153181878369165e-08\n",
      "Observed 200MeV limit is 4.153181909099249e-08\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Mass point\n",
    "scaled_thetas = {20: 0.02, 50: 0.005, 100: 0.001, 150: 0.0005, 180: 0.0005, 200: 0.0002} #Printed in 3_BDT_script\n",
    "\n",
    "exp_limit = []\n",
    "obs_limit = []\n",
    "\n",
    "for HNL_mass in HNL_masses:\n",
    "    theta_squared = (scaled_thetas[HNL_mass])**2\n",
    "\n",
    "    EXP_LIMIT = np.sqrt(exp_limits_dict[HNL_mass][2])*theta_squared\n",
    "    LIMIT = np.sqrt(obs_limit_dict[HNL_mass])*theta_squared\n",
    "    print(f\"Expected {HNL_mass}MeV limit is \" + str(EXP_LIMIT))\n",
    "    print(f\"Observed {HNL_mass}MeV limit is \" + str(LIMIT)+ \"\\n\")\n",
    "    \n",
    "    exp_limit.append(EXP_LIMIT)\n",
    "# print()\n",
    "# print(\"Owen's expected limit is \" + str(Owen_exp_limit))\n",
    "# print(\"Owen's observed limit is \" + str(Owen_obs_limit))\n",
    "\n",
    "# print()\n",
    "# perc_diff_exp = (1-(EXP_LIMIT/Owen_exp_limit))*100\n",
    "# perc_diff_obs = (1-(LIMIT/Owen_obs_limit))*100\n",
    "\n",
    "# print(\"pyhf expected limit is \" + str(perc_diff_exp) + \" different from Owen's limit.\")\n",
    "# print(\"pyhf observed limit is \" + str(perc_diff_obs) + \" different from Owen's limit.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69557119-e9c6-430c-a6b5-b6ddaea4613f",
   "metadata": {},
   "source": [
    "## Saving Limits as .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3197c589-b82b-4105-be66-ec902f4ffafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 50, 100, 150, 180, 200]\n",
      "[0.00017565276611044875, 1.0920525261344537e-05, 1.1983074147731274e-06, 1.510942780087027e-07, 7.609925062363602e-08, 4.153181878369165e-08]\n"
     ]
    }
   ],
   "source": [
    "masses = HNL_masses\n",
    "\n",
    "if stats_only == True:\n",
    "    stats =  \"Stats_only\"\n",
    "else:\n",
    "    stats = \"Owen_sys\"\n",
    "    \n",
    "if use_second_half_score == True:\n",
    "    half_hist = \"havled\"\n",
    "else:\n",
    "    half_hist = \"full_hist\"\n",
    "\n",
    "print(masses)\n",
    "print(exp_limit)\n",
    "\n",
    "r = zip(masses, exp_limit)\n",
    "\n",
    "with open(f'limit_files/{stats}_{half_hist}_expected_mu_COMBINED_highest_E.csv', \"w\") as s:\n",
    "    w = csv.writer(s)\n",
    "    for row in r:\n",
    "        w.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1405e88b-4862-4f4f-9aae-df0dc1924ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66cc7172-6236-477f-9d5c-1a50e81519ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"channels\": [\n",
      "    {\n",
      "      \"name\": \"singlechannel\",\n",
      "      \"samples\": [\n",
      "        {\n",
      "          \"name\": \"signal\",\n",
      "          \"data\": [\n",
      "            0.2123590111732483,\n",
      "            0.11062422394752502,\n",
      "            0.11753824353218079,\n",
      "            0.0948207676410675,\n",
      "            0.08494359999895096,\n",
      "            0.09975934773683548,\n",
      "            0.10074706375598907,\n",
      "            0.09778391569852829,\n",
      "            0.09778391569852829,\n",
      "            0.12050139158964157,\n",
      "            0.1333416998386383,\n",
      "            0.16099776327610016,\n",
      "            0.20445728302001953,\n",
      "            0.21927301585674286,\n",
      "            0.2508799433708191,\n",
      "            0.3121183514595032,\n",
      "            0.43360745906829834,\n",
      "            0.6222612857818604,\n",
      "            1.114143967628479,\n",
      "            4.416079521179199,\n",
      "            0.11143967509269714,\n",
      "            0.0829869881272316,\n",
      "            0.07113170623779297,\n",
      "            0.06243783235549927,\n",
      "            0.05137290060520172,\n",
      "            0.05611501261591911,\n",
      "            0.07192205637693405,\n",
      "            0.07350276410579681,\n",
      "            0.06797029823064804,\n",
      "            0.08377734571695328,\n",
      "            0.09326156973838806,\n",
      "            0.10985896736383438,\n",
      "            0.11460108309984207,\n",
      "            0.1477958858013153,\n",
      "            0.18178102374076843,\n",
      "            0.25449344515800476,\n",
      "            0.35486817359924316,\n",
      "            0.5406009554862976,\n",
      "            1.1349458694458008,\n",
      "            5.407590389251709\n",
      "          ],\n",
      "          \"modifiers\": [\n",
      "            {\n",
      "              \"name\": \"mu\",\n",
      "              \"type\": \"normfactor\",\n",
      "              \"data\": null\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"background\",\n",
      "          \"data\": [\n",
      "            4813.0419921875,\n",
      "            1084.7637939453125,\n",
      "            583.9191284179688,\n",
      "            408.3866882324219,\n",
      "            292.4494323730469,\n",
      "            216.58653259277344,\n",
      "            163.92173767089844,\n",
      "            168.064697265625,\n",
      "            130.50506591796875,\n",
      "            105.41650390625,\n",
      "            92.03352355957031,\n",
      "            73.40505981445312,\n",
      "            83.59547424316406,\n",
      "            78.19515228271484,\n",
      "            63.587196350097656,\n",
      "            54.04482650756836,\n",
      "            63.537628173828125,\n",
      "            56.97993087768555,\n",
      "            41.053070068359375,\n",
      "            26.990182876586914,\n",
      "            6222.9423828125,\n",
      "            1328.26611328125,\n",
      "            760.9569091796875,\n",
      "            562.6710205078125,\n",
      "            447.1845703125,\n",
      "            346.5769348144531,\n",
      "            290.2818603515625,\n",
      "            244.77734375,\n",
      "            225.49014282226562,\n",
      "            196.5823974609375,\n",
      "            175.8265380859375,\n",
      "            153.3267059326172,\n",
      "            154.1259307861328,\n",
      "            142.684326171875,\n",
      "            133.48500061035156,\n",
      "            118.56350708007812,\n",
      "            115.80341339111328,\n",
      "            122.71444702148438,\n",
      "            113.43251037597656,\n",
      "            62.4538459777832\n",
      "          ],\n",
      "          \"modifiers\": [\n",
      "            {\n",
      "              \"name\": \"uncorr_bkguncrt\",\n",
      "              \"type\": \"shapesys\",\n",
      "              \"data\": [\n",
      "                1481.253173828125,\n",
      "                162.64280700683594,\n",
      "                83.81015014648438,\n",
      "                59.9840202331543,\n",
      "                46.59243392944336,\n",
      "                35.241127014160156,\n",
      "                27.77196502685547,\n",
      "                24.55970001220703,\n",
      "                18.695737838745117,\n",
      "                17.6707706451416,\n",
      "                15.45075798034668,\n",
      "                12.776668548583984,\n",
      "                13.477092742919922,\n",
      "                11.36016845703125,\n",
      "                8.785843849182129,\n",
      "                8.902772903442383,\n",
      "                8.560722351074219,\n",
      "                8.49879264831543,\n",
      "                6.323156833648682,\n",
      "                5.41060733795166,\n",
      "                2432.649169921875,\n",
      "                299.70184326171875,\n",
      "                156.1425018310547,\n",
      "                106.06019592285156,\n",
      "                83.75310516357422,\n",
      "                62.723365783691406,\n",
      "                54.59048843383789,\n",
      "                45.86286544799805,\n",
      "                41.29096984863281,\n",
      "                32.37138748168945,\n",
      "                31.506181716918945,\n",
      "                26.538427352905273,\n",
      "                27.113197326660156,\n",
      "                26.818252563476562,\n",
      "                24.2493839263916,\n",
      "                20.97845458984375,\n",
      "                23.549537658691406,\n",
      "                24.74275016784668,\n",
      "                25.598798751831055,\n",
      "                12.846282958984375\n",
      "              ]\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "HNL_mass = 100\n",
    "print(json.dumps(model_dict[HNL_mass].spec, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01974e7f-3d17-4287-ba74-5328c603a38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict_full_sys = {}\n",
    "\n",
    "for HNL_mass in HNL_masses:\n",
    "    model_dict_full_sys[HNL_mass] = pyhf.Model(\n",
    "        {\n",
    "  \"channels\": [\n",
    "    {\n",
    "      \"name\": \"singlechannel\",\n",
    "      \"samples\": [\n",
    "        {\n",
    "          \"name\": \"signal\",\n",
    "          \"data\": TOTAL_SIGNAL_dict[HNL_mass],\n",
    "          \"modifiers\": [\n",
    "            {\n",
    "              \"name\": \"mu\",\n",
    "              \"type\": \"normfactor\",\n",
    "              \"data\": None\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"uncorr_siguncrt\",\n",
    "              \"type\": \"shapesys\",\n",
    "              \"data\": TOTAL_SIGNAL_ERR_dict[HNL_mass]  \n",
    "            }\n",
    "          ]\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"background\",\n",
    "          \"data\": TOTAL_BKG_dict[HNL_mass],\n",
    "          \"modifiers\": [\n",
    "            {\n",
    "              \"name\": \"uncorr_bkguncrt\",\n",
    "              \"type\": \"shapesys\",\n",
    "              \"data\": TOTAL_BKG_ERR_dict[HNL_mass]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9416cdf2-0f11-4ae6-ac1b-9260325f2396",
   "metadata": {},
   "source": [
    "# Adding in signal systematic uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "244d3408-b6f7-4cc9-bad2-86f8bb48220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Messing around with model\n",
    "\n",
    "full_model = pyhf.Model(\n",
    "    {\n",
    "  \"channels\": [\n",
    "    {\n",
    "      \"name\": \"singlechannel\",\n",
    "      \"samples\": [\n",
    "        {\n",
    "          \"name\": \"signal\",\n",
    "          \"data\": [\n",
    "            0.4354482889175415,\n",
    "            0.6531724333763123,\n",
    "            0.9367626905441284,\n",
    "            1.1947383880615234,\n",
    "            1.3539148569107056,\n",
    "            1.192908763885498,\n",
    "            0.6879351139068604,\n",
    "            0.2671237289905548,\n",
    "            0.8156560063362122,\n",
    "            1.649437665939331,\n",
    "            2.6418192386627197,\n",
    "            3.511852264404297,\n",
    "            3.4166924953460693,\n",
    "            2.6418192386627197,\n",
    "            1.114729881286621,\n",
    "            0.842844545841217\n",
    "          ],\n",
    "          \"modifiers\": [\n",
    "            {\n",
    "              \"name\": \"mu\",\n",
    "              \"type\": \"normfactor\",\n",
    "              \"data\": None\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"uncorr_siguncrt\",\n",
    "              \"type\": \"shapesys\",\n",
    "              \"data\": TOTAL_SIGNAL_ERR  \n",
    "            }\n",
    "          ]\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"background\",\n",
    "          \"data\": [\n",
    "            227.98190307617188,\n",
    "            185.65267944335938,\n",
    "            141.53671264648438,\n",
    "            83.10063171386719,\n",
    "            39.49835968017578,\n",
    "            20.065095901489258,\n",
    "            5.26054573059082,\n",
    "            0.7651026844978333,\n",
    "            385.53765869140625,\n",
    "            330.3393249511719,\n",
    "            241.39376831054688,\n",
    "            143.0430908203125,\n",
    "            55.337371826171875,\n",
    "            20.656126022338867,\n",
    "            7.634726524353027,\n",
    "            3.049088954925537\n",
    "          ],\n",
    "          \"modifiers\": [\n",
    "            {\n",
    "              \"name\": \"uncorr_bkguncrt\",\n",
    "              \"type\": \"shapesys\",\n",
    "              \"data\": [\n",
    "                34.158817291259766,\n",
    "                27.066844940185547,\n",
    "                22.60236358642578,\n",
    "                14.79345417022705,\n",
    "                6.955612659454346,\n",
    "                4.61644983291626,\n",
    "                1.6257153749465942,\n",
    "                0.48608535528182983,\n",
    "                73.31805419921875,\n",
    "                65.45207214355469,\n",
    "                51.50766372680664,\n",
    "                34.320030212402344,\n",
    "                10.886519432067871,\n",
    "                5.264797210693359,\n",
    "                2.1698012351989746,\n",
    "                1.1060731410980225\n",
    "              ]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6192c9b-f9ee-4407-be07-9f98aa29e8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-111.00315017])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(json.dumps(full_model.spec, indent=2))\n",
    "init_pars = full_model.config.suggested_init()\n",
    "full_model.expected_actualdata(init_pars) #signal plus bkg\n",
    "\n",
    "bkg_pars = init_pars.copy()\n",
    "bkg_pars[model.config.poi_index] = 0\n",
    "full_model.expected_actualdata(bkg_pars) #bkg only\n",
    "\n",
    "DATA_OBS = TOTAL_DATA+full_model.config.auxdata\n",
    "\n",
    "full_model.logpdf(pars=bkg_pars, data=DATA_OBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe01a2b1-3aa2-4348-9804-04c1f5937e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Observed CLs: 0.3368\n",
      "Expected CLs(-2 σ): 0.1098\n",
      "Expected CLs(-1 σ): 0.2229\n",
      "Expected CLs( 0 σ): 0.4195\n",
      "Expected CLs( 1 σ): 0.6851\n",
      "Expected CLs( 2 σ): 0.9041\n"
     ]
    }
   ],
   "source": [
    "CLs_obs, CLs_exp = pyhf.infer.hypotest(\n",
    "    1.0,  # null hypothesis\n",
    "    DATA_OBS,\n",
    "    full_model,\n",
    "    test_stat=\"qtilde\",\n",
    "    return_expected_set=True,\n",
    ")\n",
    "print(f\"      Observed CLs: {CLs_obs:.4f}\")\n",
    "for expected_value, n_sigma in zip(CLs_exp, np.arange(-2, 3)):\n",
    "    print(f\"Expected CLs({n_sigma:2d} σ): {expected_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6eddbe7e-3de0-4d2a-8729-49308c8ec4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper limit (obs): μ = 1.9852\n",
      "Upper limit (exp): μ = 2.2352\n"
     ]
    }
   ],
   "source": [
    "poi_values = np.linspace(0.1, 10, 50)\n",
    "obs_limit, exp_limits, (scan, results) = pyhf.infer.intervals.upperlimit(\n",
    "    DATA_OBS, full_model, poi_values, level=0.1, return_results=True\n",
    ")\n",
    "print(f\"Upper limit (obs): μ = {obs_limit:.4f}\")\n",
    "print(f\"Upper limit (exp): μ = {exp_limits[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7eb56c7e-87ee-4eb0-8390-0ef5904cddae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected limit is 1.495059542214373e-08\n",
      "Observed limit is 1.40898768497879e-08\n",
      "\n",
      "Owen's expected limit is 1.52039448e-08\n",
      "Owen's observed limit is 1.46164475e-08\n",
      "\n",
      "pyhf expected limit is 1.6663397637188937 different from Owen's limit.\n",
      "pyhf observed limit is 3.6025898236360154 different from Owen's limit.\n"
     ]
    }
   ],
   "source": [
    "#Mass point\n",
    "EXP_LIMIT = np.sqrt(exp_limits[2])*theta_squared\n",
    "LIMIT = np.sqrt(obs_limit)*theta_squared\n",
    "print(\"Expected limit is \" + str(EXP_LIMIT))\n",
    "print(\"Observed limit is \" + str(LIMIT))\n",
    "print()\n",
    "print(\"Owen's expected limit is \" + str(Owen_exp_limit))\n",
    "print(\"Owen's observed limit is \" + str(Owen_obs_limit))\n",
    "\n",
    "print()\n",
    "perc_diff_exp = (1-(EXP_LIMIT/Owen_exp_limit))*100\n",
    "perc_diff_obs = (1-(LIMIT/Owen_obs_limit))*100\n",
    "\n",
    "# perc_diff_exp = (1-(Owen_exp_limit/EXP_LIMIT))*100\n",
    "# perc_diff_obs = (1-(Owen_obs_limit/LIMIT))*100\n",
    "\n",
    "print(\"pyhf expected limit is \" + str(perc_diff_exp) + \"% different from Owen's limit.\")\n",
    "print(\"pyhf observed limit is \" + str(perc_diff_obs) + \"% different from Owen's limit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9608e383-7ca2-43da-99f1-4b5660318ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
